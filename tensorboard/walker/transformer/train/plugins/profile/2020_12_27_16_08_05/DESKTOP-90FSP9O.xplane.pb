
	/host:CPUFu"ڽퟗ"8"	 "א"ƿΫ"""曈"Ę$""ݚ"˛"ǚ""""˞""̠""آ"""ழ""""Ӧ""ӧ"Ŗ"٨"霩"٩"""ࢣ""ӯ""""Ȯ""ȯ"υ"Ȱ"慱"ϱ""ϲ""ϳ"ਆ"ϴ"ْ"""⽷"$"ܸ"͟""""""""""˾"Ҡ"""""""""ʛ""""""""ش"""Ö"""""ȵ""޵"""ࠅ""ċ""""""""ෘ""""ג""""ӷ"""""""""""""""ٚ""""""""""ա""""ڏ""""ִ"""""ɐ""""""""""ϑ""ശ""ؼ"""""""""""""̫""""ʀ""""݂""݃""""""ň"ׇg""۹""""""̌"ʉ"ƍ"Ӄ"ʺ""Ə""""""""""""""""""Ș"	Ջ""닚"Ț""ͤ""ɘ"՝"Č"Þ"͆"ϟ""	à""ױ""ૢ""Ι"ܣ"ד"Ф""ʾ"釦"ྦ""鸧""	""ũ""""""	Ŭ""ਏ"̮""Ư""ذ"މ"̱""Ӳ"""֢""좵""""ͻ""仸""ι"Ν""""""ะ""Ͼ""տ"Ӟ""""Ԁ""""""""""""""""""""""""""""Ρ""""""	"""""Ɯ""ܜ""ؐ"""	"""""""Ǒ""Å"""	ö""""୘"""""""ಷ""""""""ߙ""""""""""ܠ""""""""""""ଉ"""""""౨""""""""""""""஑"Ȁ"	෋"ȁ""""΃"	"Ȅ""Ʌ""Ɇ"垇""""""꽊""ċ""a"ʍ"ٍ"Ў"⇏"ď"끐"⸐"""ई"Œ"ୂ"œ"Ă"ȿ""ĳ""ͭ""㭗""ߡ"ޘ""ؙ"""""Ũ""ǝ"""""ڠ""ڡ""Ԣ""ȣ""Ȥ""""""""Ъ""檩""➪"۪"	""ķ"$"""˶*""""	"ؕ"	""$""	"Ê""""
"0Ȉ"  "*EagerKernelExecute 0"9Ĺ" " ""  ""g"γ"ʫ$"޸ƭ"֭"
׭"ح"٭"ุO"زɐ"  ""  " "İ"ʰ"ڏҰ"Ұҿ"߰"߰"  "*"  " ""̓	""줥"ѰI"޶"𴻼"濼"܋ļ
"Ǽз"˼"Ӽ톓"ؼȍ"ؼ"$""  ""  " "a""
""¤""O"݅C""ǩĦ"՚""줝"՝དྷ"  ""  " Ju
tf_Compute"=!" "  " ""  "!"  "  "=།!" "  " ""  "!U"  "  "=า!" "  " ""  "!U"  "  "=!" "  " ""  "!a"  "  "=!" "  " ""  "ྕ!U"  "  "=!" "  " ""  "!g"  "  "=!" "  " ""  "ը!z"  "  "=!" "  " ""  "	!"  "  "=!" "  " ""  "
!I"  "  "=!˘" "  " ""  "⅀"="  "  "="" "  " ""  ""["  "  "="" "  " ""  "ۃ"C"  "  "="" "  " ""  ""a"  "  "="" "  " ""  """  "  "=׎"" "  " ""  "堏"C"  "  "="" "  " ""  "Ю"m"  "  "=՞"" "  " ""  ""s"  "  "="" "  " ""  """  "  "="" "  " ""  ""؞"  "  "="ǌ" "  " ""  ""O"  "  "="" "  " ""  ""="  "  "="" "  " ""  "χ""  "  ">⥕#˳x" "  " ""  "#S"  "  "vڹ"  "  "ǅ
"  "  "ߑ	"  "  "?ɖ&" "  " ""  "욛"  "  "آϨ"  "  "͜"  "  "?" "  " ""  ""  "  " "  "  "!͸ȁ	"  "  ""Ҥ"  "  "?
B" "  " ""  "#ފ
"  "  "$
"  "  "%
"  "  "?" "  " ""  "&"  "  ">%" "  " ""  "'"  "  "(ፖಔ"  "  "?	" "  " ""  ")ح	"  "  "*ㆠಔ"  "  "?ԔҠ1" "  " ""  "+֠߂"  "  ",ާ"  "  "-؛"  "  "."  "  ">" "  " ""  "/"  "  "0	"  "  ">" "  " ""  "1͐"  "  "2"  "  "?寧
" "  " ""  "3	"  "  "4ྏ6"  "  ">" "  " ""  "5"  "  "6ԓ"  "  "?ݨ" "  " ""  "7ʝ"  "  "8"  "  ">q" "  " ""  "9B"  "  ":["  "  ";%"  "  "?" "  " ""  "<%"  "  "=х"  "  "?" "  " ""  ">"  "  "?"  "  "@"  "  "A"  "  "Bŉ"  "  "Cॱ"  "  "DQ"  "  "E"  "  "F+"  "  "G"  "  ">ރ," "  " ""  "H"  "  "I"  "  ">ۅq" "  " ""  "Jύ"  "  "Kर "  "  "L"  "  "M˄"  "  "NԄ"  "  "O޲"  "  "?" "  " ""  "P鄅ܮ"  "  "Qϝ"  "  "R"  "  "S९"  "  "T¼"  "  "U݅6"  "  "Vڛ"  "  ">," "  " ""  "Wؚ("  "  ">Ɠ`" "  " ""  "X="  "  "Yԭg"  "  "Zح"  "  "[࣋"  "  "?" "  " ""  "\,"  "  "]鐥"  "  "? " "  " ""  "^Ů"  "  "?" "  " ""  "_ԍ"  "  "`$"  "  "?ଢ଼8" "  " ""  "a"  "  "b٬"  "  "cר"  "  "?" "  " ""  "dނ"  "  "eƵͤ#"  "  "?ۙĒ " "  " ""  "fɀ"  "  "?נ" "  " ""  "gˑ"  "  "hܗ"  "  "iਿ؄"  "  "?̦
" "  " ""  "j̈Ϲ
"  "  "kѬ"  "  "?" "  " ""  "l"  "  "m"  "  "?" "  " ""  "n"  "  "?ڙ." "  " ""  "oã"  "  "pڎ"  "  "q鑧	"  "  "r"  "  "sڀ"  "  "tۙ摎"  "  "uꅦ"  "  "vߴ"  "  "?" "  " ""  "w
"  "  "xɏ$"  "  "@" "  " ""  "y·)"  "  "zݻ଍"  "  "{ʹ́	"  "  "|ɋ"  "  "}³"  "  "~"  "  "޵<"  "  "沬"  "  "粁ަ	"  "  "ӟ"  "  "ϖՖ
"  "  "ߒП"  "  "ਜ਼"  "  "ڠ"  "  "֤"  "  "?~" "  " ""  "ɱ"  "  "Â"  "  ""  "  "Ꮐ"  "  "Ǽ"  "  ""  "  "牯˦"  "  "΂߈ז"  "  ""  "  "ߝ"  "  ""  "  "ۖ"  "  "	"  "  "핢"  "  "@" "  " ""  ""  "  "಄Ŝ"  "  "힍"  "  ""  "  "칓"  "  "Ո	"  "  "ڝ"  "  "B"  "  ""  "  "۱"  "  "?Ǿ௺," "  " ""  "ⵁ"  "  ""  "  "빧Ո
"  "  "?ͪ
" "  " ""  "Ϳۏ"  "  "%"  "  "?æ" "  " ""  "ɷ"  "  ""  "  "?" "  " ""  "ς"  "  "?ہϵ*" "  " ""  "ଡ	"  "  "ȯ"  "  ""  "  ""  "  "	"  "  ""  "  "੍"  "  "ڛऍ"  "  "?ŵ" "  " ""  "ɵ"  "  ""  "  "@ׂ" "  " ""  "ࣝ#"  "  ""  "  ""  "  ""  "  "ٕǺ
"  "  "ƈ䛫"  "  "ܺѱ6"  "  ""  "  ""  "  "ת"  "  JZ
tf_Compute"=!ށ
" "  " ""  "!"  "  "=!ǌ" "  " ""  "!m"  "  "=!" "  " ""  """  "  "="" "  " ""  "܅"U"  "  "="" "  " ""  ""z"  "  "="" "  " ""  ""0"  "  "="" "  " ""  ""["  "  "="" "  " ""  ""z"  "  "=զ"" "  " ""  "ϧ"U"  "  "=߉"" "  " ""  """  "  "="" "  " ""  ""I"  "  "=݅"" "  " ""  ""I"  "  "="" "  " ""  ""I"  "  "="" "  " ""  ""U"  "  "="˘" "  " ""  ""U"  "  "="؞" "  " ""  ""="  "  "=Ҟ"ǽ" "  " ""  """  "  "=ϥ"" "  " ""  "ʙ"m"  "  "="" "  " ""  ""O"  "  "?྽#󸜔" "  " ""  "՟#6"  "  "YѤ"  "  "z"  "  "ˉ"  "  "?4" "  " ""  "ڻ"  "  "ﺠ"  "  ""  "  "ނ"  "  ""  "  "?
ܼu" "  " ""  "
A"  "  "ϣ"  "  "ާȅ"  "  "?ȭ" "  " ""  ""  "  ""  "  "ࣷ"  "  ""  "  ""  "  "ӕ"  "  ""  "  ""  "  "݌"  "  ""  "  "	"  "  "	"  "  ""  "  "="  "  "C"  "  "À̾	"  "  "ࣷ"  "  ">8" "  " ""  "ۈ"  "  ""  "  "؞"  "  "ד"  "  ""  "  "C"  "  "?" "  " ""  "	"  "  ""  "  "ǌ"  "  ""  "  "ٖ"  "  "O"  "  ""  "  ""  "  "Ľ&"  "  ""  "  ""  "  ""  "  ""  "  "òś"  "  ""  "  "ǌ"  "  ""  "  "	"  "  ""  "  "="  "  "0"  "  ""  "  ""  "  "><" "  " ""  ""  "  "൫"  "  "୴"  "  "ઝ"  "  "̫"  "  "쿟a"  "  "?௯у" "  " ""  "Է	"  "  ""  "  ""  "  ""  "  ""  "  "I"  "  "ܡ"  "  "ޡ"  "  ""  "  "ʼu"  "  "٤"  "  ""  "  ""  "  ""  "  "ܧǽ"  "  ""  "  "Ж	"  "  "ո
"  "  ""  "  "뛧0"  "  "0"  "  ""  "  ""  "  ">Z" "  " ""  "˷ඤ""  "  "ñ"  "  ""  "  ""  "  "Ɛ"  "  "﯐I"  "  ">őࠠ
" "  " ""  ""  "  "["  "  ""  "  ">" "  " ""  ""  "  ">J" "  " ""  "."  "  ""  "  "?౓" "  " ""  "޹"  "  "ݟӾ"  "  "?ടҶ>" "  " ""  "ଔ
"  "  "ꮭ"  "  "ϫ"  "  ""  "  "?" "  " ""  "đЎ"  "  ">!" "  " ""  ""  "  "	"  "  "?<" "  " ""  "	"  "  "힮"  "  ""  "  "U"  "  "?ߕ5" "  " ""  ""  "  ""  "  "ۀ"  "  "$"  "  "?" "  " ""  "༿"  "  "/"  "  "?%" "  " ""  " "  "  "?ؒ," "  " ""  "ے"  "  ""  "  ""  "  "?ꚫ" "  " ""  ""  "  "ܷ"  "  "?
" "  " ""  "ϡ؛
"  "  ""  "  "?" "  " ""  "݃ݎ"  "  "Ț<"  "  "?̬" "  " ""  "̴"  "  "Ɵ)"  "  "?̗" "  " ""  ""  "  ""  "  "?=" "  " ""  "0"  "  ""  "  "?τ" "  " ""  "҄ܝ"  "  "9"  "  "?	" "  " ""  "܃"  "  ""  "  "?Ԗ
" "  " ""  "זǜ
"  "  "?" "  " ""  "ȗ"  "  "?#" "  " ""  ""  "  ""  "  "Խ
"  "  "?ނ̅	" "  " ""  "	"  "  "Ź"  "  "@ǣ" "  " ""  "笊$"  "  "Ѝţ"  "  "Џ"  "  "ψ"  "  "䣥	"  "  "̓"  "  "ٹ7"  "  ""  "  "Ɓ
"  "  "֩ځ"  "  "	"  "  "ҹ
"  "  ""  "  "ց"  "  ""  "  "?ɺͻ" "  " ""  "œ	"  "  ""  "  ""  "  "?
" "  " ""  "Ʋ
"  "  "ۼ"  "  "?Ȑ*" "  " ""  ""  "  "N"  "  "?" "  " ""  "൒Ư"  "  "࡙("  "  "?
" "  " ""  "
"  "  "?" "  " ""  "ƹͣ"  "  "("  "  "?" "  " ""  ""  "  "彿"  "  X
tf_Compute">ا" "  " ""  "=$" "  " ""  "$"  "  "=$" "  " ""  "̰$C"  "  "=Ʊ$˘" "  " ""  "$6"  "  "=$˘" "  " ""  "$6"  "  "=$" "  " ""  "$I"  "  "=ڷ$ఌ" "  " ""  "$0"  "  "=$؞" "  " ""  "$O"  "  "=$" "  " ""  "$U"  "  "=$" "  " ""  "$="  "  "=Ͻ$" "  " ""  "$="  "  "=$˘" "  " ""  "$C"  "  "=$" "  " ""  "$="  "  "=Ƚ$˘" "  " ""  "$6"  "  "=$ఌ" "  " ""  "$C"  "  "=$" "  " ""  "$6"  "  "=$" "  " ""  "$U"  "  "=$" "  " ""  "$="  "  "<ӎ$m" "  " ""  "$*"  "  "=$ఌ" "  " ""  "$C"  "  "=$" "  " ""  "$="  "  "=$" "  " ""  "$0"  "  "=$" "  " ""  "$6"  "  "=$˘" "  " ""  "$C"  "  "=$" "  " ""  "$6"  "  "=$" "  " ""  "Ֆ$="  "  "=$" "  " ""  "$I"  "  "<$z" "  " ""  "$0"  "  "=$" "  " ""  "$6"  "  "=$" "  " ""  "$6"  "  "=$" "  " ""  "$0"  "  "=$" "  " ""  "೘$6"  "  "<$z" "  " ""  "$6"  "  "<Ӓ$s" "  " ""  "$*"  "  "=$" "  " ""  "ܽ$6"  "  "=$" "  " ""  "$a"  "  "=$" "  " ""  "$O"  "  "=$" "  " ""  "$*"  "  "<˾$s" "  " ""  "$0"  "  "=$݌" "  " ""  "$0"  "  "<$m" "  " ""  "$*"  "  "=$" "  " ""  "$="  "  "=$" "  " ""  "$6"  "  "=$
" "  " ""  "֏$C"  "  "$"  "  "ע$g"  "  "$"  "  "=$" "  " ""  "$="  "  "=ꋂ%ఌ" "  " ""  "Ȃ%6"  "  "=а%˘" "  " ""  "%6"  "  "=%˘" "  " ""  "Ʌ%0"  "  "<%m" "  " ""  "ۆ%0"  "  "=%" "  " ""  "%6"  "  "<Ј%s" "  " ""  "%*"  "  "<%g" "  " ""  "%$"  "  "=%" "  " ""  "͙%6"  "  "=%" "  " ""  "%C"  "  "<%z" "  " ""  "ʍ%6"  "  "<%s" "  " ""  "ݎ%*"  "  "=踏%" "  " ""  "ё%0"  "  "=%" "  " ""  "ݒ%="  "  "=œ%" "  " ""  "%C"  "  "=%" "  " ""  "ƕ%U"  "  "<Ɩ%s" "  " ""  "%*"  "  ">ؗ%σR" "  " ""  "%޷Q"  "  "v"  "  "w"  "  "w"  "  ">w" "  " ""  "ߞw"  "  "z"  "  "鈂{
"  "  "ԑ{	"  "  ">Н{
" "  " ""  "{³
"  "  "ԅ"  "  ""  "  "
"  "  "?" "  " ""  "ྞ
"  "  "ؒࠠ
"  "  "③"  "  ""  "  "?䟎	" "  " ""  ""  "  "୪!"  "  "է	"  "  "ʩ"  "  "?" "  " ""  "⧛"  "  "ɞ"  "  "ٞ"  "  "ઞ	"  "  "?" "  " ""  "ޗ"  "  "܈"  "  "˾ෳ"  "  "঩"  "  "?ϡ" "  " ""  "ס"  "  "٧"  "  "Ⱦࠠ
"  "  "վ"  "  "?" "  " ""  ""  "  ""  "  "飇
"  "  "矓"  "  "?ӒZ" "  " ""  "܌海"  "  ""  "  "τ"  "  "
"  "  ""  "  "М"  "  ""  "  "÷"  "  "ٛؚ	"  "  "?Ȱ̐*" "  " ""  "ΐ"  "  ""  "  "ҧ멟"  "  "?̉)" "  " ""  "̋ĩ"  "  "֝Ϧ"  "  "ż"  "  "?&" "  " ""  "ܹ"  "  "Ԝ"  "  "
"  "  "?
Ƕs" "  " ""  "
вC"  "  ""  "  ""  "  "?" "  " ""  "ⳙ"  "  ""  "  "ִU"  "  "׵ඤ""  "  "U"  "  ""  "  ""  "  "*"  "  ""  "  "ьե"  "  "ݝ"  "  ""  "  ""  "  "
"  "  ""  "  "Ŀ6"  "  "*"  "  "	"  "  ""  "  "?" "  " ""  "%"  "  ""  "  ""  "  "'"  "  "ȶ!"  "  ""  "  "%"  "  ""  "  "݌"  "  "Ų"  "  "Ŵ"  "  "
"  "  ""  "  "*"  "  "$"  "  "	"  "  "ࣷ"  "  ">ڊ" "  " ""  "۹"  "  "߈"  "  "I"  "  "?" "  " ""  """  "  ""  "  "I"  "  "'"  "  ""  "  "ල"  "  ""  "  "ď$"  "  ""  "  ""  "  ""  "  ""  "  ""  "  ""  "  ""  "  "*"  "  "0"  "  "	"  "  "ࣷ"  "  "?ଽ" "  " ""  "ٌ$"  "  ""  "  "؞"  "  "ॿ"  "  "ͦ"  "  "¬$"  "  ""  "  "
"  "  "̶+"  "  "s"  "  ""  "  "ؒ"  "  "ا"  "  "ʒ"  "  "ȎІ"  "  "ࣷ"  "  "䏻ȁ	"  "  "
"  "  ""  "  "C"  "  "0"  "  ""  "  ""  "  "?" "  " ""  "ர""  "  ""  "  ""  "  ""  "  ""  "  ""  "  "ඤ""  "  "ո
"  "  "؈"  "  "؋"  "  ""  "  ""  "  ""  "  "*"  "  "Ũ$"  "  "ඎ"  "  ""  "  ">`" "  " ""  "ӄ"  "  "Ǩ"  "  ""  "  ""  "  "݌"  "  ""  "  ""  "  ""  "  ""  "  "Ŋ"  "  ""  "  "։"  "  "0"  "  "Φ"  "  "C"  "  "ޖ0"  "  ">Ɨ" "  " ""  ""  "  "Ҙ$"  "  "৺m"  "  ">" "  " ""  ""  "  ""  "  ">" "  " ""  "
"  "  ""  "  ">!" "  " ""  ""  "  "ષ"  "  ""  "  ""  "  "z"  "  "?" "  " ""  ""  "  "Կ}"  "  "?ۃ	" "  " ""  ""  "  "ܽ٥"  "  ">D" "  " ""  "ϊ"  "  ""  "  "?ࢃ" "  " ""  "A"  "  ""  "  "?" "  " ""  "U"  "  ""  "  ""  "  "U"  "  "$"  "  "ۯ"  "  "ŏI"  "  ""  "  """  "  "?ӆ" "  " ""  "."  "  "ָs"  "  ">" "  " ""  ""  "  ""  "  ">ޱϬ." "  " ""  ""  "  ""  "  ""  "  ""  "  ""  "  ">" "  " ""  "	"  "  ""  "  "?" "  " ""  ""  "  ""  "  ">" "  " ""  "	"  "  ""  "  ">V" "  " ""  ";"  "  ""  "  "ƅ"  "  "
"  "  ">Ѵb" "  " ""  ","  "  "1"  "  ">֗F" "  " ""  "֘"  "  ""  "  ""  "  ">Ÿ1" "  " ""  ""  "  "̍"  "  ">ߑ" "  " ""  ""  "  ""  "  "ʦ"  "  ""  "  "?" "  " ""  "᧣"  "  "͌"  "  "?إ" "  " ""  ""  "  "؜Č"  "  "?4" "  " ""  "ٮɭ"  "  "卷ژ"  "  ""  "  "n"  "  "?*" "  " ""  "À"  "  ""  "  ""  "  "ڞ"  "  "ݢ"  "  "?" "  " ""  ""  "  ""  "  ""  "  "?" "  " ""  "Ϸ"  "  ""  "  "?" "  " ""  "˛"  "  ""  "  "?ݮ" "  " ""  ""  "  ""  "  "?>" "  " ""  ""  "  "ٚ"  "  "݁Ւ"  "  "ة"  "  ""  "  "ߠ"  "  ""  "  "߀"  "  "?Û" "  " ""  "Ʊ
"  "  "Յq"  "  "@" "  " ""  " "  "  ""  "  "ܫ"  "  "ҭұ"  "  "ٰ"  "  ""  "  "Ջ?"  "  ""  "  "	"  "  "½"  "  "㗗"  "  "ѓģ"  "  ""  "  ""  "  "೦"  "  "?ʆ͒x" "  " ""  "獻"  "  "ʊ"  "  ""  "  "酪"  "  "뛝"  "  ""  "  ""  "  "Ǟ"  "  ""  "  "௬"  "  ""  "  "ּʞ"  "  ""  "  "઼"  "  "@්Ė" "  " ""  "ຊ"  "  ""  "  "ړ"  "  "Û鯬"  "  "ܶ"  "  ""  "  "ަ"  "  "B"  "  "ҧ"  "  "Ȅ"  "  "?ࢀ/" "  " ""  ""  "  ""  "  "	"  "  "?ప" "  " ""  "쾼
"  "  "Δ޶""  "  "?Ж" "  " ""  "Ӗ"  "  ""  "  "?" "  " ""  "	"  "  "˫"  "  ""  "  "?̥
" "  " ""  "ǌ
"  "  ""  "  "?%" "  " ""  "ײ"  "  ""  "  "?" "  " ""  "ܒ"  "  "?ȵl" "  " ""  "˵Ѝ"  "  "ʼǶ"  "  "ؖA"  "  "ƪ"  "  ""  "  "("  "  "?" "  " ""  ""  "  "&"  "  "?Ŵ!" "  " ""  ""  "  "ʀņ"  "  "͓Γ"  "  ""  "  ""  "  "!"  "  "෯؟"  "  "9ڽ" " ""  yo
tf_Compute"=!" "  " ""  "!"  "  "=຺!ๆ" "  " ""  "!"  "  "=ࠐ!" "  " ""  "੊!6"  "  "=κ!ǽ" "  " ""  "Ө!ఌ"  "  "=!" "  " ""  "!I"  "  "=̅!" "  " ""  "!C"  "  "="" "  " ""  "Ɂ"U"  "  "="" "  " ""  "Ã"6"  "  "="" "  " ""  ""C"  "  "="ǽ" "  " ""  "ˎ"g"  "  "="݌" "  " ""  """  "  "="" "  " ""  ""U"  "  "=Һ"" "  " ""  ""["  "  "=Ӿ"" "  " ""  ""6"  "  "="˘" "  " ""  "ө"C"  "  "="൫" "  " ""  """  "  "="ࣷ" "  " ""  ""g"  "  "="" "  " ""  ""ఌ"  "  "="" "  " ""  ""I"  "  ">#" "  " ""  "ں#"  "  "%޲"  "  "%"  "  "%
"  "  ">%ίu" "  " ""  "%P"  "  "ɋv
"  "  "姃"  "  "
"  "  "?" 䗷"  " "䗷" "ՠ" "  ">Ʌ$" 䗷"  " "䗷" "Ї" "  ">@" 䗷"  " "䗷" "譡8" "  "9" 䗷" "䗷" "?" "  " ""  "߃"  "  ""  "  "Ю"  "  ""  "  "&"  "  "ସ"  "  "?سL" "  " ""  "Ҷ4"  "  ""  "  "Λ"  "  ""  "  "@狍߮" "  " ""  "ፍ"  "  ""  "  "ǚٳ"  "  "κ"  "  "֡	"  "  "Կ"  "  "č"  "  ""  "  "ȯɹ"  "  "Ο"  "  "˵"  "  ""  "  "਋"  "  "ߢڝ"  "  "ͷ"  "  "ѩ"  "  ""  "  ""  "  ""  "  "Νǰ"  "  "??" "  " ""  ""  "  ""  "  "ފ"  "  "ǐ"  "  "؅"  "  ""  "  "?R" "  " ""  ""  "  ""  "  ""  "  "۝"  "  ""  "  "ʋ"  "  ""  "  "ࡌ"  "  "౿ű"  "  "▿"  "  ""  "  "콂"  "  ""  "  "᧋І"  "  ""  "  "î"  "  "Ŧ	"  "  "@" "  " ""  ""  "  "֝"  "  "ൺ"  "  "ƈ೿ "  "  "Ԇի	"  "  "͇
"  "  "ఐహ"  "  ""  "  "ː޼ؼ"  "  ""  "  "Խ"  "  "ʻ"  "  ""  "  "ݕ"  "  "ع"  "  "ϯ"  "  "І"  "  "ࣷ"  "  "ܴƦ"  "  ""  "  "?<" "  " ""  "Ɋ"  "  "⬢"  "  "ߧ"  "  "˕"  "  "Ħ"  "  "酖"  "  "?	V" "  " ""  "	ܕ"  "  "
"  "  "֝
Ư"  "  "ڊ
"  "  "汖
"  "  "
"  "  "«
"  "  "
"  "  "
"  "  "ׯ
ᡸ"  "  "Ʋ
"  "  "
"  "  "ô
"  "  "ݚ
"  "  "Ş
ࣷ"  "  "깡
"  "  "͂
"  "  "?
S" "  " ""  "࣏
"  "  "
"  "  "ߗ"  "  "> " "  " ""  "٢"  "  "ۍ"  "  "?" "  " ""  "Å:"  "  ""  "  "ƈ"  "  "Ƌ"  "  "="  "  "m"  "  "8"  "  "ΧΆ"  "  "ӆإ"  "  "ǒ "  "  ""  "  ">ۊ+" "  " ""  ""  "  ""  "  "Ŝ͠"  "  ""  "  "貓଱"  "  ">Üh" "  " ""  "E"  "  ""  "  ">Æ" "  " ""  ""  "  ""  "  ">ķ'" "  " ""  ""  "  "	"  "  ">Ǹ" "  " ""  ""  "  "ͧո
"  "  "?" "  " ""  "A"  "  "݂೨"  "  ">ɞ" "  " ""  ""  "  "ݧ"  "  ">d" "  " ""  "&"  "  "秗2"  "  ">#" "  " ""  ""  "  "
"  "  ""  "  "?" "  " ""  "Ó"  "  ""  "  ""  "  "ƃ"  "  ""  "  "ۏ,"  "  ""  "  "ܠ"  "  ""  "  ""  "  ">׊:" "  " ""  "ˌ"  "  ""  "  ""  "  ""  "  "ǌ"  "  ">R" "  " ""  "ͷ"  "  "
"  "  "	"  "  "
"  "  "ๆ"  "  ""  "  "ܑ"  "  ""  "  ">覘" "  " ""  "љ"  "  ""  "  ">Ș$" "  " ""  "	"  "  "ݎ"  "  ""  "  "?" "  " ""  ""  "  ""  "  ""  "  ""  "  "$"  "  ""  "  "	"  "  "ۤ"  "  ""  "  "Ғ"  "  "ϲ"  "  "<"  "  ""  "  ""  "  "̜ǌ"  "  "ͪX"  "  "냆"  "  ""  "  ">Z" "  " ""  ""  "  ""  "  ""  "  ""  "  "݌"  "  ">r" "  " ""  "1"  "  ""  "  "ɭ
"  "  "ෳ"  "  "ñ"  "  "Ã"  "  ""  "  ""  "  ">&" "  " ""  "養˜"  "  "ڤ	"  "  ">˷J" "  " ""  "༬౅"  "  ""  "  ""  "  "?" "  " ""  ""  "  ""  "  "إݽ"  "  ""  "  "ʾ&"  "  "ؠ"  "  "E"  "  "޳"  "  "ڼ"  "  "C"  "  "0"  "  ""  "  "C"  "  "="  "  "ϙ;"  "  ""  "  "?߮" "  " ""  "׾"  "  ">ʸ" "  " ""  "ǽ"  "  "১"  "  ">޲" "  " ""  "̢"  "  "ά"  "  ">2" "  " ""  "ϛĈ"  "  "ث"  "  "ȶ"  "  "ɿ"  "  ""  "  "؞"  "  ">" "  " ""  "Œ"  "  "ٚ̾	"  "  "?" "  " ""  "ۦ"  "  ">׏" "  " ""  ""  "  "?" "  " ""  " "  "  "˧"  "  "ƭЧڐ="  "  "㏨a"  "  "ꗨ޲"  "  "	"  "  "?" "  " ""  "鱨B"  "  "۫
"  "  "?" "  " ""  "$"  "  "╴"  "  ""  "  ""  "  "Ӵ"  "  ""  "  "?ǰ!" "  " ""  "Ҹ"  "  "@֘Й" "  " ""  "ә"  "  ""  "  "ͣ"  "  "Ӎ՚"  "  "羻"  "  "唔"  "  ""  "  ""  "  ""  "  ""  "  ""  "  "ܖ"  "  "궿"  "  "բ"  "  "@΃ɜ" "  " ""  "ˊ"  "  "狺"  "  ""  "  ""  "  ""  "  ""  "  "߹"  "  "G"  "  "嵻
"  "  ""  "  "?Ū۟" "  " ""  ""  "  ""  "  "?" "  " ""  ""  "  "?Ϛ2" "  " ""  ""  "  ""  "  ""  "  "ӣӰ"  "  "ࠠ
"  "  ""  "  ""  "  "廒ܕ"  "  "?״(" "  " ""  "ஃ"  "  ""  "  "?ˣ" "  " ""  ""  "  ""  "  "?߇<" "  " ""  ""  "  "ݼ"  "  "͹"  "  "Ϋ"  "  "ࢨ"  "  ""  "  "ɼ"  "  ""  "  "?̓" "  " ""  "Ѯ"  "  "⫌С5"  "  "?" "  " ""  ""  "  ""  "  "?Ҍ" "  " ""  "§ဤ"  "  "="  "  "?" "  " ""  "»"  "  "׌"  "  "?	" "  " ""  "	"  "  "?0" "  " ""  "̹"  "  ""  "  "Է"  "  "ɅȊ"  "  "ត"  "  "༿"  "  ""  "  "ȗ"  "  "?Ʋଗ" "  " ""  "Ȳ"  "  "ʥ,"  "  "?" "  " ""  "യ"  "  "ɔ"  "  "?
" "  " ""  "ȼ
"  "  "͉"  "  b,
tf_Compute"=!	" "  " ""  "!"  "  "=!" "  " ""  "!U"  "  "=!" "  " ""  "!a"  "  "=!" "  " ""  "!˘"  "  "=!؞" "  " ""  "ଡ!C"  "  "=!" "  " ""  "!O"  "  "=!؞" "  " ""  "!C"  "  "=!" "  " ""  "	!O"  "  "=!" "  " ""  "	ԙ!U"  "  "=!" "  " ""  "	́!C"  "  "=!" "  " ""  "	!="  "  "=!ఌ" "  " ""  "	!="  "  "=!" "  " ""  "	!I"  "  "=!ఌ" "  " ""  "	!6"  "  "=!ǌ" "  " ""  "	!C"  "  "=!" "  " ""  "	!a"  "  "=!" "  " ""  "	!U"  "  "=!" "  " ""  "	!I"  "  "=ԝ!" "  " ""  "	!I"  "  "=!" "  " ""  "	!U"  "  "="" "  " ""  "	"U"  "  "="" "  " ""  "	"I"  "  "="" "  " ""  "	"I"  "  "="" "  " ""  "	"O"  "  "=Ǜ"" "  " ""  "	Ƙ"ఌ"  "  "=࠯"؞" "  " ""  "	"U"  "  "="" "  " ""  "	""  "  "="" "  " ""  "	"C"  "  "="" "  " ""  "	Ƹ"O"  "  "="" "  " ""  "	ƻ"I"  "  "=ٿ"" "  " ""  "	"I"  "  "="" "  " ""  "	"C"  "  "="" "  " ""  "	"["  "  "="" "  " ""  "	"m"  "  "?˝#ĩѥ" "  " ""  "	Ɵ#y"  "  "	"  "  "	"  "  "	؀	"  "  "?" "  " ""  "	ޅ"  "  "	ϝ̾	"  "  "	"  "  "	"  "  ">-" "  " ""  "	л"  "  "	"  "  "	s"  "  ">8" "  " ""  "	"  "  "	Й"  "  "	"  "  "	"  "  "	"  "  "	="  "  "?
ةm" "  " ""  "	Ȼ
"  "  "	
ز*"  "  "	"  "  "	"  "  "	Լ+"  "  "	ヽg"  "  "	̾"  "  ">6" "  " ""  "	Ə"  "  "	"  "  "	"  "  "	"  "  "	ϒs"  "  ">" "  " ""  "	"  "  "	"  "  ">ר" "  " ""  "	"  "  "	"  "  ">" "  " ""  "	"  "  ">"" "  " ""  "		"  "  "	"  "  "	ђ"  "  "?ù" "  " ""  "	镜"  "  "	"  "  "	"  "  "	Ȫ"  "  "	۬"  "  "	"  "  "	["  "  "	ߣ"  "  "	θδ\"  "  "	͙ڔT"  "  "	̒k"  "  "	"  "  "	?"  "  "	ڵ"  "  "	"  "  "	ʩ"  "  "	Խ+"  "  "	ߌ
"  "  "	͠"  "  ">Í0" "  " ""  "	󽐂"  "  "	"  "  "	Ĉ"  "  "	ᰂո
"  "  "	ꚼ"  "  ">9" "  " ""  "	"  "  "	т଱"  "  "	ǫւ
"  "  "	
"  "  "	s"  "  "	ଅ"  "  "	"  "  "	"  "  ">" "  " ""  "	"  "  "	൴"  "  ">'" "  " ""  "	千"  "  "	Ε"  "  "	"  "  "?ഃ" "  " ""  "		"  "  "	Ãٱ"  "  "	ʃ"  "  "	΃"  "  "	׃+"  "  "	℄؞"  "  "	ↄ7"  "  "	0"  "  "	ҝ"  "  "?Ʈ݄" "  " ""  "	"  "  "	Ç"  "  ">ڒर " "  " ""  "	ݒ"  "  "	"  "  ">Н" "  " ""  "	"  "  "	ޟ"  "  ">[" "  " ""  "	"  "  "	"  "  "	"  "  "	ʓ"  "  "	ލۓ˘"  "  "	ܓ"  "  "	"  "  "	s"  "  "?" "  " ""  "	"  "  "	Ơ؞"  "  "	󠃔"  "  "	󳇔"  "  "
"  "  "
弗ΰE"  "  "
"  "  "
+"  "  "
"  "  "
ƕ"  "  ">5" "  " ""  "
	"  "  "
"  "  "
"  "  "
ª"  "  "
ʔ"  "  ">ЗA" "  " ""  "
ј"  "  "
ࣩ"  "  "
έ"  "  "
ⶖ"  "  "
Ŗ"  "  "
ǖ"  "  "
͖"  "  "
Ֆ"  "  ">ཱྀݖ " "  " ""  "
ޖ"  "  "
"  "  ">" "  " ""  "
"  "  "
ƿಔ"  "  "
֯"  "  "?%" "  " ""  "
ܒ"  "  "
	"  "  "
ȸ"  "  "
󋼗	"  "  "
ȗ"  "  "
І"  "  "
 "  "  "
ђy"  "  "
]"  "  "
༻6"  "  "
๎"  "  "
ҳ"  "  "
ఌ"  "  "
ǮŠ
"  "  "
ה"  "  "
G"  "  "
"  "  "
"  "  ">ŮY" "  " ""  "
"  "  "
¼"  "  "
ټ"  "  "
ࠠ
"  "  "
샽"  "  ">n" "  " ""  "
В3"  "  "
ƾ"  "  "
ƽ"  "  "
ҽॿ"  "  "
"  "  "
"  "  "
"  "  "
"  "  ">*" "  " ""  "
"  "  "
﷚Ó"  "  ">9" "  " ""  "

"  "  "
ʺ"  "  "
̾"  "  "?޾" "  " ""  "
߾%"  "  "
"  "  "
旿"  "  "
ė"  "  "
ůͷ'"  "  "
ڿ"  "  "
޿@"  "  "
O"  "  "
ܳ$"  "  "?Ѳ" "  " ""  "
N"  "  "
ǯ"  "  ">֬" "  " ""  "
ܰ"  "  "?Θ" "  " ""  "
"  "  "
"  "  ">" "  " ""  "
"  "  ">୔R" "  " ""  "
"  "  "
"  "  "
"  "  "
Θޟ"  "  "
ܠ"  "  "
ྥ"  "  "?" "  " ""  "
"  "  "
"  "  ">]" "  " ""  "
D"  "  "
"  "  ">"" "  " ""  "
ǂ"  "  ">䠄-" "  " ""  "
	"  "  "
ڭ"  "  "
	"  "  "
˄"  "  ">΄6" "  " ""  "
τӃ"  "  "
է"  "  "
"  "  "
"  "  "
ׁ"  "  "
֠"  "  ">݅" "  " ""  "
ޅ	"  "  "
	"  "  "?Ȏ" "  " ""  "
 "  "  "
"  "  "
ɪ"  "  "
ࠍڅ"  "  "
⤎X"  "  "
8"  "  "
伏	"  "  "
Ə"  "  "
"  "  "
"  "  "
"  "  "
૖Λ2"  "  "
	"  "  "
"  "  "
"  "  ">ģ" "  " ""  "
"  "  "
ǳ"  "  "?Ī" "  " ""  "
ນȪG"  "  "
"  "  "
"  "  "
"  "  "
Ӡ["  "  "
٢"  "  "
P"  "  "
"  "  "
ꉇ	"  "  "
풬Ħ"  "  "?㠬" "  " ""  "
."  "  "
Ҭ"  "  Gv
tf_Compute"=!" "  " ""  "!"  "  "=!Ԓ" "  " ""  "!["  "  "=!" "  " ""  "!C"  "  "="݌" "  " ""  ""m"  "  "=঒"ñ" "  " ""  ""z"  "  "=ि"" "  " ""  ""U"  "  "="" "  " ""  ""a"  "  "="ǽ" "  " ""  """  "  "="" "  " ""  "܍"C"  "  "?#⻗" "  " ""  "໦#Ŏc"  "  "ޔ	"  "  "ٞ"  "  ""  "  "?պƀ<" "  " ""  "ٺ!"  "  "ǳ"  "  ""  "  "Ǫ"  "  "?֒ " "  " ""  ""  "  ""  "  ""  "  "?߰S" "  " ""  "	"  "  "ൺ"  "  "梾"  "  "Ύø
"  "  ""  "  "ɭ¯"  "  ""  "  "Ƚ"  "  ""  "  "Ó"  "  ""  "  "Ċ"  "  "ѣ"  "  "ǝ"  "  ""  "  ""  "  "࣠߱	"  "  "@ː" "  " ""  "͐"  "  "݅"  "  ""  "  "Ϣ"  "  ""  "  "Ǩ"  "  "Ǘ"  "  "ċ"  "  ""  "  "ो"  "  "Ѓ"  "  "ҋˮդ"  "  ""  "  "ϰ¬"  "  "߸"  "  "ھൈ"  "  ""  "  ""  "  ""  "  ""  "  "?٭=" "  " ""  "ٯ"  "  "ܛ̧"  "  "㊞࡞"  "  ""  "  ""  "  "ئ๧"  "  "?恦U" "  " ""  "⦨"  "  ""  "  "挠"  "  "
"  "  "ጵ"  "  ""  "  "漋"  "  "í"  "  "ȡ"  "  ""  "  ""  "  ""  "  "Ԁ"  "  "$"  "  "٨"  "  "डߨ˪"  "  "Տ
"  "  "@ӎ泖" "  " ""  ""  "  "˵"  "  ""  "  "К "  "  "̷	"  "  "	Ϯ"  "  "	"  "  "	"  "  "ԫ	"  "  "	"  "  "	Ʀ"  "  "	Σ"  "  "	"  "  "Ϯ	"  "  "	"  "  "	"  "  "͵	଱"  "  "	"  "  "	"  "  "	ّ"  "  "@
՗" "  " ""  "
"  "  "
̩"  "  "
"  "  "
؟E"  "  "荂"  "  "Ų"  "  "ٻ"  "  ""  "  "ܶ"  "  "ͅ"  "  "٣"  "  "݌"  "  "
"  "  "嚠"  "  "ɻ"  "  "I"  "  "["  "  ""  "  "ѹ"  "  ">" "  " ""  "¹"  "  "۪"  "  "I"  "  "?Ȫ" "  " ""  "ʪ"  "  "ٱ"  "  "ϜC"  "  "ː!"  "  "="  "  "	"  "  ""  "  "*"  "  ""  "  "ā"  "  "ܔ"  "  ""  "  "塋Շ	"  "  "ڔ"  "  "ϝ"  "  "˦*"  "  "*"  "  "ݧ"  "  ""  "  "?՟" "  " ""  "
"  "  ""  "  "ไ"  "  "0"  "  "2"  "  ""  "  "#"  "  ""  "  "ـ"  "  ""  "  "΂"  "  "
"  "  "ѡ"  "  "6"  "  "ͤ*"  "  "驧"  "  "в"  "  ">>" "  " ""  ""  "  "׀#"  "  ""  "  "?" "  " ""  "ǽ"  "  "Æ"  "  "%"  "  ""  "  ""  "  ""  "  ""  "  ">Ր6" "  " ""  "ܪ""  "  "
"  "  ""  "  ">U" "  " ""  "4"  "  "ߓ๻"  "  ">Ʈ" "  " ""  ""  "  ""  "  ">" "  " ""  "
"  "  "
"  "  "?ʤ٪" "  " ""  ""  "  "󥪒"  "  ">麹 " "  " ""  "Ӝ"  "  "ђ"  "  ">ےW" "  " ""  "ܒ5"  "  ""  "  ">*" "  " ""  ""  "  "˓"  "  "ݓ"  "  ">
" "  " ""  "ᙔ"  "  ""  "  "?܈" "  " ""  "௡"  "  ""  "  "?" "  " ""  ""  "  "Ժ̍"  "  ">ӏ" "  " ""  "Ԅ"  "  "ġ"  "  ">켐f" "  " ""  "@"  "  "ö "  "  "?Ҿ" "  " ""  ""  "  "?౗2" "  " ""  "ڼ"  "  "ّ"  "  "כ"  "  ""  "  ">ƢΛ+" "  " ""  "ћ"  "  "ߔ"  "  ">ս" "  " ""  "ɧ"  "  ">茍1" "  " ""  "֎"  "  "겕"  "  "짝"  "  "䈼"  "  "?ƿמ	" "  " ""  "	"  "  "ܣ"  "  "?" "  " ""  "ƪǟ"  "  ""  "  ">" "  " ""  "ǒ"  "  ""  "  "
tf_Compute"=!
" "  " ""  "!m"  "  "=Ȣ!Ԓ" "  " ""  "!O"  "  "?#" "  " ""  "#Ԫ6"  "  "ޞY!"  "  "ȁ"  "  "൭ʝ!"  "  "?" "  " ""  ""  "  ""  "  "ו"  "  "ӟ"  "  "?
̬p" "  " ""  "Ր
5"  "  "׋Ϣ"  "  "츆๧$"  "  ">̚" "  " ""  "z"  "  "ߟ؞"  "  ">ʉ" "  " ""  ""  "  "݌"  "  ">חB" "  " ""  "	"  "  ""  "  "Ϥµ"  "  "ڮȁ	"  "  "I"  "  ""  "  "Ľg"  "  "m"  "  "?ȿ" "  " ""  "ٱ"  "  ""  "  ""  "  ""  "  ""  "  "."  "  ""  "  "&"  "  "ࣷ"  "  "ǽ"  "  ">4" "  " ""  "	"  "  ""  "  "	"  "  ""  "  ""  "  ""  "  "g"  "  "ʛ"  "  ">Ʀ	" "  " ""  ""  "  ""  "  "?$" "  " ""  "ܪ"  "  ""  "  "ڣ"  "  "2"  "  ">" "  " ""  "ࣆ"  "  "
"  "  "?" "  " ""  "ଣ<"  "  "Ũ"  "  "آ"  "  ""  "  "
"  "  ">A" "  " ""  "ӳ"  "  ""  "  "ܱਗ਼"  "  ""  "  "m"  "  ""  "  ""  "  ""  "  ">" "  " ""  "ـ"  "  ""  "  "?Ȩø	" "  " ""  ""  "  ""  "  "?ࡔ" "  " ""  ""  "  ""  "  "?֛௴" "  " ""  "ڛɎ"  "  "
"  "  "?ٍ" "  " ""  "쒧ڵ"  "  "?" "  " ""  "ƛ"  "  "?" "  " ""  "ő"  "  "Ԁ	"  "  "-"  "  "?誅" "  " ""  "೎"  "  "ߪ"  "  "?̈́ω" "  " ""  "҄"  "  " "  "  "?ٽƝ" "  " ""  ""  "  "ނ("  "  "?	" "  " ""  ""  "  "ҡ"  "  "?Ԗś#" "  " ""  "δז"  "  "?ƀ" "  " ""  "ଙż"  "  ;k
tf_Compute"=!
" "  " ""  "!"  "  "=!" "  " ""  "!m"  "  "=!" "  " ""  "!a"  "  "=!" "  " ""  "!ఌ"  "  "=˹!ๆ" "  " ""  "!a"  "  "=!ఌ" "  " ""  "١!6"  "  "=!˘" "  " ""  "!="  "  "=!" "  " ""  "!"  "  "=!" "  " ""  "!m"  "  "=!" "  " ""  "ⶁ""  "  "="" "  " ""  ""["  "  "="" "  " ""  """  "  "=ȣ"ๆ" "  " ""  "դ"O"  "  "="" "  " ""  "܌"I"  "  "="" "  " ""  ""s"  "  "?#" "  " ""  "#l"  "  "̯
"  "  "ۯ"  "  "©"  "  "?ղ" "  " ""  ""  "  ""  "  "	"  "  "خ"  "  ""  "  "ϛ"  "  ""  "  "؞"  "  "?Ѧ" "  " ""  ""  "  ""  "  "0"  "  "ݧ5"  "  "C"  "  "ȁ	"  "  "௲,"  "  "I"  "  "ަ"  "  ""  "  "ǅ"  "  ""  "  ""  "  "ė"  "  "	"  "  "ᑰm"  "  "±I"  "  "²"  "  "଱"  "  "?
m" "  " ""  "
 "  "  "
-"  "  "巤"  "  ">Ңл" "  " ""  ""  "  "Շ	"  "  "?" "  " ""  "8"  "  "ę۟"  "  "?ô" "  " ""  "D"  "  ""  "  "ཏ;"  "  "?" "  " ""  "R"  "  "ދˍ"  "  ">$" "  " ""  ""  "  "Ӓ	"  "  ">" "  " ""  "ੇ"  "  "?" "  " ""  ""  "  "?̮-" "  " ""  "ή
"  "  "ʌ"  "  "਑	"  "  "ޘ"  "  ">Ǎ-" "  " ""  ""  "  "⮱"  "  "?ɼȹ" "  " ""  ""  "  ">~" "  " ""  "
"  "  ""  "  "ଷ"  "  "鹝̾	"  "  "ӝ"  "  ""  "  ">-" "  " ""  "ٸ"  "  "
"  "  "݌"  "  "ʝ"  "  "颞˘"  "  "؞"  "  "?" "  " ""  "#"  "  "ў"  "  "؞བ"  "  "൫"  "  ""  "  "X"  "  ""  "  ">ԡ0" "  " ""  "Ϫ'"  "  "?ӳ*" "  " ""  "جԳ"  "  ""  "  "ʮു"  "  "?:" "  " ""  ""  "  ""  "  ""  "  "魊Ư"  "  ""  "  "ວ"  "  "ݤ"  "  "˙ฺ"  "  "?˹ࢺ" "  " ""  "ࣉ"  "  "ƿҡ"  "  "?׿&" "  " ""  "鳀"  "  ""  "  "?3" "  " ""  "˂"  "  ""  "  ""  "  "ꨎ"  "  "ìૢ"  "  ""  "  ""  "  ""  "  "?Լ" "  " ""  "ђ"  "  "$"  "  "?" "  " ""  ""  "  "Ӗ!"  "  "?" "  " ""  "þ"  "  ""  "  "?ţ" "  " ""  ""  "  "׺"  "  "?梽" "  " ""  "ٳ"  "  ""  "  "?Ԏ" "  " ""  "ϰ"  "  "?ϗڄm" "  " ""  "җļ"  "  "ᔜ"  "  ""  "  "ͩ"  "  "䤭"  "  "俲"  "  "Ʈ"  "  "Ӗ"  "  ""  "  ""  "  ""  "  "נ"  "  ""  "  "܃ڴ"  "  "?諭" "  " ""  "ۇ"  "  "ꯎֈ"  "  "ז"  "  "?ļ+" "  " ""  "Վ"  "  ""  "  "ȣ"  "  "ᴬ"  "  "񀨰"  "  "ĵ"  "  ";"  "  "?؈" "  " ""  ""  "  "?(" "  " ""  ""  "  "ѹ"  "  ""  "  ""  "  5tf_data_iterator_get_next"*"˴" "  "  "#Ҟ"" ҂x"  "B߅&̍" ãȤ"
 ҂x"8"8" "  "ۻ&m" "  Wtf_data_iterator_resource"Y " 	"*Y" Ԣ"
 ãȤ"+Y" ¢ԋ"
 Ԣ"+
Y݌" "
 ¢ԋ"*Y
" Ҥa"
 Ԣ"*ȵY" ҡ"
 Ҥa"+Y" ҡ"
 Ҥa"Y" 䗷"8Y" 䗷" "䗷" "zEvEjgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_35/Tensordot/MatMul/MatMul:MatMul"MatMul"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_2/Mul:Mul"Mul"c^Tgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_12/dropout/Mul_2:Mul"Mul"zfmodel/transformer/encoder/encoder_layer_1/dropout_2/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"e`Vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/mul:Mul"Mul"b]Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/mean:Mean"Mean"a\Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/sub:Sub"Sub"a\Ogradient_tape/model/transformer/decoder/dense_26/Tensordot/MatMul/MatMul:MatMul"MatMul"zfmodel/transformer/encoder/encoder_layer_2/dropout_4/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"WRHmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/sub:Sub"Sub"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/sub:Sub"Sub"U	P	8Adam/Adam/update_170/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/sub/Sum:Sum"Sum"+&Adam/gradients/AddN_40:AddN"AddN"c^Tgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_20/dropout/Mul_2:Mul"Mul"`[Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/truediv_1:Mul"Mul"Adam/Pow_1:Pow"Pow"rgngegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul/Mul_1:Mul"Mul"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/Tensordot/MatMul/MatMul_1:MatMul"MatMul"oj`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/mul_1:Mul"Mul"mgradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_24/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"+&Adam/gradients/AddN_50:AddN"AddN"niUmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul:BatchMatMulV2"BatchMatMulV2"TO7Adam/Adam/update_47/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_56/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Qmodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/add:AddV2"AddV2"UP8Adam/Adam/update_155/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lgYmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/BiasAdd:BiasAdd"BiasAdd"|gmodel/transformer/encoder/encoder_layer_2/sequential_2/dense_17/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/sub:Sub"Sub"

ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"{gmodel/transformer/decoder/decoder_layer_3/dropout_19/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_2/Mul:Mul"Mul"lg]gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/Mul:Mul"Mul"d_Qmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/Softmax:Softmax"Softmax"<7"Adam/ReadVariableOp:ReadVariableOp"ReadVariableOp"YTImodel/transformer/decoder/decoder_layer_3/sequential_7/dense_65/Relu:Relu"Relu"a\Rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/Sum:Sum"Sum"xgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/Tensordot/MatMul/MatMul_1:MatMul"MatMul"zemodel/transformer/encoder/encoder_layer_3/sequential_3/dense_24/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"r
m
cgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_1/Mul:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/truediv_1:Mul"Mul"w
r
hgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_2/Mul_1:Mul"Mul"_ZEmodel/transformer/encoder/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"TOEmodel/transformer/encoder/encoder_layer_2/dropout_4/dropout/Mul_1:Mul"Mul"s
n
_gradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_55/ReluGrad:ReluGrad"ReluGrad"sgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_3/Tensordot/MatMul/MatMul_1:MatMul"MatMul"zjgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"q#m#amodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/Tensordot/MatMul:MatMul"MatMul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul/Mul:Mul"Mul"niVmodel/transformer/decoder/decoder_layer_2/dropout_17/dropout/GreaterEqual:GreaterEqual"GreaterEqual"		omodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"RVNV7Adam/Adam/update_84/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"`[Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_2/Mul:Mul"Mul"QLAmodel/transformer/encoder/encoder_layer/dropout/dropout/Cast:Cast"Cast"mh^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/Mul:Mul"Mul" TFE_DeleteTensorHandle"pkagradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/truediv:Mul"Mul"		omodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"lg]gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/Mul:Mul"Mul"zemodel/transformer/decoder/decoder_layer_2/sequential_6/dense_55/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_2/Sum:Sum"Sum"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/Tensordot/MatMul/MatMul_1:MatMul"MatMul"kfVmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_3:Transpose"	Transpose"vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/Tensordot/MatMul/MatMul:MatMul"MatMul"+&Adam/gradients/AddN_24:AddN"AddN"e`Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/add:AddV2"AddV2"TO7Adam/Adam/update_13/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_1:Mul"Mul"j	e	Wmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/BiasAdd:BiasAdd"BiasAdd")p%pAdam/gradients/AddN_46:AddN"AddN"a\Rgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_12/dropout/Mul:Mul"Mul"toegradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_2/Mul_1:Mul"Mul"oj_gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/Tile:Tile"Tile"FA5model/transformer/decoder/decoder_layer_3/add_1:AddV2"AddV2"kmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"c
^
Tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/mul:Mul"Mul"NI?model/transformer/encoder/encoder_layer/dropout/dropout/Mul:Mul"Mul"j	e	Wmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/BiasAdd:BiasAdd"BiasAdd"UP8Adam/Adam/update_117/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/Tensordot/MatMul/MatMul_1:MatMul"MatMul"}hmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"*	%	Adam/gradients/AddN_6:AddN"AddN"qlbgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/truediv:Mul"Mul"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_89/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_2/Mul:Mul"Mul"
|
lgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"wrhgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_2/Mul_1:Mul"Mul"c^Pmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/Softmax:Softmax"Softmax"vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/Tensordot/MatMul/MatMul:MatMul"MatMul"u
p
fgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul/Sum_1:Sum"Sum"vqggradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_2/Mul_1:Mul"Mul"+&Adam/gradients/AddN_42:AddN"AddN"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul/Sum_1:Sum"Sum"{vbmodel/transformer/encoder/encoder_layer/dropout/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"faUmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/Rsqrt:Rsqrt"Rsqrt"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_1/Mul:Mul"Mul"vqggradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_2/Mul_1:Mul"Mul"e`Umodel/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/variance:Mean"Mean"<<xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/Tensordot/MatMul/MatMul_1:MatMul"MatMul"rm`model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/Tensordot/MatMul:MatMul"MatMul"{ngradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_46/Tensordot/MatMul/MatMul_1:MatMul"MatMul"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/Mul:Mul"Mul"c^Pmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/Softmax:Softmax"Softmax"XS5Iterator::Model::ParallelMapV2::Zip[1]::ForeverRepeat"Iterator::ForeverRepeat"m	h	Umodel/transformer/encoder/encoder_layer_3/dropout_7/dropout/GreaterEqual:GreaterEqual"GreaterEqual"wgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/Tensordot/MatMul/MatMul_1:MatMul"MatMul"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_1/Mul:Mul"Mul"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/Tensordot/MatMul:MatMul"MatMul"|gmodel/transformer/decoder/decoder_layer_2/sequential_6/dense_56/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/sub/Sum:Sum"Sum"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"lgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"UP8Adam/Adam/update_132/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"U
P
8Adam/Adam/update_104/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul:Mul"Mul"u	p	fgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul/Sum_1:Sum"Sum"pMlMcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul/Mul_1:Mul"Mul"|lgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/truediv/Sum:Sum"Sum"E@6model/transformer/decoder/dropout_21/dropout/Mul_1:Mul"Mul"xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/Tensordot/MatMul/MatMul_1:MatMul"MatMul"UP8Adam/Adam/update_123/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"c^Pmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/Softmax:Softmax"Softmax"qlbgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/truediv:Mul"Mul"NI6model/transformer/encoder/strided_slice_4:StridedSlice"StridedSlice"0+!model/transformer/decoder/Min:Min"Min"c^Pmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/Softmax:Softmax"Softmax"		qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"pkagradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/truediv:Mul"Mul"+&Adam/gradients/AddN_37:AddN"AddN"UP8Adam/Adam/update_141/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"niUmodel/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul_1:BatchMatMulV2"BatchMatMulV2"UP8Adam/Adam/update_129/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"topoggradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_2/Mul_1:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_1/Mul:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul/Sum_1:Sum"Sum"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_2/Mul:Mul"Mul"UPFmodel/transformer/decoder/decoder_layer_2/dropout_16/dropout/Mul_1:Mul"Mul"S	N	Cmodel/transformer/decoder/decoder_layer/dropout_9/dropout/Cast:Cast"Cast"[VLmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/truediv:Mul"Mul"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"mhUmodel/transformer/encoder/encoder_layer_3/dropout_6/dropout/GreaterEqual:GreaterEqual"GreaterEqual"PKAmodel/transformer/encoder/encoder_layer/dropout_1/dropout/Mul:Mul"Mul"FA5model/transformer/decoder/decoder_layer_1/add_2:AddV2"AddV2"e
`
Vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/mul_1:Mul"Mul"{gmodel/transformer/decoder/decoder_layer_1/dropout_12/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"		pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/sub/Sum:Sum"Sum"TO7Adam/Adam/update_22/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/SquaredDifference:SquaredDifference"SquaredDifference"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"e`Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/add:AddV2"AddV2"72-TensorHandle::GetResourceHandleInfo WaitReady"TO7Adam/Adam/update_29/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"FA6model/transformer/decoder/dropout_21/dropout/Cast:Cast"Cast"m
h
]gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/Tile:Tile"Tile"UP8Adam/Adam/update_130/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"m
h
^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/sub:Sub"Sub"UPEmodel/transformer/encoder/encoder_layer_3/dropout_6/dropout/Cast:Cast"Cast"s
n
dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/truediv_1:Mul"Mul"kmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"++ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"*%Adam/gradients/AddN_1:AddN"AddN"niVmodel/transformer/decoder/decoder_layer_3/dropout_18/dropout/GreaterEqual:GreaterEqual"GreaterEqual"		omodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"t^p^ggradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_1/Mul_1:Mul"Mul"b]Smodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_2:Mul"Mul"b]Sgradient_tape/model/transformer/encoder/encoder_layer_2/dropout_5/dropout/Mul_2:Mul"Mul"~jgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"UP8Adam/Adam/update_150/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"% EagerLocalExecute: Identity"	|	gmodel/transformer/encoder/encoder_layer_3/sequential_3/dense_24/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"}xcmodel/transformer/decoder/decoder_layer/sequential_4/dense_35/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_25:AddN"AddN"xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/Tensordot/MatMul/MatMul_1:MatMul"MatMul"d_Pmodel/transformer/decoder/decoder_layer/multi_head_attention_5/SelectV2:SelectV2"SelectV2"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_2/Mul:Mul"Mul"UP8Adam/Adam/update_122/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"idWmodel/transformer/decoder/decoder_layer_3/sequential_7/dense_66/Tensordot/MatMul:MatMul"MatMul"d_Mgradient_tape/model/transformer/encoder/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"b]Omodel/transformer/decoder/decoder_layer_1/sequential_5/dense_46/BiasAdd:BiasAdd"BiasAdd"u	p	fgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_2/Sum:Sum"Sum"RxNx7Adam/Adam/update_40/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qlbgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/truediv/RealDiv:Mul"Mul"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_31/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_2:Mul"Mul"0+!model/transformer/encoder/Cos:Cos"Cos"T
O
7Adam/Adam/update_73/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"|lgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose/transpose:Transpose"	Transpose"a	\	Nmodel/transformer/decoder/decoder_layer/multi_head_attention_5/Softmax:Softmax"Softmax"|gmodel/transformer/decoder/decoder_layer_1/sequential_5/dense_45/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_121/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"oj`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/mul_1:Mul"Mul"C?5model/transformer/encoder/dropout_8/dropout/Cast:Cast"Cast"TO7Adam/Adam/update_75/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"U
P
8Adam/Adam/update_142/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"mh^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/sub:Sub"Sub"kmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/SquaredDifference:SquaredDifference"SquaredDifference"ni_gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/mul_1:Mul"Mul"

lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"xgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/Tensordot/MatMul/MatMul_1:MatMul"MatMul"+&Adam/gradients/AddN_44:AddN"AddN"gbXgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/mul_1:Mul"Mul"~ngradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_2/transpose:Transpose"	Transpose"kfVmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_2:Transpose"	Transpose"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_2:Mul"Mul"UP8Adam/Adam/update_158/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"niUmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul:BatchMatMulV2"BatchMatMulV2"omodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"kfVmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_3:Transpose"	Transpose"TO7Adam/Adam/update_79/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"+&Adam/gradients/AddN_19:AddN"AddN"
~
jgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"lmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/SquaredDifference:SquaredDifference"SquaredDifference"zemodel/transformer/encoder/encoder_layer_2/sequential_2/dense_18/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"U	P	8Adam/Adam/update_168/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ni_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul/Sum:Sum"Sum"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/Tensordot/MatMul/MatMul:MatMul"MatMul"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/Rsqrt:Rsqrt"Rsqrt"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul/Sum:Sum"Sum"a\Gmodel/transformer/encoder/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"vqggradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_1/Mul_1:Mul"Mul"kmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/SquaredDifference:SquaredDifference"SquaredDifference"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/Tensordot/MatMul/MatMul_1:MatMul"MatMul"omodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"&&wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/Tensordot/MatMul/MatMul:MatMul"MatMul"~
y
lgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_36/Tensordot/MatMul/MatMul_1:MatMul"MatMul"?:+model/transformer/decoder/concat_1:ConcatV2"ConcatV2"		lmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"UUvgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/Tensordot/MatMul/MatMul_1:MatMul"MatMul"UP8Adam/Adam/update_120/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"YTJmodel/transformer/decoder/decoder_layer/multi_head_attention_4/truediv:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/sub/Neg:Neg"Neg"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/SquaredDifference:SquaredDifference"SquaredDifference"sn_gradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_65/ReluGrad:ReluGrad"ReluGrad"`[Mmodel/transformer/decoder/decoder_layer/sequential_4/dense_35/BiasAdd:BiasAdd"BiasAdd"ni\model/transformer/encoder/encoder_layer/multi_head_attention/dense_1/Tensordot/MatMul:MatMul"MatMul"lmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/SquaredDifference:SquaredDifference"SquaredDifference"	|	gmodel/transformer/encoder/encoder_layer_1/sequential_1/dense_11/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"gbXgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/mul_1:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_2/Mul:Mul"Mul"UP8Adam/Adam/update_114/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"c^Smodel/transformer/decoder/decoder_layer/layer_normalization_9/moments/variance:Mean"Mean"e`Umodel/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/variance:Mean"Mean"idWmodel/transformer/decoder/decoder_layer_1/sequential_5/dense_46/Tensordot/MatMul:MatMul"MatMul"zu`model/transformer/encoder/encoder_layer/sequential/dense_6/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"wwxgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/Tensordot/MatMul/MatMul_1:MatMul"MatMul"~ylgradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_23/Tensordot/MatMul/MatMul:MatMul"MatMul"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"b]Sgradient_tape/model/transformer/encoder/encoder_layer_1/dropout_2/dropout/Mul_2:Mul"Mul"c^Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_1:Mul"Mul"q	l	_model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/Tensordot/MatMul:MatMul"MatMul"D?3model/transformer/encoder/encoder_layer_1/add:AddV2"AddV2"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/sub/Sum:Sum"Sum"SNDmodel/transformer/encoder/encoder_layer/multi_head_attention/sub:Sub"Sub"+&Adam/gradients/AddN_49:AddN"AddN"^YOmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_2:Mul"Mul"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/Tensordot/MatMul:MatMul"MatMul"T
O
7Adam/Adam/update_91/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"4/#model/transformer/encoder/add:AddV2"AddV2"omodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"D?3model/transformer/encoder/encoder_layer_2/add:AddV2"AddV2"`[Qgradient_tape/model/transformer/encoder/encoder_layer/dropout_1/dropout/Mul_2:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/sub/Neg:Neg"Neg"zemodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"E@2model/transformer/decoder/dense_26/BiasAdd:BiasAdd"BiasAdd"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_2/Mul:Mul"Mul"rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_3/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"idTmodel/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_1:Transpose"	Transpose"]XJmodel/transformer/encoder/encoder_layer/sequential/dense_6/BiasAdd:BiasAdd"BiasAdd"~ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_1/transpose:Transpose"	Transpose"c
^
Tgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_15/dropout/Mul_2:Mul"Mul"_ZLmodel/transformer/encoder/encoder_layer/multi_head_attention/Softmax:Softmax"Softmax"m
h
^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/Mul:Mul"Mul"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_55:AddN"AddN"33xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/Tensordot/MatMul/MatMul_1:MatMul"MatMul"UP8Adam/Adam/update_146/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"niVmodel/transformer/decoder/decoder_layer_1/dropout_13/dropout/GreaterEqual:GreaterEqual"GreaterEqual"		mmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_17/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TOEmodel/transformer/encoder/encoder_layer_2/dropout_5/dropout/Mul_1:Mul"Mul"qlagradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/Tile_1:Tile"Tile"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul/Sum_1:Sum"Sum"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"mmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"		kmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"gbXgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/mul_1:Mul"Mul"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul/Mul_1:Mul"Mul"jeQmodel/transformer/encoder/encoder_layer/multi_head_attention/MatMul:BatchMatMulV2"BatchMatMulV2"gbPgradient_tape/model/transformer/decoder/dense_25/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"c^Tgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_14/dropout/Mul_2:Mul"Mul"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/Rsqrt:Rsqrt"Rsqrt"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul:Mul"Mul"u	p	fgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul/Mul_1:Mul"Mul")@%@Adam/gradients/AddN_28:AddN"AddN"TO7Adam/Adam/update_99/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"C>4model/transformer/decoder/dropout_21/dropout/Mul:Mul"Mul"+&Adam/gradients/AddN_56:AddN"AddN"UP8Adam/Adam/update_113/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"gbUmodel/transformer/decoder/decoder_layer/sequential_4/dense_35/Tensordot/MatMul:MatMul"MatMul"

vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/Tensordot/MatMul/MatMul:MatMul"MatMul"TO7Adam/Adam/update_32/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"		mgradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_65/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"pkWmodel/transformer/decoder/dropout_21/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"TO7Adam/Adam/update_80/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"C>)Adam/Cast_2/ReadVariableOp:ReadVariableOp"ReadVariableOp"wrhgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_1/Mul_1:Mul"Mul"b{blgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose/transpose:Transpose"	Transpose"TO7Adam/Adam/update_66/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/Tensordot/MatMul/MatMul:MatMul"MatMul"~
y
lgradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_55/Tensordot/MatMul/MatMul:MatMul"MatMul"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul/Mul_1:Mul"Mul"faUmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/add_1:AddV2"AddV2"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/sub/Neg:Neg"Neg"c
^
Tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/Sum:Sum"Sum"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_2/Mul:Mul"Mul"HC)AssignAddVariableOp_2:AssignAddVariableOp"AssignAddVariableOp"TO7Adam/Adam/update_33/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Omodel/transformer/encoder/encoder_layer_3/sequential_3/dense_24/BiasAdd:BiasAdd"BiasAdd"UPFmodel/transformer/decoder/decoder_layer_1/dropout_14/dropout/Mul_1:Mul"Mul"~jgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"d_Smodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/add:AddV2"AddV2"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/sub/Neg:Neg"Neg"r
m
bgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/Tile_1:Tile"Tile"b]Omodel/transformer/decoder/decoder_layer_3/sequential_7/dense_65/BiasAdd:BiasAdd"BiasAdd"}xcmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"		ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_2/transpose:Transpose"	Transpose"a\Rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/mul:Mul"Mul"omodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_50/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_27/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"e`Vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/mul:Mul"Mul"faUmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/add_1:AddV2"AddV2"qlbgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul/Sum:Sum"Sum"UPEmodel/transformer/encoder/encoder_layer_1/dropout_2/dropout/Cast:Cast"Cast"S.O.8Adam/Adam/update_134/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"p
k
agradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/truediv_1:Mul"Mul"HC)AssignAddVariableOp_1:AssignAddVariableOp"AssignAddVariableOp"	|	gmodel/transformer/decoder/decoder_layer_3/sequential_7/dense_65/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"R]N]7Adam/Adam/update_70/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"~ylgradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_45/Tensordot/MatMul/MatMul:MatMul"MatMul"pkagradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/truediv:Mul"Mul"_ZOmodel/transformer/decoder/decoder_layer/layer_normalization_8/moments/mean:Mean"Mean"`[Qgradient_tape/model/transformer/encoder/encoder_layer_2/dropout_5/dropout/Mul:Mul"Mul"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/Tensordot/MatMul/MatMul_1:MatMul"MatMul"c^Rmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/add:AddV2"AddV2"UP8Adam/Adam/update_138/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a\Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul:Mul"Mul"EagerKernelExecute"gbRmodel/transformer/encoder/encoder_layer/multi_head_attention/transpose_3:Transpose"	Transpose"wgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"		qmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_1/Mul:Mul"Mul"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_1/Mul:Mul"Mul"`[Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/sub:Sub"Sub"snamodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/Tensordot/MatMul:MatMul"MatMul"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/Rsqrt:Rsqrt"Rsqrt"VQFmodel/transformer/decoder/decoder_layer_3/dropout_20/dropout/Cast:Cast"Cast"lgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul/Mul_1:Mul"Mul"UP8Adam/Adam/update_106/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/sub:Sub"Sub"lmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_2/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"_ZPmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/sub:Sub"Sub"U	P	Fmodel/transformer/decoder/decoder_layer/multi_head_attention_5/sub:Sub"Sub"<7#Iterator::Model::ParallelMapV2::Zip"Iterator::Zip"jmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_4/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"]XMmodel/transformer/encoder/encoder_layer/layer_normalization/moments/mean:Mean"Mean"TO7Adam/Adam/update_28/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"D?3model/transformer/encoder/encoder_layer_3/add:AddV2"AddV2"d_Qmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/Softmax:Softmax"Softmax"k
f
\gradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/truediv/Sum:Sum"Sum"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"[WEmodel/transformer/encoder/dropout_8/dropout/GreaterEqual:GreaterEqual"GreaterEqual"b]Smodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_2:Mul"Mul"mh]gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/Tile_1:Tile"Tile"UP8Adam/Adam/update_133/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"QLBmodel/transformer/decoder/decoder_layer/dropout_10/dropout/Mul:Mul"Mul"Mul:Mul"Mul"b]Sgradient_tape/model/transformer/encoder/encoder_layer_1/dropout_3/dropout/Mul_2:Mul"Mul"^YLgradient_tape/model/transformer/encoder/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul:Mul"Mul"RMCmodel/transformer/decoder/decoder_layer/dropout_9/dropout/Mul_1:Mul"Mul"^YOmodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul:Mul"Mul"vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/Tensordot/MatMul/MatMul:MatMul"MatMul"u
p
fgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_2/Mul:Mul"Mul"e`Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/add:AddV2"AddV2"gmodel/transformer/encoder/encoder_layer/layer_normalization/moments/SquaredDifference:SquaredDifference"SquaredDifference"a
\
Rgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_16/dropout/Mul:Mul"Mul"VQFmodel/transformer/decoder/decoder_layer_2/dropout_15/dropout/Cast:Cast"Cast"TO7Adam/Adam/update_12/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam";;vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/Tensordot/MatMul/MatMul:MatMul"MatMul"UP8Adam/Adam/update_127/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"0+!model/transformer/encoder/Sin:Sin"Sin"	z	fmodel/transformer/encoder/encoder_layer_3/dropout_7/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"lg]gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/truediv:Mul"Mul"b]Smodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_1:Mul"Mul"~ngradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_3/transpose:Transpose"	Transpose"zjgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/transpose_3/transpose:Transpose"	Transpose"~ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_1/transpose:Transpose"	Transpose"e
`
Vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/sub:Sub"Sub"qmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"m	h	^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/sub:Sub"Sub"ugradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/Tensordot/MatMul/MatMul:MatMul"MatMul"wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"mhUmodel/transformer/encoder/encoder_layer_1/dropout_2/dropout/GreaterEqual:GreaterEqual"GreaterEqual"i%e%Vmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_2:Transpose"	Transpose"PKAmodel/transformer/encoder/encoder_layer/dropout/dropout/Mul_1:Mul"Mul"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/Tensordot/MatMul/MatMul_1:MatMul"MatMul"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_2/Sum:Sum"Sum"NI6model/transformer/decoder/strided_slice_8:StridedSlice"StridedSlice"SNDmodel/transformer/decoder/decoder_layer_2/dropout_17/dropout/Mul:Mul"Mul"ojVmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul:BatchMatMulV2"BatchMatMulV2"		qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"nHjHagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/sub/Sum:Sum"Sum"kf\gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/Mul:Mul"Mul"lgSmodel/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul:BatchMatMulV2"BatchMatMulV2"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_2/Mul:Mul"Mul"TO7Adam/Adam/update_97/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"jmodel/transformer/decoder/decoder_layer/layer_normalization_10/moments/SquaredDifference:SquaredDifference"SquaredDifference"u
p
fgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_2/Mul_1:Mul"Mul"~jgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"	~	imodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"ql_model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/Tensordot/MatMul:MatMul"MatMul"omodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"oj_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/Tile_1:Tile"Tile"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul/Mul:Mul"Mul"j~jmgradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_18/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"sn_gradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_23/ReluGrad:ReluGrad"ReluGrad"qlbgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/truediv_1:Mul"Mul"w
r
hgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_2/Mul_1:Mul"Mul"UP8Adam/Adam/update_135/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"SNDmodel/transformer/decoder/decoder_layer/dropout_10/dropout/Mul_1:Mul"Mul"`[Qgradient_tape/model/transformer/encoder/encoder_layer_1/dropout_2/dropout/Mul:Mul"Mul"+
&
Adam/gradients/AddN_32:AddN"AddN"b]Sgradient_tape/model/transformer/encoder/encoder_layer_2/dropout_4/dropout/Mul_2:Mul"Mul"mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"rmcgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_1/Mul_1:Mul"Mul"`[Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul:Mul"Mul"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_1:Mul"Mul"lmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_1/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"omodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"A<Iterator::Model::ParallelMapV2"Iterator::ParallelMapV2"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/Tensordot/MatMul/MatMul_1:MatMul"MatMul"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul/Sum:Sum"Sum"q
l
bgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/truediv:Mul"Mul"faVmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/variance:Mean"Mean"RMCmodel/transformer/encoder/encoder_layer_1/dropout_3/dropout/Mul:Mul"Mul"+&Adam/gradients/AddN_59:AddN"AddN"w	r	hgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_2/Mul_1:Mul"Mul"SN6Adam/Adam/update_5/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"^YFmodel/transformer/decoder/dropout_21/dropout/GreaterEqual:GreaterEqual"GreaterEqual"TO7Adam/Adam/update_38/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"je[gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/sub:Sub"Sub"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/Tensordot/MatMul:MatMul"MatMul"b]Omodel/transformer/encoder/encoder_layer_3/sequential_3/dense_23/BiasAdd:BiasAdd"BiasAdd"TO7Adam/Adam/update_24/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"jeWmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/BiasAdd:BiasAdd"BiasAdd"S6O68Adam/Adam/update_105/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"d_Rmodel/transformer/encoder/encoder_layer/sequential/dense_5/Tensordot/MatMul:MatMul"MatMul"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul:Mul"Mul"	z	emodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/sub/Sum:Sum"Sum"wrhgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_2/Mul_1:Mul"Mul"vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_2/Sum:Sum"Sum"sndgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_2/Sum:Sum"Sum"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/BiasAdd:BiasAdd"BiasAdd"lgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"FA5gradient_tape/model/transformer/decoder/Slice_1:Slice"Slice"'"EagerLocalExecute: LogicalAnd"`[Omodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/add:AddV2"AddV2"{ngradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_17/Tensordot/MatMul/MatMul_1:MatMul"MatMul"}	x	dmodel/transformer/decoder/decoder_layer/dropout_9/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"e`Vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/sub:Sub"Sub"TO7Adam/Adam/update_81/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"idWmodel/transformer/encoder/encoder_layer_2/sequential_2/dense_17/Tensordot/MatMul:MatMul"MatMul"YTImodel/transformer/encoder/encoder_layer_3/sequential_3/dense_23/Relu:Relu"Relu"lgWmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_1:Transpose"	Transpose"rGnGegradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_1/Mul_1:Mul"Mul"~ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_3/transpose:Transpose"	Transpose"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/Tensordot/MatMul:MatMul"MatMul"UPEmodel/transformer/encoder/encoder_layer_2/dropout_4/dropout/Cast:Cast"Cast"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/Tensordot/MatMul:MatMul"MatMul"U	P	8Adam/Adam/update_167/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"}hmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"RMCmodel/transformer/encoder/encoder_layer_1/dropout_2/dropout/Mul:Mul"Mul"^YOmodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/sub:Sub"Sub"TO7Adam/Adam/update_19/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Smodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_2:Mul"Mul"rm`model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/Tensordot/MatMul:MatMul"MatMul"

vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/Tensordot/MatMul/MatMul:MatMul"MatMul"mmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"a}ajgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"faUmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/add_1:AddV2"AddV2"ni_gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/truediv:Mul"Mul"TO7Adam/Adam/update_96/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"e`Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/add:AddV2"AddV2"qlagradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/Tile_1:Tile"Tile"faUmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/add_1:AddV2"AddV2"c^Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_2:Mul"Mul"c^Pmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/Softmax:Softmax"Softmax"ni_gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/mul_1:Mul"Mul"
|
lgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"94*gradient_tape/mean_squared_error/mul_1:Mul"Mul"d_Smodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/add_1:AddV2"AddV2"

tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/Tensordot/MatMul/MatMul:MatMul"MatMul"VQFmodel/transformer/decoder/decoder_layer_3/dropout_19/dropout/Cast:Cast"Cast"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"qmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad" Adam/Cast_1:Cast"Cast"u	p	fgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul/Sum_1:Sum"Sum"c^Tgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/mul_1:Mul"Mul"qlagradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/Tile_1:Tile"Tile"+&Adam/gradients/AddN_60:AddN"AddN"oj_gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/Tile_1:Tile"Tile"w
r
hgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_1/Mul_1:Mul"Mul"c	^	Tgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_18/dropout/Mul_2:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul/Sum_1:Sum"Sum"oj`gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/truediv:Mul"Mul"ql_model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/Tensordot/MatMul:MatMul"MatMul"--xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/Tensordot/MatMul/MatMul_1:MatMul"MatMul"^YOmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_1:Mul"Mul"TO7Adam/Adam/update_41/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pk`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/Tile:Tile"Tile"FA'AssignAddVariableOp:AssignAddVariableOp"AssignAddVariableOp"SNDmodel/transformer/decoder/decoder_layer_3/dropout_18/dropout/Mul:Mul"Mul"gbTmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_3/BiasAdd:BiasAdd"BiasAdd"		qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"hPdP[gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/sub:Sub"Sub"|gmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_18/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"B=1model/transformer/decoder/decoder_layer/add:AddV2"AddV2"~yigradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"sndgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_2/Mul:Mul"Mul"gbVmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/Rsqrt:Rsqrt"Rsqrt"+&LogicalAnd:LogicalAnd"
LogicalAnd"T
O
7Adam/Adam/update_87/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RMCgradient_tape/model/transformer/encoder/dropout_8/dropout/Mul_2:Mul"Mul"		rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"ql_model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/Tensordot/MatMul:MatMul"MatMul"|gmodel/transformer/decoder/decoder_layer_2/sequential_6/dense_55/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_10/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/SquaredDifference:SquaredDifference"SquaredDifference"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul/Mul_1:Mul"Mul"prlrcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul/Sum:Sum"Sum"oj`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/mul_1:Mul"Mul"HC)AssignAddVariableOp_4:AssignAddVariableOp"AssignAddVariableOp"m
h
^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/sub:Sub"Sub"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/Tensordot/MatMul/MatMul_1:MatMul"MatMul"zemodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"faUmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/Rsqrt:Rsqrt"Rsqrt"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"e
`
Vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/mul_1:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_2/Mul:Mul"Mul"~ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_2/transpose:Transpose"	Transpose"SN6Adam/Adam/update_2/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/Tensordot/MatMul/MatMul:MatMul"MatMul"\WMmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/truediv:Mul"Mul"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"GC7model/transformer/encoder/dense/Tensordot/MatMul:MatMul"MatMul"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_46/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul/Sum_1:Sum"Sum"+
&
Adam/gradients/AddN_16:AddN"AddN"LG:model/transformer/decoder/dense_26/Tensordot/MatMul:MatMul"MatMul"kfVmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_3:Transpose"	Transpose"rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_1/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"m	h	^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/sub:Sub"Sub"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/sub/Neg:Neg"Neg"}hmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"jeWmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/BiasAdd:BiasAdd"BiasAdd"wgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"+&Adam/gradients/AddN_57:AddN"AddN"UP8Adam/Adam/update_164/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"e`Umodel/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/variance:Mean"Mean"toegradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_2/Mul_1:Mul"Mul"niUmodel/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul_1:BatchMatMulV2"BatchMatMulV2"i>e>\gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/sub:Sub"Sub"imodel/transformer/encoder/encoder_layer/layer_normalization_1/moments/SquaredDifference:SquaredDifference"SquaredDifference"ojVmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul:BatchMatMulV2"BatchMatMulV2"FA5model/transformer/decoder/decoder_layer_2/add_2:AddV2"AddV2"R	M	Cmodel/transformer/encoder/encoder_layer_3/dropout_7/dropout/Mul:Mul"Mul"kf[gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/Tile:Tile"Tile"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/sub:Sub"Sub"mh]gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/Tile:Tile"Tile"vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/Tensordot/MatMul/MatMul:MatMul"MatMul"B=(div_no_nan/ReadVariableOp:ReadVariableOp"ReadVariableOp"niUmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul:BatchMatMulV2"BatchMatMulV2"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_2/Sum:Sum"Sum"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_166/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam")$EagerLocalExecute: WriteSummary"lgWmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_1:Transpose"	Transpose"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul/Mul_1:Mul"Mul"a	\	Rgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_18/dropout/Mul:Mul"Mul"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/Tensordot/MatMul/MatMul:MatMul"MatMul"UP8Adam/Adam/update_102/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"kmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/SquaredDifference:SquaredDifference"SquaredDifference"d_Smodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/add:AddV2"AddV2"UPFmodel/transformer/decoder/decoder_layer_3/dropout_18/dropout/Mul_1:Mul"Mul"RONO7Adam/Adam/update_92/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"~ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_1/transpose:Transpose"	Transpose"{ngradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_45/Tensordot/MatMul/MatMul_1:MatMul"MatMul"kfVmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_3:Transpose"	Transpose"hcYgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/sub:Sub"Sub"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/BiasAdd:BiasAdd"BiasAdd"kfVmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_3:Transpose"	Transpose"		omodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"}xdmodel/transformer/encoder/encoder_layer/dropout_1/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"idTmodel/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_2:Transpose"	Transpose"faWgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/sub:Sub"Sub"niZgradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_5/ReluGrad:ReluGrad"ReluGrad"ql_model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/Tensordot/MatMul:MatMul"MatMul"kfVmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_1:Transpose"	Transpose"

xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/Tensordot/MatMul/MatMul_1:MatMul"MatMul"~yemodel/transformer/decoder/decoder_layer/dropout_10/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"RiNi7Adam/Adam/update_48/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a\Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/mean:Mean"Mean"TO7Adam/Adam/update_76/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pk`gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/Tile_1:Tile"Tile"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/BiasAdd:BiasAdd"BiasAdd"~ngradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_3/transpose:Transpose"	Transpose"a\Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/mean:Mean"Mean"WRHmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/sub:Sub"Sub"kmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/SquaredDifference:SquaredDifference"SquaredDifference"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/sub/Neg:Neg"Neg"U
P
8Adam/Adam/update_144/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_172/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"hcYgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/mul_1:Mul"Mul"k
f
\gradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/truediv/Sum:Sum"Sum"VQFmodel/transformer/decoder/decoder_layer_1/dropout_12/dropout/Cast:Cast"Cast"`[Qgradient_tape/model/transformer/encoder/encoder_layer_3/dropout_6/dropout/Mul:Mul"Mul"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_83/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"}hmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"		ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"'"ValidateInputTypeAndPlacement"TO7Adam/Adam/update_59/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"kfVmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_2:Transpose"	Transpose"mgradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_46/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"s
n
dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul/Mul:Mul"Mul"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul/Sum_1:Sum"Sum"		xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"~qgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_1/Tensordot/MatMul/MatMul:MatMul"MatMul"wgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/Tensordot/MatMul/MatMul_1:MatMul"MatMul"a\Nmodel/transformer/decoder/decoder_layer/multi_head_attention_4/Softmax:Softmax"Softmax"55wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_1/Mul:Mul"Mul"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/Rsqrt:Rsqrt"Rsqrt"SNDmodel/transformer/decoder/decoder_layer_1/dropout_13/dropout/Mul:Mul"Mul"snamodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/Tensordot/MatMul:MatMul"MatMul"	|	gmodel/transformer/decoder/decoder_layer_3/sequential_7/dense_66/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"X{Xhgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"|gmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"~yigradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"`[Qgradient_tape/model/transformer/decoder/decoder_layer/dropout_9/dropout/Mul_2:Mul"Mul"lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"upYgradient_tape/model/transformer/decoder/strided_slice_9/StridedSliceGrad:StridedSliceGrad"StridedSliceGrad"1,WriteSummary:WriteSummary"WriteSummary"~
y
igradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"b]Smodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_2:Mul"Mul"		pmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"|gmodel/transformer/encoder/encoder_layer_2/sequential_2/dense_18/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"jeUmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose:Transpose"	Transpose"cz_zVgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/mul:Mul"Mul"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/Tensordot/MatMul/MatMul:MatMul"MatMul"rmbgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/Tile_1:Tile"Tile"c
^
Tgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_16/dropout/Mul_2:Mul"Mul"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/truediv_1:Mul"Mul"nmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"kfVmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_2:Transpose"	Transpose"mhUmodel/transformer/encoder/encoder_layer_2/dropout_4/dropout/GreaterEqual:GreaterEqual"GreaterEqual"T
O
7Adam/Adam/update_72/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_60/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_65/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"rm`model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/Tensordot/MatMul:MatMul"MatMul"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/truediv/Sum:Sum"Sum"gbRmodel/transformer/encoder/encoder_layer/multi_head_attention/transpose_2:Transpose"	Transpose"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"^YOgradient_tape/model/transformer/encoder/encoder_layer/dropout/dropout/Mul_2:Mul"Mul"ddwgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"zfmodel/transformer/encoder/encoder_layer_1/dropout_3/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"TO7Adam/Adam/update_37/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"w
r
hgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_1/Mul_1:Mul"Mul"C>/mean_squared_error/weighted_loss/value:DivNoNan"DivNoNan"d_Smodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/add:AddV2"AddV2"c	^	Tgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_19/dropout/Mul_2:Mul"Mul"`[Qgradient_tape/model/transformer/encoder/encoder_layer_1/dropout_3/dropout/Mul:Mul"Mul"omodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"jeWmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/BiasAdd:BiasAdd"BiasAdd"lgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul/Mul:Mul"Mul"faVmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/variance:Mean"Mean"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/sub/Sum:Sum"Sum"+&Adam/gradients/AddN_22:AddN"AddN"{vigradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_6/Tensordot/MatMul/MatMul_1:MatMul"MatMul"qmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"idTmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose:Transpose"	Transpose"UPFmodel/transformer/decoder/decoder_layer_3/dropout_19/dropout/Mul_1:Mul"Mul"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/Tensordot/MatMul:MatMul"MatMul"*	%	Adam/gradients/AddN_7:AddN"AddN"a\Rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/sub:Sub"Sub"TO7Adam/Adam/update_15/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_2/Sum:Sum"Sum"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_2/Mul:Mul"Mul"UPFmodel/transformer/decoder/decoder_layer_1/dropout_13/dropout/Mul_1:Mul"Mul"TO7Adam/Adam/update_67/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_151/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"nmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"ni_gradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/truediv/Sum:Sum"Sum"e`Vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/sub:Sub"Sub"U	P	8Adam/Adam/update_152/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ni^gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/Tile:Tile"Tile"j f Tmodel/transformer/decoder/decoder_layer/dropout_11/dropout/GreaterEqual:GreaterEqual"GreaterEqual"wgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"idTmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose:Transpose"	Transpose"a\Rgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_13/dropout/Mul:Mul"Mul"kfVmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_1:Transpose"	Transpose"WWtgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/Tensordot/MatMul/MatMul:MatMul"MatMul"m
h
^gradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/truediv/Sum:Sum"Sum"qlbgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul/Mul:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul/Mul_1:Mul"Mul"e`Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/add:AddV2"AddV2"zfgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"gbUmodel/transformer/decoder/decoder_layer/sequential_4/dense_36/Tensordot/MatMul:MatMul"MatMul"e`Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/add:AddV2"AddV2"	z	emodel/transformer/decoder/decoder_layer_2/sequential_6/dense_56/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"ni\model/transformer/encoder/encoder_layer/multi_head_attention/dense_2/Tensordot/MatMul:MatMul"MatMul"idTmodel/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_3:Transpose"	Transpose"wrhgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_1/Mul_1:Mul"Mul"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul/Sum_1:Sum"Sum"d_Smodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/Rsqrt:Rsqrt"Rsqrt"[VLmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/truediv:Mul"Mul"b]Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/mean:Mean"Mean"T
O
7Adam/Adam/update_94/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"{gmodel/transformer/decoder/decoder_layer_2/dropout_16/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"pqlqcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul/Mul:Mul"Mul"UP8Adam/Adam/update_118/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul/Sum:Sum"Sum"'"div_no_nan:DivNoNan"DivNoNan"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/Tensordot/MatMul:MatMul"MatMul"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/Tensordot/MatMul:MatMul"MatMul"|gmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgYmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/BiasAdd:BiasAdd"BiasAdd"b]Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/mean:Mean"Mean"ParallelMapProduce"`[Qgradient_tape/model/transformer/encoder/encoder_layer_2/dropout_4/dropout/Mul:Mul"Mul"e
`
Vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/mul:Mul"Mul"UP8Adam/Adam/update_161/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/sub/Neg:Neg"Neg"T
O
7Adam/Adam/update_77/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ni\model/transformer/encoder/encoder_layer/multi_head_attention/dense_3/Tensordot/MatMul:MatMul"MatMul"TO7Adam/Adam/update_51/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"84IteratorGetNext:IteratorGetNext"IteratorGetNext"UP8Adam/Adam/update_112/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"|wbmodel/transformer/encoder/encoder_layer/sequential/dense_5/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"U	P	8Adam/Adam/update_147/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qlagradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/Tile_1:Tile"Tile"oj_gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/Tile:Tile"Tile"b]Omodel/transformer/encoder/encoder_layer_1/sequential_1/dense_12/BiasAdd:BiasAdd"BiasAdd"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/Tensordot/MatMul/MatMul:MatMul"MatMul"u
p
fgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul/Mul_1:Mul"Mul"SN6Adam/Adam/update_8/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"	|	lgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"kmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul/Sum:Sum"Sum"imodel/transformer/decoder/decoder_layer/layer_normalization_8/moments/SquaredDifference:SquaredDifference"SquaredDifference"S=O=8Adam/Adam/update_100/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/Tensordot/MatMul/MatMul:MatMul"MatMul"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"jeUmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose:Transpose"	Transpose"=8)model/transformer/encoder/concat:ConcatV2"ConcatV2"kfVmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_1:Transpose"	Transpose"c^Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_1:Mul"Mul"U	P	Emodel/transformer/encoder/encoder_layer_3/dropout_7/dropout/Cast:Cast"Cast"~jgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"ni_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/sub/Sum:Sum"Sum"+&Adam/gradients/AddN_35:AddN"AddN"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/sub/Neg:Neg"Neg"{ngradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_66/Tensordot/MatMul/MatMul_1:MatMul"MatMul"qmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"d_Rmodel/transformer/encoder/encoder_layer/sequential/dense_6/Tensordot/MatMul:MatMul"MatMul"TOEmodel/transformer/encoder/encoder_layer_1/dropout_3/dropout/Mul_1:Mul"Mul"		pmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"}hmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul/Mul_1:Mul"Mul"_B[BRgradient_tape/model/transformer/decoder/decoder_layer/dropout_11/dropout/Mul_2:Mul"Mul"lgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/Tensordot/MatMul/MatMul_1:MatMul"MatMul"
|
lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_3/transpose:Transpose"	Transpose"UP8Adam/Adam/update_115/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"0+!model/transformer/decoder/mul:Mul"Mul"b]Omodel/transformer/encoder/encoder_layer_2/sequential_2/dense_18/BiasAdd:BiasAdd"BiasAdd"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/Tensordot/MatMul:MatMul"MatMul"U
P
8Adam/Adam/update_126/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul/Sum:Sum"Sum"C>)Adam/Cast_3/ReadVariableOp:ReadVariableOp"ReadVariableOp"YTImodel/transformer/encoder/encoder_layer_1/sequential_1/dense_11/Relu:Relu"Relu"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_2/Sum:Sum"Sum"lgYmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/BiasAdd:BiasAdd"BiasAdd"}hmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"l~lmgradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_17/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"\WMmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/sub:Sub"Sub"b]Hmodel/transformer/decoder/dense_25/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"s
n
dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul/Mul:Mul"Mul"faVmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/variance:Mean"Mean"jeWmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/BiasAdd:BiasAdd"BiasAdd"r	m	cgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/truediv/RealDiv:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_2/Sum:Sum"Sum"4/#model/transformer/decoder/add:AddV2"AddV2"FA,div_no_nan_1/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_36:AddN"AddN"72(gradient_tape/mean_squared_error/sub:Sub"Sub"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/Tensordot/MatMul/MatMul_1:MatMul"MatMul"e`Vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/sub:Sub"Sub"mmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"omodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgYmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/BiasAdd:BiasAdd"BiasAdd"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_1:Mul"Mul"c^Qgradient_tape/model/transformer/decoder/dense_26/Tensordot/MatMul/MatMul_1:MatMul"MatMul"		ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/Tensordot/MatMul/MatMul_1:MatMul"MatMul")$EagerCopyToDeviceAndAddCacheKey"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/truediv_1:Mul"Mul"mgradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_23/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"TO7Adam/Adam/update_62/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_78/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"LG:model/transformer/decoder/dense_25/Tensordot/MatMul:MatMul"MatMul"kfVmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_1:Transpose"	Transpose"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_2/Sum:Sum"Sum"lgWmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_2:Transpose"	Transpose"s	n	dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul/Sum:Sum"Sum"TO7Adam/Adam/update_23/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"S(O(8Adam/Adam/update_145/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_1/Mul:Mul"Mul"gbXgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/mul_1:Mul"Mul"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/BiasAdd:BiasAdd"BiasAdd"__xgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/Tensordot/MatMul/MatMul_1:MatMul"MatMul"u
p
fgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_2/Sum:Sum"Sum"xgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/Tensordot/MatMul/MatMul_1:MatMul"MatMul"TO7Adam/Adam/update_34/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"_ZPmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul:Mul"Mul"83.EagerExecute: __inference_train_function_14421"xgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/Tensordot/MatMul/MatMul_1:MatMul"MatMul"	z	emodel/transformer/decoder/decoder_layer_3/sequential_7/dense_65/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"snamodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/Tensordot/MatMul:MatMul"MatMul"mgradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_55/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"je[gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/sub:Sub"Sub"snamodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/Tensordot/MatMul:MatMul"MatMul"b]Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/mean:Mean"Mean"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/BiasAdd:BiasAdd"BiasAdd"o
j
_gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/Tile_1:Tile"Tile"yylgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"e`Vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/mul:Mul"Mul"TO7Adam/Adam/update_58/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_2/Sum:Sum"Sum"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/Rsqrt:Rsqrt"Rsqrt"idTmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose:Transpose"	Transpose"94'model/transformer/encoder/Cumsum:Cumsum"Cumsum"snamodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/Tensordot/MatMul:MatMul"MatMul"d_Tmodel/transformer/decoder/decoder_layer/layer_normalization_10/moments/variance:Mean"Mean"~imodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/sub/Neg:Neg"Neg"c
^
Tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/sub:Sub"Sub"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/Tensordot/MatMul:MatMul"MatMul"UP8Adam/Adam/update_139/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"
|
lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_1/transpose:Transpose"	Transpose"pkagradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/truediv:Mul"Mul"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"pkagradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/truediv:Mul"Mul"@<3model/transformer/encoder/dropout_8/dropout/Mul:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul/Sum_1:Sum"Sum"niVmodel/transformer/decoder/decoder_layer_3/dropout_20/dropout/GreaterEqual:GreaterEqual"GreaterEqual"m	h	^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/Mul:Mul"Mul"sn_gradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_11/ReluGrad:ReluGrad"ReluGrad"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_2:Mul"Mul"e`Vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/sub:Sub"Sub"`[Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul:Mul"Mul"TO7Adam/Adam/update_39/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"~
y
lgradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_56/Tensordot/MatMul/MatMul:MatMul"MatMul"YTImodel/transformer/decoder/decoder_layer_1/sequential_5/dense_45/Relu:Relu"Relu"m	h	^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/sub:Sub"Sub"{gmodel/transformer/decoder/decoder_layer_2/dropout_17/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"TO7Adam/Adam/update_11/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"{ngradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_56/Tensordot/MatMul/MatMul_1:MatMul"MatMul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul/Sum:Sum"Sum"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/BiasAdd:BiasAdd"BiasAdd"Adam/Pow:Pow"Pow"UPFmodel/transformer/decoder/decoder_layer_1/dropout_12/dropout/Mul_1:Mul"Mul"upYgradient_tape/model/transformer/decoder/strided_slice_8/StridedSliceGrad:StridedSliceGrad"StridedSliceGrad"u	p	fgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_1/Mul:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_2/Mul_1:Mul"Mul"idQmodel/transformer/encoder/encoder_layer/dropout/dropout/GreaterEqual:GreaterEqual"GreaterEqual"omodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_61/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_136/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"zemodel/transformer/encoder/encoder_layer_2/sequential_2/dense_17/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"d_Smodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/Rsqrt:Rsqrt"Rsqrt"b]Smodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_1:Mul"Mul"u	p	fgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul/Mul_1:Mul"Mul"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/sub/Neg:Neg"Neg"q'm'dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/sub/Sum:Sum"Sum"niVmodel/transformer/decoder/decoder_layer_2/dropout_15/dropout/GreaterEqual:GreaterEqual"GreaterEqual"UP8Adam/Adam/update_157/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"nJjJagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/sub/Neg:Neg"Neg"UP8Adam/Adam/update_101/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"
|
hgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"vqggradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_1/Mul_1:Mul"Mul"'"GatherV2_1:GatherV2"GatherV2"`[Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul:Mul"Mul"WRGmodel/transformer/decoder/decoder_layer/sequential_4/dense_35/Relu:Relu"Relu"s
n
dgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul/Mul_1:Mul"Mul"e
`
Vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/Sum:Sum"Sum"e`Vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/mul:Mul"Mul"~imodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"d_Smodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/add:AddV2"AddV2"pk`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/Tile:Tile"Tile"niUmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul:BatchMatMulV2"BatchMatMulV2"~ngradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_1/transpose:Transpose"	Transpose"idWmodel/transformer/decoder/decoder_layer_1/sequential_5/dense_45/Tensordot/MatMul:MatMul"MatMul"mtit_gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/Tile:Tile"Tile"a\Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/mean:Mean"Mean"*%Adam/gradients/AddN_3:AddN"AddN"u
p
fgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul/Mul_1:Mul"Mul"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/Tensordot/MatMul:MatMul"MatMul"_ZOmodel/transformer/decoder/decoder_layer/layer_normalization_9/moments/mean:Mean"Mean"u	p	fgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_2/Mul:Mul"Mul"vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/Tensordot/MatMul/MatMul:MatMul"MatMul"61%model/transformer/decoder/Equal:Equal"Equal"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/Tensordot/MatMul/MatMul_1:MatMul"MatMul"vqggradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_1/Mul_1:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul/Sum_1:Sum"Sum"zemodel/transformer/decoder/decoder_layer/sequential_4/dense_36/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"wrhgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_1/Mul_1:Mul"Mul"+&Adam/gradients/AddN_41:AddN"AddN"mmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"a\AIterator::Model::ParallelMapV2::Zip[1]::ForeverRepeat::FromTensor"Iterator::FromTensor"mgradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_45/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"UP8Adam/Adam/update_171/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"s	n	dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul/Mul:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_2/Sum:Sum"Sum"ngradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"{kgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"qlbgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/truediv/RealDiv:Mul"Mul"TO7Adam/Adam/update_52/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"wgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"% GatherV2:GatherV2"GatherV2"UPFmodel/transformer/decoder/decoder_layer_2/dropout_15/dropout/Mul_1:Mul"Mul"UP8Adam/Adam/update_143/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_162/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a	\	Rgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_17/dropout/Mul:Mul"Mul"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul/Mul:Mul"Mul"S0O08Adam/Adam/update_119/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"zemodel/transformer/decoder/decoder_layer/sequential_4/dense_35/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/sub/Neg:Neg"Neg"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/BiasAdd:BiasAdd"BiasAdd"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_1/Mul:Mul"Mul"p
k
`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/Tile:Tile"Tile"rmcgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_1/Mul:Mul"Mul"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_2:Mul"Mul""TFE_Py_FastPathExecute_C"xgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/Tensordot/MatMul/MatMul_1:MatMul"MatMul"A	<	'Adam/Cast/ReadVariableOp:ReadVariableOp"ReadVariableOp"faUmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/Rsqrt:Rsqrt"Rsqrt"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/Tensordot/MatMul/MatMul:MatMul"MatMul"YTImodel/transformer/encoder/encoder_layer_2/sequential_2/dense_17/Relu:Relu"Relu"idWmodel/transformer/decoder/decoder_layer_3/sequential_7/dense_65/Tensordot/MatMul:MatMul"MatMul"TO7Adam/Adam/update_68/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Qmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/add_1:AddV2"AddV2"]AYAPgradient_tape/model/transformer/decoder/decoder_layer/dropout_11/dropout/Mul:Mul"Mul"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/Tensordot/MatMul/MatMul:MatMul"MatMul"UP8Adam/Adam/update_131/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"rmbgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/Tile_1:Tile"Tile"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/BiasAdd:BiasAdd"BiasAdd"`[Qmodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_2:Mul"Mul"zfmodel/transformer/encoder/encoder_layer_3/dropout_6/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/Tensordot/MatMul:MatMul"MatMul"SNCmodel/transformer/encoder/encoder_layer/dropout_1/dropout/Cast:Cast"Cast"{ngradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_24/Tensordot/MatMul/MatMul_1:MatMul"MatMul"p
k
agradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/sub/Sum:Sum"Sum"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/Tensordot/MatMul:MatMul"MatMul"UP8Adam/Adam/update_125/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"

ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"wgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/Tensordot/MatMul/MatMul_1:MatMul"MatMul"jmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul/Mul:Mul"Mul"ccvgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/Tensordot/MatMul/MatMul:MatMul"MatMul"wgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"a	\	Rgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_19/dropout/Mul:Mul"Mul"lg]gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/sub:Sub"Sub"gbVmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/add_1:AddV2"AddV2"c^Pmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/Softmax:Softmax"Softmax"qmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"r
m
bgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/Tile_1:Tile"Tile"e`Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/add:AddV2"AddV2"f	a	Wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/mul:Mul"Mul"{gmodel/transformer/decoder/decoder_layer_3/dropout_18/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"|gmodel/transformer/encoder/encoder_layer_3/sequential_3/dense_23/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/Tensordot/MatMul/MatMul_1:MatMul"MatMul"ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_2/transpose:Transpose"	Transpose"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul:Mul"Mul"|gmodel/transformer/decoder/decoder_layer_1/sequential_5/dense_46/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/sub:Sub"Sub"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/sub/Sum:Sum"Sum"		wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/Tensordot/MatMul/MatMul:MatMul"MatMul"rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_4/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/Tensordot/MatMul/MatMul:MatMul"MatMul"~ngradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_3/transpose:Transpose"	Transpose"gbXgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/mul_1:Mul"Mul"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/BiasAdd:BiasAdd"BiasAdd"WRHmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/sub:Sub"Sub"pkWmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul_1:BatchMatMulV2"BatchMatMulV2"		ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_3/transpose:Transpose"	Transpose"zhgradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_6/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"q/m/dgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/sub/Sum:Sum"Sum"niVmodel/transformer/decoder/decoder_layer_3/dropout_19/dropout/GreaterEqual:GreaterEqual"GreaterEqual"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/BiasAdd:BiasAdd"BiasAdd"{kgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad")R%RAdam/gradients/AddN_31:AddN"AddN"lg]gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/Mul:Mul"Mul"~ngradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_1/transpose:Transpose"	Transpose"
~
jgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"xgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/Tensordot/MatMul/MatMul_1:MatMul"MatMul"TO7Adam/Adam/update_36/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"=83EagerLocalExecute: __inference_train_function_14421"r
m
cgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_2/Mul:Mul"Mul"+
&
Adam/gradients/AddN_14:AddN"AddN"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"[VLmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/truediv:Mul"Mul"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/sub:Sub"Sub"D?3model/transformer/decoder/decoder_layer_1/add:AddV2"AddV2"rmcgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul/Mul_1:Mul"Mul"lmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/SquaredDifference:SquaredDifference"SquaredDifference"c|_|Vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/sub:Sub"Sub"`[Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/sub:Sub"Sub"UP8Adam/Adam/update_163/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"
~
ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_3/transpose:Transpose"	Transpose"lgWmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_3:Transpose"	Transpose"b]Smodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_1:Mul"Mul"	|	lgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"pmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/sub/Sum:Sum"Sum"UP8Adam/Adam/update_108/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/Tensordot/MatMul/MatMul:MatMul"MatMul"lg]gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/Mul:Mul"Mul"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul/Mul:Mul"Mul"wgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad".*!model/transformer/encoder/mul:Mul"Mul"&!IteratorGetNextOp::DoCompute"wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"`[Qmodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_1:Mul"Mul"+	&	Adam/gradients/AddN_10:AddN"AddN"~ylgradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_12/Tensordot/MatMul/MatMul:MatMul"MatMul"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul/Mul:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul/Mul:Mul"Mul"e`Vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/Sum:Sum"Sum"qlbgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/truediv/RealDiv:Mul"Mul"TO7Adam/Adam/update_35/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/Tensordot/MatMul/MatMul:MatMul"MatMul"c^Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_1:Mul"Mul"a\Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/mean:Mean"Mean"b]Omodel/transformer/decoder/decoder_layer_1/sequential_5/dense_45/BiasAdd:BiasAdd"BiasAdd"ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"		mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"zhgradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_5/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"S8O88Adam/Adam/update_109/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul/Mul:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul/Sum:Sum"Sum"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul:Mul"Mul"hcYgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/Mul:Mul"Mul"u
p
fgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_1/Mul:Mul"Mul"je[gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/Mul:Mul"Mul"wrhgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_1/Mul_1:Mul"Mul"WRHmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/sub:Sub"Sub"C>%FlushSummaryWriter:FlushSummaryWriter"FlushSummaryWriter"TO7Adam/Adam/update_30/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"o	j	`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/mul_1:Mul"Mul"idTmodel/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_2:Transpose"	Transpose"`[Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul:Mul"Mul"oj_gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/Tile:Tile"Tile"d_Smodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/add:AddV2"AddV2"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/SquaredDifference:SquaredDifference"SquaredDifference"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"_ZOmodel/transformer/encoder/encoder_layer/layer_normalization_1/moments/mean:Mean"Mean"RINI7Adam/Adam/update_93/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"wrhgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_2/Mul_1:Mul"Mul"mh^gradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/truediv/Sum:Sum"Sum"~jgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"a\Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul:Mul"Mul"SNDmodel/transformer/decoder/decoder_layer/dropout_11/dropout/Mul_1:Mul"Mul"WRHmodel/transformer/encoder/encoder_layer/multi_head_attention/truediv:Mul"Mul"idTmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose:Transpose"	Transpose"{ngradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_12/Tensordot/MatMul/MatMul_1:MatMul"MatMul"gbRmodel/transformer/encoder/encoder_layer/multi_head_attention/transpose_1:Transpose"	Transpose"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul/Mul:Mul"Mul"o
j
`gradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/truediv/RealDiv:Mul"Mul"gbVmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/Rsqrt:Rsqrt"Rsqrt"b]Smodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_1:Mul"Mul"s
n
dgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_1/Mul:Mul"Mul"^YOgradient_tape/model/transformer/encoder/encoder_layer/dropout_1/dropout/Mul:Mul"Mul"TODmodel/transformer/decoder/decoder_layer/dropout_10/dropout/Cast:Cast"Cast"j	e	Wmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/BiasAdd:BiasAdd"BiasAdd"RkNk7Adam/Adam/update_45/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Hmodel/transformer/decoder/dense_26/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"h	c	Ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/mul_1:Mul"Mul"~ngradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_2/transpose:Transpose"	Transpose"pkWmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul_1:BatchMatMulV2"BatchMatMulV2"LG4model/transformer/decoder/strided_slice:StridedSlice"StridedSlice"~ylgradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_65/Tensordot/MatMul/MatMul:MatMul"MatMul"q
l
bgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/truediv:Mul"Mul"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/BiasAdd:BiasAdd"BiasAdd"		wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/Tensordot/MatMul/MatMul:MatMul"MatMul"{gmodel/transformer/decoder/decoder_layer_1/dropout_13/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/Tensordot/MatMul/MatMul:MatMul"MatMul"{gmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"d_Smodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/add:AddV2"AddV2"+&Adam/gradients/AddN_17:AddN"AddN"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/truediv_1:Mul"Mul"jmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_2/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"FA5model/transformer/decoder/decoder_layer_3/add_2:AddV2"AddV2"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/Tensordot/MatMul/MatMul_1:MatMul"MatMul"*	%	Adam/gradients/AddN_9:AddN"AddN"|hgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul/Mul_1:Mul"Mul"+&Adam/gradients/AddN_43:AddN"AddN"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/BiasAdd:BiasAdd"BiasAdd"a\Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/mean:Mean"Mean"[VJmodel/transformer/decoder/decoder_layer/multi_head_attention_5/Equal:Equal"Equal"s	n	dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/sub/Sum:Sum"Sum"SN6Adam/Adam/update_4/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"77wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"niVmodel/transformer/decoder/decoder_layer_1/dropout_12/dropout/GreaterEqual:GreaterEqual"GreaterEqual"pkWmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul_1:BatchMatMulV2"BatchMatMulV2"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/sub/Sum:Sum"Sum"ZZugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"TO7Adam/Adam/update_21/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lg]gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/sub:Sub"Sub"

ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"{ngradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_11/Tensordot/MatMul/MatMul_1:MatMul"MatMul""EagerExecute: LogicalAnd"n
i
_gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/truediv:Mul"Mul"+
&
Adam/gradients/AddN_15:AddN"AddN"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"3.#model/transformer/decoder/Cast:Cast"Cast"+&Adam/gradients/AddN_20:AddN"AddN"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/add_1:AddV2"AddV2"SN6Adam/Adam/update_6/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"idTmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose:Transpose"	Transpose"oDkD]gradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_35/ReluGrad:ReluGrad"ReluGrad"jeWmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/BiasAdd:BiasAdd"BiasAdd"|lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose/transpose:Transpose"	Transpose"c
^
Tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/mul:Mul"Mul"e`Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/add:AddV2"AddV2"`[Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/sub:Sub"Sub"RMCmodel/transformer/encoder/encoder_layer_2/dropout_4/dropout/Mul:Mul"Mul"TO7Adam/Adam/update_26/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul/Mul_1:Mul"Mul"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/Tensordot/MatMul/MatMul:MatMul"MatMul"idTmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose:Transpose"	Transpose"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul/Mul_1:Mul"Mul"oj_gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/Tile:Tile"Tile"rfnfegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_1/Mul:Mul"Mul"jmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_3/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_95/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"[VLmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/truediv:Mul"Mul"		ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_3/transpose:Transpose"	Transpose"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/truediv_1:Mul"Mul"mgradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_11/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/sub/Sum:Sum"Sum"qlagradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/Tile_1:Tile"Tile"lgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"zemodel/transformer/encoder/encoder_layer_3/sequential_3/dense_23/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"mgradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_12/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"b]Omodel/transformer/decoder/decoder_layer_2/sequential_6/dense_56/BiasAdd:BiasAdd"BiasAdd"`[Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/sub:Sub"Sub"faVmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/variance:Mean"Mean"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/sub/Sum:Sum"Sum"	}	mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose/transpose:Transpose"	Transpose"kmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul/Sum_1:Sum"Sum"UPFmodel/transformer/decoder/decoder_layer_3/dropout_20/dropout/Mul_1:Mul"Mul"mh^gradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/truediv/RealDiv:Mul"Mul"+
&
Adam/gradients/AddN_11:AddN"AddN"qmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"mh^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/Mul:Mul"Mul"b]Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/mean:Mean"Mean"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"qlbgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/truediv/RealDiv:Mul"Mul"		wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/Tensordot/MatMul/MatMul:MatMul"MatMul"imodel/transformer/decoder/decoder_layer/layer_normalization_9/moments/SquaredDifference:SquaredDifference"SquaredDifference"b]Smodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_2:Mul"Mul"O"K"Bmodel/transformer/decoder/decoder_layer/dropout_11/dropout/Mul:Mul"Mul"[VLmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/truediv:Mul"Mul"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/add_1:AddV2"AddV2"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/Tensordot/MatMul:MatMul"MatMul"kfXmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/BiasAdd:BiasAdd"BiasAdd"jQfQ]gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/mul_1:Mul"Mul"xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/Tensordot/MatMul/MatMul_1:MatMul"MatMul"
|
lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose/transpose:Transpose"	Transpose"lgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"upfgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_1/Mul_1:Mul"Mul"a\Rmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_2:Mul"Mul"train_function"B=1model/transformer/encoder/encoder_layer/add:AddV2"AddV2"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/BiasAdd:BiasAdd"BiasAdd"vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"TOEmodel/transformer/encoder/encoder_layer_3/dropout_6/dropout/Mul_1:Mul"Mul"lgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"`
[
?Iterator::Model::ParallelMapV2::Zip[0]::FlatMap[0]::TensorSlice"Iterator::TensorSlice"YTImodel/transformer/decoder/decoder_layer_2/sequential_6/dense_55/Relu:Relu"Relu"`[Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/sub:Sub"Sub"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/add_1:AddV2"AddV2"T
O
7Adam/Adam/update_88/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_2/Sum:Sum"Sum"VQFmodel/transformer/decoder/decoder_layer_2/dropout_16/dropout/Cast:Cast"Cast"q	l	_model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/Tensordot/MatMul:MatMul"MatMul"~szskgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"wrhgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_2/Mul_1:Mul"Mul"kfVmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_2:Transpose"	Transpose"s	n	dgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/sub/Neg:Neg"Neg"nmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"faVmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/variance:Mean"Mean"gbTmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_1/BiasAdd:BiasAdd"BiasAdd"pk`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/Tile:Tile"Tile"+
&
Adam/gradients/AddN_13:AddN"AddN"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/BiasAdd:BiasAdd"BiasAdd"w	r	hgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_2/Mul_1:Mul"Mul"NI6model/transformer/encoder/strided_slice_1:StridedSlice"StridedSlice"vqggradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_2/Mul_1:Mul"Mul"@</model/transformer/encoder/dense/BiasAdd:BiasAdd"BiasAdd"lgYmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/BiasAdd:BiasAdd"BiasAdd"}kgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_36/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"qlbgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/truediv:Mul"Mul"|lgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose/transpose:Transpose"	Transpose"SNDmodel/transformer/decoder/decoder_layer_3/dropout_20/dropout/Mul:Mul"Mul"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_2:Mul"Mul"niUmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul:BatchMatMulV2"BatchMatMulV2"o	j	`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/mul_1:Mul"Mul"~ngradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_1/transpose:Transpose"	Transpose"~qgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_4/Tensordot/MatMul/MatMul:MatMul"MatMul"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/add_1:AddV2"AddV2"TO7Adam/Adam/update_44/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_2/Sum:Sum"Sum"a\Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul:Mul"Mul"0+&InstantiatedCapturedFunction::RunAsync"e`Pmodel/transformer/encoder/encoder_layer/multi_head_attention/transpose:Transpose"	Transpose"q	l	bgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/truediv:Mul"Mul"lmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_3/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"k?g?^gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/mul_1:Mul"Mul"D?5model/transformer/encoder/dropout_8/dropout/Mul_1:Mul"Mul"faVmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/variance:Mean"Mean"lg]gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/mul_1:Mul"Mul"ugradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/Tensordot/MatMul/MatMul:MatMul"MatMul"ni_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/truediv:Mul"Mul"+&Adam/gradients/AddN_45:AddN"AddN"
~
ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_2/transpose:Transpose"	Transpose"*%Adam/gradients/AddN_2:AddN"AddN"SN6Adam/Adam/update_7/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"$EagerExecute: WriteSummary"RMCmodel/transformer/encoder/encoder_layer/dropout_1/dropout/Mul_1:Mul"Mul"o
j
`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/mul_1:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_2/Sum:Sum"Sum"RMCmodel/transformer/encoder/encoder_layer_3/dropout_6/dropout/Mul:Mul"Mul"+&Adam/gradients/AddN_21:AddN"AddN"b]Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/mean:Mean"Mean"kmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgWmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_3:Transpose"	Transpose")L%LAdam/gradients/AddN_30:AddN"AddN"^YOmodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul:Mul"Mul"|lgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"

tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/Tensordot/MatMul/MatMul:MatMul"MatMul"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_2/Sum:Sum"Sum"FA5model/transformer/encoder/encoder_layer_2/add_1:AddV2"AddV2"kfVmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_1:Transpose"	Transpose"sgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_1/Tensordot/MatMul/MatMul_1:MatMul"MatMul"zemodel/transformer/encoder/encoder_layer_1/sequential_1/dense_12/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"ni_gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/mul_1:Mul"Mul"kfVmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_3:Transpose"	Transpose"}hmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"~ylgradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_46/Tensordot/MatMul/MatMul:MatMul"MatMul"+&Adam/gradients/AddN_52:AddN"AddN"rnnnegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_1/Mul:Mul"Mul"UPEmodel/transformer/encoder/encoder_layer_1/dropout_3/dropout/Cast:Cast"Cast"TO7Adam/Adam/update_86/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/mean:Mean"Mean"		kgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"ngradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"toegradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_1/Mul_1:Mul"Mul"k	f	Smodel/transformer/decoder/decoder_layer/dropout_9/dropout/GreaterEqual:GreaterEqual"GreaterEqual"sn_gradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_17/ReluGrad:ReluGrad"ReluGrad"gbVmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/add_1:AddV2"AddV2"|lgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"zjgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/transpose_2/transpose:Transpose"	Transpose"{gmodel/transformer/decoder/decoder_layer_1/dropout_14/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"idWmodel/transformer/encoder/encoder_layer_3/sequential_3/dense_23/Tensordot/MatMul:MatMul"MatMul"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/Tensordot/MatMul:MatMul"MatMul"omodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"s	n	dgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/truediv_1:Mul"Mul"b]Sgradient_tape/model/transformer/encoder/encoder_layer_3/dropout_6/dropout/Mul_2:Mul"Mul"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/Tensordot/MatMul/MatMul:MatMul"MatMul"sn_gradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_45/ReluGrad:ReluGrad"ReluGrad"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_1:Mul"Mul"FunctionRun"+
&
Adam/gradients/AddN_12:AddN"AddN"ni_gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/mul_1:Mul"Mul"UP8Adam/Adam/update_137/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_57/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"HC)AssignAddVariableOp_3:AssignAddVariableOp"AssignAddVariableOp"U	P	8Adam/Adam/update_153/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Smodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_2:Mul"Mul"TOEmodel/transformer/encoder/encoder_layer_3/dropout_7/dropout/Mul_1:Mul"Mul"S*O*8Adam/Adam/update_159/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"	Sum_2:Sum"Sum"c^Pmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/Softmax:Softmax"Softmax"snamodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/Tensordot/MatMul:MatMul"MatMul"}YyYjgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/transpose/transpose:Transpose"	Transpose"a\Rgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_14/dropout/Mul:Mul"Mul"s
n
dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/truediv_1:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/truediv_1:Mul"Mul"UP8Adam/Adam/update_107/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/add_1:AddV2"AddV2"% Identity:Identity"Identity"`[Qmodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_2:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul/Sum_1:Sum"Sum"ytggradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_6/Tensordot/MatMul/MatMul:MatMul"MatMul"b]Smodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_1:Mul"Mul"u
p
fgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_1/Mul:Mul"Mul"UPEmodel/transformer/encoder/encoder_layer_2/dropout_5/dropout/Cast:Cast"Cast"FA5model/transformer/encoder/encoder_layer_3/add_1:AddV2"AddV2"b]Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/mean:Mean"Mean"p
k
agradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul/Mul:Mul"Mul"mh]gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/Tile:Tile"Tile"u	p	fgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_2/Mul:Mul"Mul"c{_{Vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/Sum:Sum"Sum"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"[VLmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/truediv:Mul"Mul"s	n	dgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul/Sum:Sum"Sum"NI6model/transformer/encoder/strided_slice_2:StridedSlice"StridedSlice"e`Tmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/Rsqrt:Rsqrt"Rsqrt"ni\model/transformer/encoder/encoder_layer/multi_head_attention/dense_4/Tensordot/MatMul:MatMul"MatMul"toegradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_1/Mul_1:Mul"Mul"UP8Adam/Adam/update_160/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"T
O
7Adam/Adam/update_85/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lgYmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/BiasAdd:BiasAdd"BiasAdd"Adam/add:AddV2"AddV2"{ngradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_18/Tensordot/MatMul/MatMul_1:MatMul"MatMul"ReNe7Adam/Adam/update_53/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"idWmodel/transformer/encoder/encoder_layer_3/sequential_3/dense_24/Tensordot/MatMul:MatMul"MatMul"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/BiasAdd:BiasAdd"BiasAdd"qlbgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/sub/Sum:Sum"Sum"SN6mean_squared_error/SquaredDifference:SquaredDifference"SquaredDifference"D?3model/transformer/decoder/decoder_layer_2/add:AddV2"AddV2"		wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/Tensordot/MatMul/MatMul:MatMul"MatMul"lg]gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/sub:Sub"Sub"~qgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_2/Tensordot/MatMul/MatMul:MatMul"MatMul"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/BiasAdd:BiasAdd"BiasAdd"oj_gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/Tile:Tile"Tile"~ylgradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_18/Tensordot/MatMul/MatMul:MatMul"MatMul"idWmodel/transformer/decoder/decoder_layer_2/sequential_6/dense_56/Tensordot/MatMul:MatMul"MatMul"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"gbTmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_4/BiasAdd:BiasAdd"BiasAdd"*	%	Adam/gradients/AddN_4:AddN"AddN"VQFmodel/transformer/decoder/decoder_layer_2/dropout_17/dropout/Cast:Cast"Cast"{wcmodel/transformer/decoder/decoder_layer/sequential_4/dense_36/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"idWmodel/transformer/decoder/decoder_layer_2/sequential_6/dense_55/Tensordot/MatMul:MatMul"MatMul"ni_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/sub/Neg:Neg"Neg"ni_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul/Mul:Mul"Mul"lmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_4/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_47:AddN"AddN"q
l
bgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/sub/Neg:Neg"Neg"qlbgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/truediv:Mul"Mul"QL4Adam/Adam/update/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"omodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"`[Qmodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_1:Mul"Mul"c
^
Tgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_17/dropout/Mul_2:Mul"Mul"{vigradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_5/Tensordot/MatMul/MatMul_1:MatMul"MatMul"R!N!Dmodel/transformer/decoder/decoder_layer/dropout_11/dropout/Cast:Cast"Cast"lgSmodel/transformer/encoder/encoder_layer/multi_head_attention/MatMul_1:BatchMatMulV2"BatchMatMulV2"oj`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/mul_1:Mul"Mul"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/sub:Sub"Sub"SNDmodel/transformer/decoder/decoder_layer_2/dropout_16/dropout/Mul:Mul"Mul"kfVmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_1:Transpose"	Transpose"_T[TRgradient_tape/model/transformer/decoder/decoder_layer/dropout_10/dropout/Mul_2:Mul"Mul"}hmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgYmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/BiasAdd:BiasAdd"BiasAdd"`[Qmodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_1:Mul"Mul"c
^
Tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/sub:Sub"Sub"UP8Adam/Adam/update_103/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"snamodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/Tensordot/MatMul:MatMul"MatMul"`[Mmodel/transformer/decoder/decoder_layer/sequential_4/dense_36/BiasAdd:BiasAdd"BiasAdd"PK1Adam/Adam/AssignAddVariableOp:AssignAddVariableOp"AssignAddVariableOp"g
b
Xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/mul_1:Mul"Mul"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/sub/Neg:Neg"Neg"e`Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/add:AddV2"AddV2"+&Adam/gradients/AddN_54:AddN"AddN"rmbgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/Tile_1:Tile"Tile"q	l	_model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/Tensordot/MatMul:MatMul"MatMul"jvfv]gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/Mul:Mul"Mul"pkWmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul_1:BatchMatMulV2"BatchMatMulV2"UP8Adam/Adam/update_173/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a\Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/sub:Sub"Sub"r	m	bgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/Tile_1:Tile"Tile"zemodel/transformer/decoder/decoder_layer_3/sequential_7/dense_66/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"ytggradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_5/Tensordot/MatMul/MatMul:MatMul"MatMul"d	_	Smodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/add_1:AddV2"AddV2"lg]gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/sub:Sub"Sub"{ngradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_65/Tensordot/MatMul/MatMul_1:MatMul"MatMul"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/Tensordot/MatMul/MatMul_1:MatMul"MatMul"B=3gradient_tape/model/transformer/encoder/mul/Mul:Mul"Mul")$div_no_nan_1:DivNoNan"DivNoNan"kmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/SquaredDifference:SquaredDifference"SquaredDifference"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/Tensordot/MatMul:MatMul"MatMul"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"m	h	^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/Mul:Mul"Mul"vqggradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_1/Mul_1:Mul"Mul"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"|lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_2/transpose:Transpose"	Transpose"pk`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/Tile:Tile"Tile"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/truediv_1:Mul"Mul"NI6model/transformer/decoder/strided_slice_9:StridedSlice"StridedSlice"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/truediv_1:Mul"Mul"o
j
`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/mul_1:Mul"Mul"vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/Tensordot/MatMul/MatMul:MatMul"MatMul"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul/Mul:Mul"Mul"TO7Adam/Adam/update_49/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_1/transpose:Transpose"	Transpose"p	k	`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/Tile:Tile"Tile"faUmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/add_1:AddV2"AddV2"b]Smodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_1:Mul"Mul"S2O28Adam/Adam/update_111/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/SquaredDifference:SquaredDifference"SquaredDifference"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/SquaredDifference:SquaredDifference"SquaredDifference"LG/Iterator::Model::ParallelMapV2::Zip[0]::FlatMap"Iterator::FlatMap"|lgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose/transpose:Transpose"	Transpose"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_2/Mul:Mul"Mul"m
h
^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/Mul:Mul"Mul"\WMgradient_tape/model/transformer/encoder/encoder_layer/dropout/dropout/Mul:Mul"Mul"~ylgradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_17/Tensordot/MatMul/MatMul:MatMul"MatMul"TO7Adam/Adam/update_69/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pkWmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul_1:BatchMatMulV2"BatchMatMulV2"*% EagerExecute: FlushSummaryWriter"faWgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/mul:Mul"Mul"xgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/Tensordot/MatMul/MatMul_1:MatMul"MatMul"ni_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/truediv_1:Mul"Mul"idTmodel/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_3:Transpose"	Transpose"s
n
dgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul/Sum_1:Sum"Sum"kfVmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_2:Transpose"	Transpose"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/Tensordot/MatMul:MatMul"MatMul"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/BiasAdd:BiasAdd"BiasAdd"]XJmodel/transformer/encoder/encoder_layer/sequential/dense_5/BiasAdd:BiasAdd"BiasAdd"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/Tensordot/MatMul/MatMul_1:MatMul"MatMul"u	p	fgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_1/Mul:Mul"Mul"zCvCjgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_36/Tensordot/MatMul/MatMul:MatMul"MatMul"~jgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"FA5model/transformer/decoder/decoder_layer_2/add_1:AddV2"AddV2"d_Smodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/add_1:AddV2"AddV2"kfVmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_2:Transpose"	Transpose"b]Qmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/Rsqrt:Rsqrt"Rsqrt"TO7Adam/Adam/update_74/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"wrhgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_2/Mul_1:Mul"Mul"o
j
`gradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/truediv/RealDiv:Mul"Mul"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/Tensordot/MatMul:MatMul"MatMul"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"{kgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"RmNm7Adam/Adam/update_43/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"faUmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/Rsqrt:Rsqrt"Rsqrt"a\Ogradient_tape/model/transformer/decoder/dense_25/Tensordot/MatMul/MatMul:MatMul"MatMul"wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/Tensordot/MatMul/MatMul:MatMul"MatMul"~ylgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_35/Tensordot/MatMul/MatMul_1:MatMul"MatMul"D?3model/transformer/decoder/decoder_layer_3/add:AddV2"AddV2"c^Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_2:Mul"Mul"n	i	_gradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/truediv/Sum:Sum"Sum"+&Adam/gradients/AddN_51:AddN"AddN"kfXmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/BiasAdd:BiasAdd"BiasAdd"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/Tensordot/MatMul:MatMul"MatMul"^	Y	Omodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/sub:Sub"Sub"je[gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/mul_1:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/truediv_1:Mul"Mul"RMCmodel/transformer/encoder/encoder_layer_2/dropout_5/dropout/Mul:Mul"Mul"kfSmodel/transformer/encoder/encoder_layer/dropout_1/dropout/GreaterEqual:GreaterEqual"GreaterEqual"\WMmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul:Mul"Mul"f	a	Wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/sub:Sub"Sub"VQFmodel/transformer/decoder/decoder_layer_3/dropout_18/dropout/Cast:Cast"Cast"mmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"zfmodel/transformer/encoder/encoder_layer_2/dropout_5/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul/Sum:Sum"Sum"|hgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"lg]gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/sub:Sub"Sub"TO7Adam/Adam/update_82/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"
}
kgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_35/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"idWmodel/transformer/encoder/encoder_layer_1/sequential_1/dense_11/Tensordot/MatMul:MatMul"MatMul"pkWmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"u
p
fgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_2/Sum:Sum"Sum"SN6Adam/Adam/update_1/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"))xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"a\Qmodel/transformer/encoder/encoder_layer/layer_normalization/moments/variance:Mean"Mean",'mean_squared_error/Mean:Mean"Mean"SNDmodel/transformer/decoder/decoder_layer_2/dropout_15/dropout/Mul:Mul"Mul"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/BiasAdd:BiasAdd"BiasAdd"\\vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/Tensordot/MatMul/MatMul_1:MatMul"MatMul"jmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_1/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"idWmodel/transformer/encoder/encoder_layer_2/sequential_2/dense_18/Tensordot/MatMul:MatMul"MatMul"kgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"

vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/Tensordot/MatMul/MatMul_1:MatMul"MatMul"+&Adam/gradients/AddN_26:AddN"AddN""TFE_Py_ExecuteCancelable"b]Omodel/transformer/encoder/encoder_layer_1/sequential_1/dense_11/BiasAdd:BiasAdd"BiasAdd"s
n
dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/sub/Neg:Neg"Neg"{fmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_116/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Omodel/transformer/decoder/decoder_layer_2/sequential_6/dense_55/BiasAdd:BiasAdd"BiasAdd"TO7Adam/Adam/update_16/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qlbgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/truediv:Mul"Mul"g	b	Rmodel/transformer/decoder/decoder_layer/multi_head_attention_5/transpose:Transpose"	Transpose"o~k~bgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/truediv/RealDiv:Mul"Mul"e`Umodel/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/variance:Mean"Mean"xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/Tensordot/MatMul/MatMul_1:MatMul"MatMul"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"d_Jmodel/transformer/decoder/dense_25/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"q	l	bgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/truediv:Mul"Mul"2-#model/transformer/encoder/mul_2:Mul"Mul"TO7Adam/Adam/update_90/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"Y	T	Jmodel/transformer/decoder/decoder_layer/multi_head_attention_5/truediv:Mul"Mul"|lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_2/transpose:Transpose"	Transpose"vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/Tensordot/MatMul/MatMul:MatMul"MatMul"lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"wrhgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_1/Mul_1:Mul"Mul"`[Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/sub:Sub"Sub"pk`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/Tile:Tile"Tile"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_1/Mul:Mul"Mul"snamodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/Tensordot/MatMul:MatMul"MatMul"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"lg]gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/Mul:Mul"Mul"miVmodel/transformer/encoder/dropout_8/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"B=3gradient_tape/model/transformer/decoder/mul/Mul:Mul"Mul"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/Tensordot/MatMul:MatMul"MatMul"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/Mul:Mul"Mul"D?*div_no_nan/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"~ylgradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_11/Tensordot/MatMul/MatMul:MatMul"MatMul"

vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/Tensordot/MatMul/MatMul:MatMul"MatMul"qmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"{kgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"d_Smodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/Rsqrt:Rsqrt"Rsqrt"vqggradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_1/Mul_1:Mul"Mul"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/Tensordot/MatMul/MatMul_1:MatMul"MatMul"o	j	`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/mul_1:Mul"Mul"a\Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/mean:Mean"Mean"~ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_3/transpose:Transpose"	Transpose":}:ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_2/transpose:Transpose"	Transpose"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/add_1:AddV2"AddV2"gbVmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/add_1:AddV2"AddV2"Iterator::Model"+&Adam/gradients/AddN_58:AddN"AddN"|lgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"a
\
Rgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_15/dropout/Mul:Mul"Mul"SN6Adam/Adam/update_3/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ni_gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/mul_1:Mul"Mul"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/Tensordot/MatMul/MatMul_1:MatMul"MatMul"faVmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/variance:Mean"Mean"ExecutorDoneCallback"zemodel/transformer/encoder/encoder_layer_1/sequential_1/dense_11/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"*%Adam/gradients/AddN_8:AddN"AddN"wgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"je[gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/Mul:Mul"Mul"b]Qmodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/add:AddV2"AddV2"j$f$Ymodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/BiasAdd:BiasAdd"BiasAdd"r
m
cgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_2/Sum:Sum"Sum"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul/Sum:Sum"Sum"lgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"qlXmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul_1:BatchMatMulV2"BatchMatMulV2"c^Smodel/transformer/encoder/encoder_layer/layer_normalization_1/moments/variance:Mean"Mean"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul/Mul:Mul"Mul"		qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"rKnKegradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_2/Mul_1:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul/Sum:Sum"Sum"c^Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_2:Mul"Mul"`[Pmodel/transformer/decoder/decoder_layer/layer_normalization_10/moments/mean:Mean"Mean"[VLmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/truediv:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/sub/Sum:Sum"Sum"lg]gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/sub:Sub"Sub"c^Smodel/transformer/decoder/decoder_layer/layer_normalization_8/moments/variance:Mean"Mean"

ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/Tensordot/MatMul:MatMul"MatMul"mmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"`	[	Qmodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_2:Mul"Mul"nujuagradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/truediv:Mul"Mul"c^Tgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_13/dropout/Mul_2:Mul"Mul"~ylgradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_24/Tensordot/MatMul/MatMul:MatMul"MatMul"~ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_1/transpose:Transpose"	Transpose"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/sub/Sum:Sum"Sum"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_2:Mul"Mul"UPFmodel/transformer/decoder/decoder_layer_2/dropout_17/dropout/Mul_1:Mul"Mul"u	p	fgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_2/Sum:Sum"Sum"+&Adam/gradients/AddN_53:AddN"AddN"idWmodel/transformer/encoder/encoder_layer_1/sequential_1/dense_12/Tensordot/MatMul:MatMul"MatMul"gbVmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/Rsqrt:Rsqrt"Rsqrt"l	g	Smodel/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul:BatchMatMulV2"BatchMatMulV2"}xhgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/transpose/transpose:Transpose"	Transpose"ngradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"D?*div_no_nan_1/ReadVariableOp:ReadVariableOp"ReadVariableOp"gbTmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_2/BiasAdd:BiasAdd"BiasAdd"UP8Adam/Adam/update_169/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"w	r	hgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_1/Mul_1:Mul"Mul"VQFmodel/transformer/decoder/decoder_layer_1/dropout_13/dropout/Cast:Cast"Cast"omodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgTmodel/transformer/decoder/decoder_layer/dropout_10/dropout/GreaterEqual:GreaterEqual"GreaterEqual"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/Tensordot/MatMul:MatMul"MatMul"^YOgradient_tape/model/transformer/decoder/decoder_layer/dropout_9/dropout/Mul:Mul"Mul"rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_2/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"~ngradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_2/transpose:Transpose"	Transpose"TO7Adam/Adam/update_64/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"p
k
agradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul/Sum:Sum"Sum"+&Adam/gradients/AddN_18:AddN"AddN"kmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/SquaredDifference:SquaredDifference"SquaredDifference"e`Umodel/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/variance:Mean"Mean"p
k
`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/Tile:Tile"Tile"lmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"11wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/BiasAdd:BiasAdd"BiasAdd"b]Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/mean:Mean"Mean"SNDmodel/transformer/decoder/decoder_layer_3/dropout_19/dropout/Mul:Mul"Mul"pkWmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul_1:BatchMatMulV2"BatchMatMulV2"TO7Adam/Adam/update_20/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"E@2model/transformer/decoder/dense_25/BiasAdd:BiasAdd"BiasAdd"faUmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/Rsqrt:Rsqrt"Rsqrt"wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/Tensordot/MatMul/MatMul:MatMul"MatMul"

xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/Tensordot/MatMul/MatMul_1:MatMul"MatMul"wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"convert_to_tensor"e`Umodel/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/variance:Mean"Mean"s
n
dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul/Sum:Sum"Sum"zemodel/transformer/decoder/decoder_layer_1/sequential_5/dense_46/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"e`Vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/mul:Mul"Mul"TO7Adam/Adam/update_14/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"mhUmodel/transformer/encoder/encoder_layer_2/dropout_5/dropout/GreaterEqual:GreaterEqual"GreaterEqual"sgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_2/Tensordot/MatMul/MatMul_1:MatMul"MatMul"s	n	dgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/sub/Neg:Neg"Neg")F%FAdam/gradients/AddN_29:AddN"AddN"ql_model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/Tensordot/MatMul:MatMul"MatMul"e`Vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/sub:Sub"Sub"mmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"VQFmodel/transformer/decoder/decoder_layer_1/dropout_14/dropout/Cast:Cast"Cast"^YOmodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/sub:Sub"Sub"lg]gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/mul_1:Mul"Mul"		mgradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_66/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul/Mul_1:Mul"Mul"|lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_1/transpose:Transpose"	Transpose"SNDgradient_tape/model/transformer/decoder/dropout_21/dropout/Mul_2:Mul"Mul"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/Mul:Mul"Mul"FA5model/transformer/encoder/encoder_layer_1/add_1:AddV2"AddV2"~ylgradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_66/Tensordot/MatMul/MatMul:MatMul"MatMul"e`Vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/Sum:Sum"Sum"lgWmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_2:Transpose"	Transpose"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul/Sum:Sum"Sum"R`N`7Adam/Adam/update_54/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Sgradient_tape/model/transformer/encoder/encoder_layer_3/dropout_7/dropout/Mul_2:Mul"Mul"}mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose/transpose:Transpose"	Transpose"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_1:Mul"Mul"ni_gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/mul_1:Mul"Mul"
~
jgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"vqggradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_2/Mul_1:Mul"Mul"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/Tensordot/MatMul/MatMul_1:MatMul"MatMul"e`Vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/Sum:Sum"Sum"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_1/Mul:Mul"Mul"f	a	Wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/Sum:Sum"Sum"lgYmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/BiasAdd:BiasAdd"BiasAdd"~jgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"ExecutorState::Process"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul/Mul_1:Mul"Mul"qlXmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul_1:BatchMatMulV2"BatchMatMulV2"q
l
bgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/truediv/RealDiv:Mul"Mul"|gmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"|gmodel/transformer/encoder/encoder_layer_1/sequential_1/dense_12/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"SN6Adam/Adam/update_9/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"s
n
dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/sub/Neg:Neg"Neg"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/Tensordot/MatMul/MatMul_1:MatMul"MatMul"lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"TO7Adam/Adam/update_55/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_140/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_25/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/Tensordot/MatMul/MatMul:MatMul"MatMul"faUmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/add_1:AddV2"AddV2",},ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_2/transpose:Transpose"	Transpose"j
e
[gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/Mul:Mul"Mul"a\Rgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_20/dropout/Mul:Mul"Mul"|lgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose/transpose:Transpose"	Transpose"kfXmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/BiasAdd:BiasAdd"BiasAdd"niUmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul:BatchMatMulV2"BatchMatMulV2"{ngradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_23/Tensordot/MatMul/MatMul_1:MatMul"MatMul"		omodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"]SYSPgradient_tape/model/transformer/decoder/decoder_layer/dropout_10/dropout/Mul:Mul"Mul"^YOmodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul:Mul"Mul"e`Tmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/add_1:AddV2"AddV2"tf.constant"FA5model/transformer/decoder/decoder_layer_1/add_1:AddV2"AddV2"mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"+&Adam/gradients/AddN_38:AddN"AddN"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"
~
jgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/Rsqrt:Rsqrt"Rsqrt"{gmodel/transformer/decoder/decoder_layer_3/dropout_20/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"i	d	Tmodel/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_1:Transpose"	Transpose"e}a}Xgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/mul_1:Mul"Mul"qlbgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/truediv/RealDiv:Mul"Mul"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/sub:Sub"Sub"+&Adam/gradients/AddN_34:AddN"AddN"UP8Adam/Adam/update_156/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"XSImodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/sub:Sub"Sub"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_1:Mul"Mul"niVmodel/transformer/decoder/decoder_layer_1/dropout_14/dropout/GreaterEqual:GreaterEqual"GreaterEqual"p	k	`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/Tile:Tile"Tile"omodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"faUmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/Rsqrt:Rsqrt"Rsqrt"a\Rmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_1:Mul"Mul"s	n	dgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/truediv_1:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/truediv_1:Mul"Mul"|lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_3/transpose:Transpose"	Transpose"|lgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"lgYmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/BiasAdd:BiasAdd"BiasAdd"ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_1/transpose:Transpose"	Transpose"s	n	dgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul/Mul:Mul"Mul"NI6model/transformer/encoder/strided_slice_3:StridedSlice"StridedSlice"|xemodel/transformer/decoder/decoder_layer/dropout_11/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/Tensordot/MatMul/MatMul:MatMul"MatMul"niVmodel/transformer/decoder/decoder_layer_2/dropout_16/dropout/GreaterEqual:GreaterEqual"GreaterEqual"(#Adam/gradients/AddN:AddN"AddN"vqggradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_2/Mul_1:Mul"Mul"+&Adam/gradients/AddN_48:AddN"AddN"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/BiasAdd:BiasAdd"BiasAdd"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul/Sum:Sum"Sum"+&Adam/gradients/AddN_39:AddN"AddN"TODmodel/transformer/encoder/encoder_layer/sequential/dense_5/Relu:Relu"Relu"b]Qmodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/add:AddV2"AddV2"idTmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose:Transpose"	Transpose"ParallelMapConsume"u
p
fgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_1/Mul:Mul"Mul"{gmodel/transformer/decoder/decoder_layer_2/dropout_15/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"99ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"rmcgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/truediv/RealDiv:Mul"Mul"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/sub:Sub"Sub"SNDmodel/transformer/decoder/decoder_layer_1/dropout_12/dropout/Mul:Mul"Mul"faVmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/variance:Mean"Mean"|wggradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"'"GatherV2_2:GatherV2"GatherV2"WRHmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/sub:Sub"Sub"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/sub/Neg:Neg"Neg"+
&
Adam/gradients/AddN_27:AddN"AddN"gbPgradient_tape/model/transformer/decoder/dense_26/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"

vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/Tensordot/MatMul/MatMul:MatMul"MatMul"/*%EagerLocalExecute: FlushSummaryWriter"niUmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul:BatchMatMulV2"BatchMatMulV2"u
p
fgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul/Sum_1:Sum"Sum"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/truediv_1:Mul"Mul"TO7Adam/Adam/update_98/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"~qgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_3/Tensordot/MatMul/MatMul:MatMul"MatMul"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/BiasAdd:BiasAdd"BiasAdd"zu`model/transformer/encoder/encoder_layer/sequential/dense_5/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"U	P	8Adam/Adam/update_165/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pNlNcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul/Sum_1:Sum"Sum"D?3model/transformer/decoder/decoder_layer/add_1:AddV2"AddV2"UP8Adam/Adam/update_124/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"|wbmodel/transformer/encoder/encoder_layer/sequential/dense_6/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"wrhgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_1/Mul_1:Mul"Mul"D?3model/transformer/decoder/decoder_layer/add_2:AddV2"AddV2"+&Adam/gradients/AddN_33:AddN"AddN"	}	hmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_63/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"`[Qgradient_tape/model/transformer/encoder/encoder_layer_3/dropout_7/dropout/Mul:Mul"Mul"kfVmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_1:Transpose"	Transpose"snamodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/Tensordot/MatMul:MatMul"MatMul"{ngradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_55/Tensordot/MatMul/MatMul_1:MatMul"MatMul"+&Adam/gradients/AddN_23:AddN"AddN"kfVmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_3:Transpose"	Transpose"rmcgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_2/Mul:Mul"Mul"g	b	Rmodel/transformer/decoder/decoder_layer/multi_head_attention_4/transpose:Transpose"	Transpose"rhnhegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul/Sum_1:Sum"Sum"qlagradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/Tile_1:Tile"Tile"lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"\WMmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/truediv:Mul"Mul"ugradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/Tensordot/MatMul/MatMul:MatMul"MatMul"
z
jgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/transpose/transpose:Transpose"	Transpose"|gmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"P	K	Amodel/transformer/decoder/decoder_layer/dropout_9/dropout/Mul:Mul"Mul"UP8Adam/Adam/update_149/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/BiasAdd:BiasAdd"BiasAdd"d_Jmodel/transformer/decoder/dense_26/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"*	%	Adam/gradients/AddN_5:AddN"AddN"rmbgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/Tile_1:Tile"Tile"
{
gmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"sgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_4/Tensordot/MatMul/MatMul_1:MatMul"MatMul"faVmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/variance:Mean"Mean"u
p
fgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_2/Mul:Mul"Mul"SNDmodel/transformer/decoder/decoder_layer_1/dropout_14/dropout/Mul:Mul"Mul"mhUmodel/transformer/encoder/encoder_layer_1/dropout_3/dropout/GreaterEqual:GreaterEqual"GreaterEqual"zjgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/transpose_1/transpose:Transpose"	Transpose"s
n
dgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul/Sum:Sum"Sum"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul/Sum_1:Sum"Sum"vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/Tensordot/MatMul/MatMul:MatMul"MatMul"TO7Adam/Adam/update_42/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_128/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a\Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/sub:Sub"Sub"{kgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"b]Omodel/transformer/encoder/encoder_layer_2/sequential_2/dense_17/BiasAdd:BiasAdd"BiasAdd"S4O48Adam/Adam/update_110/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"D?3model/transformer/encoder/encoder_layer/add_1:AddV2"AddV2"mgradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_56/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/truediv_1:Mul"Mul"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/Tensordot/MatMul:MatMul"MatMul"TOEmodel/transformer/encoder/encoder_layer_1/dropout_2/dropout/Mul_1:Mul"Mul"	z	emodel/transformer/decoder/decoder_layer_1/sequential_5/dense_45/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"R[N[7Adam/Adam/update_71/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_154/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/BiasAdd:BiasAdd"BiasAdd" EagerExecute: Identity"wgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"rmbgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/Tile_1:Tile"Tile"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul/Sum_1:Sum"Sum"UP8Adam/Adam/update_148/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"
~
ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_3/transpose:Transpose"	Transpose"b]Omodel/transformer/decoder/decoder_layer_3/sequential_7/dense_66/BiasAdd:BiasAdd"BiasAdd"r	m	bgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/Tile_1:Tile"Tile*_pt*
_c*tf_function_call*
_p*
id*_ct*iter_num*true*autotune*parallelism*deterministic*		tracing_count*notTraced-nonXla*
element_id*

	parent_id*	step_name*group_id*selected_group_ids*is_eager"DESKTOP-90FSP9O