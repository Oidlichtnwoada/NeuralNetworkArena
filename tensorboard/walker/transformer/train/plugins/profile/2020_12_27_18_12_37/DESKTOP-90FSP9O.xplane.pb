
	/host:CPUJ:̻"ʀ["8" "]ܢ؝"]"]ލ"]+"ཽ]"왇"ܑ""Ȝ""՝""ជ"ꪟ"Ϡ"ᒡ"ա"""ݷ""""ʥ"럦"⦇""㧇"""߬"慎"""""ѭ""
ޮ""د"ʡ"갇"""Ʋ"ʃ"Ƴ"""""""ఊ"""ٸ""ڹ""溇"ٯ"""ཇ""""""""Ç"Ç"Ҍć"ć"ۆŇ"Ň"Ƈ"Ƈ"Ǉ"Ǉ"ȇ"ȇ"ɇ"ɇ"ʇ"ʇ"ˇ"
ˇ"Ƭ̇"̇"Ϧ͇"͇"·"·"χ"χ"Ї"Ї"҇"҇"Ӈ"Ӈ"ݡԇ"ԇ"Շ"Շ"և"և"պׇ"ׇ"؇"؇"ه"
ه"ڇ"ڇ"ۇ"ۇ"Ļ܇"܇"ۻ݇"݇"އ"އ"߇"""༅""Ӆ""
"""""""""·""ط"""""""Ǉ""""ì""ڬ""""""""
ڿ"""ෛ""Λ"""""Ŵ"""""Ӝ""""""""ȁ""΂""ȃ"ԑ"턈""텈""ᆈ""ۇ"⪈"툈""版"""""໫"ʍ""ʎ"ࡁ"""""""۸""׬"铈"ঔ"㔈"""ഹ"""ꗈ"ƭ"ꘈ"¡"䙈""
""""
뜈"
"ӝ"""ߟ"ޢ"
堈""졈""梈""ࣈ""Τ""楈"񩦈""""""ۼ""䶪"""᫈"餬"۬"ג"ɭ"ӆ"î"܀"Ὧ"򀰈"""󱱈"Ⲉ""㳈$"Ĵ""澵""˶""ѷ"̔"㸈""깈""޺""ػ"ಛ"ؼ"㧽"
꽈"졾"뾈""߿"""""Ҩ""È"È"Ĉ"Ĉ"ňg"ӻƈ"
ǈ"ǈ"Ȉ"
Ȉ"ԝɈ"Ɉ"ϑʈ"ʈ"ʈ"ˈ"ˈ"̈"͈"͈"Έ"Έ"ψ"ψ"Ј"Ј"ୱш"ш"ı҈"҈"ͫӈ"ӈ"Ԉ"Ԉ"Ո"Ո"ֈ"ֈ"׈"׈"؈"و"ڈ"ڈ"ۈ"ۈ"܈"܈"ำ݈"݈"ވ"ވ"ح߈"߈"""
"
"""""""൜"""""""""
""
"""""""
"""""۪""""""""""""""""""""๬""Ь""٦"""""п""Ł"""""̄"Ɔ$""֢0"ي""ʯ"掉""""a"撗"ɘ"
"♉"뱚""""ч"Н""ʞ""ן"֦"頉"હ""ţ""俤""""
Ʀ"ࢃ"̧""Ҩ""婉"ܺ"
"ӫ"ᨬ"嬉"""உ"""""α""β"ȑ"೉""
紉""絉"㰷""ø"""ɺ"߆"ܻ"ұ""۫""⾉"ࢸ"܍"ȉ"ɉ"ɉ"ʉ"Éˉ"ˉ"̉"̉"͉"͉"֮Ή"ůӉ"Ӊ"ԉ$"Չ"Չ"։"΋׉""1"  "*EagerKernelExecute 0":" ٜ" "ٜ"  "ǽ""Ї"͊["ɭҨ^""
ɀ"ɱܓ^"^"U"Έ."  "ƭ-"  " ""-"""ସ*""  "O"  " "ɯ"ƕƐ"O"̨:"ǥg"㒴""Ö"ȖĦ"̖"Ж"ۖՔu"ාu"u"ҋC"ꉍt"  "쐗t"  " ""6"
"֐""0"ܒ؞"O"
"ӌʴ"݌ʠ"ތ֟"଴0"혛"  ""  " ;|
tf_Compute̻"?֟" ٜ"  " "ٜ"  ""  "  "̬Q"  "  ""  "  ""  "  "?" ٜ"  " "ٜ"  ""  "  ""  "  "þ"  "  "	⧿C"  "  "
"  "  "뇇"  "  "+"  "  "ǇK"  "  "ؕa"  "  ""  "  "ĝ"  "  "಼g"  "  "m"  "  ""  "  "ե"  "  ""  "  "ᓫ6"  "  "靖O"  "  "鬈І"  "  "="  "  ">Ƶ#" ٜ"  " "ٜ"  "̶"  "  "븈"  "  "ැ$"  "  "ۖྥ"  "  "ǌ"  "  "϶ĈI"  "  " ň"  "  "!ˈa"  "  ""̈I"  "  "#͈$"  "  "$эΈ"  "  "%Ј"  "  "&҈"  "  "'ӈ*"  "  "(Ԉ"  "  ")Ԉ"  "  "*؈="  "  ">و" ٜ"  " "ٜ"  "+و"  "  ",ۈ"  "  "-܈"  "  "."  "  "/"  "  "0$"  "  ">" ٜ"  " "ٜ"  "1"  "  "2g"  "  "3"  "  ">" ٜ"  " "ٜ"  "4"  "  "5٥"  "  "6򜨌m"  "  "7ᮌ"  "  "8"  "  "9ַO"  "  ">" ٜ"  " "ٜ"  ":"  "  ";߬s"  "  "<龌"  "  ">\" ٜ"  " "ٜ"  "=ڣŎ"  "  ">ǎ="  "  "?Ɏ"  "  "@Ҏ"  "  "AԎ"  "  "B܎"  "  "C$"  "  ">Ľ*" ٜ"  " "ٜ"  "D"  "  "Eȏ"  "  "?Т" ٜ"  " "ٜ"  "FœX"  "  "Gy"  "  "H"  "  "If"  "  ">
" ٜ"  " "ٜ"  "J팂ๆ"  "  "K"  "  ">G" ٜ"  " "ٜ"  "L݌Շ	"  "  "Mࠊ;"  "  ">Ԗ" ٜ"  " "ٜ"  "N֖"  "  "Oٖե"  "  ">ͻ>" ٜ"  " "ٜ"  "P"  "  "Q+"  "  ">Ԓ	" ٜ"  " "ٜ"  "R"  "  "Sǘ"  "  ">֜ๆ" ٜ"  " "ٜ"  "Ts"  "  ">Փ" ٜ"  " "ٜ"  "Uܟ"  "  "V"  "  "Wŧ൫"  "  "?ഘû" ٜ"  " "ٜ"  "X緘݌"  "  "YỘI"  "  "Zๆ"  "  "[还g"  "  "\U"  "  "]Ř	"  "  "^Ϙg"  "  "_ј>"  "  "`ǡ"  "  "a"  "  "b͚"  "  "cȞU"  "  "dΟU"  "  "eΪ0"  "  "fϽ;"  "  "g["  "  "h۞"  "  "i޹ఌ"  "  "jԒ"  "  ">׭" ٜ"  " "ٜ"  "ks"  "  "l"  "  "m쇚"  "  "n"  "  "oǽC"  "  ">Ñ" ٜ"  " "ٜ"  "p"  "  "qm"  "  "r"  "  "s䛚"  "  "tƟC"  "  "uƠ"  "  "v0"  "  "w0"  "  ">ඖ" ٜ"  " "ٜ"  "x碏"  "  "y텘C"  "  "zܤ"  "  "{Ϝñ"  "  "?ܡ" ٜ"  " "ٜ"  "|"  "  "}ܒ۱"  "  ">ܳ"" ٜ"  " "ٜ"  "~׭"  "  "˳
"  "  ">׳D" ٜ"  " "ٜ"  "̸س"  "  "4"  "  "?ܵۤ" ٜ"  " "ٜ"  "ߵ"  "  "y"  "  "?ė" ٜ"  " "ٜ"  "ۋ"  "  ""  "  "?ખࢺ" ٜ"  " "ٜ"  "ז̕6"  "  "୪!"  "  "ő)"  "  "U"  "  ""  "  "ߔ"  "  ""  "  "ɱ"  "  "?" ٜ"  " "ٜ"  "ɸ"  "  "4"  "  "?ԝ" ٜ"  " "ٜ"  "հࡸq"  "  "	"  "  "?ۢщ" ٜ"  " "ٜ"  "ХȪ"  "  "ع3"  "  ">_" ٜ"  " "ٜ"  "੹T"  "  "ե"  "  "?ﾗ" ٜ"  " "ٜ"  ""  "  "?૴" ٜ"  " "ٜ"  ";֬"  "  "?Ü" ٜ"  " "ٜ"  "Ɯ"  "  "?ۘ" ٜ"  " "ٜ"  "ۛ"  "  "?" ٜ"  " "ٜ"  "ݦ"  "  "إ<"  "  "蒟#"  "  "F"  "  "ఌ"  "  ""  "  ""  "  ""  "  "?ְ" ٜ"  " "ٜ"  "೸'"  "  "؈2"  "  "઒2"  "  ""  "  "`"  "  ""  "  "%"  "  "?" ٜ"  " "ٜ"  "ن"  "  "?" ٜ"  " "ٜ"  "ण"  "  "ߊމ8"  "  "?؝" ٜ"  " "ٜ"  "뭟a"  "  "g"  "  ""  "  "찃"  "  "ױԲ"  "  "1"  "  ""  "  "9" ٜ" "ٜ"  E<
tf_Compute̻"?" ٜ"  " "ٜ"  ""  "  "̵襢"  "  "擕"  "  "ʓ칓"  "  "?̻" ٜ"  " "ٜ"  "˅"  "  "əp"  "  ""  "  "?řࣷ" ٜ"  " "ٜ"  ""  "  "1"  "  ""  "  "?ߘ" ٜ"  " "ٜ"  "ߚ|"  "  "ś["  "  ""  "  "ɔ"  "  "¶{"  "  ""  "  "鵩"  "  "ˁ"  "  "Ѓ8"  "  "\"  "  "஼!"  "  "ԎN"  "  "E"  "  "שF"  "  ";"  "  ","  "  "߇"  "  "U"  "  "ཀI"  "  "S"  "  "?" ٜ"  " "ٜ"  "ַ"  "  "ŭռ!"  "  "ϔண?"  "  ""  "  "ಖחB"  "  ""  "  "?" ٜ"  " "ٜ"  ""  "  "Ź<"  "  ""  "  "ި"  "  ""  "  ""  "  "ʲȋ"  "  "쒜"  "  "6"  "  "ɝ"  "  ""  "  "ӗ9"  "  "Ѯ2"  "  "ŶD"  "  "H"  "  "୔R"  "  ""  "  "a"  "  "愞@"  "  "."  "  "?" ٜ"  " "ٜ"  ""  "  "0"  "  "ǃ8"  "  "८儨"  "  "?"  "  "˨"  "  "?" ٜ"  " "ٜ"  ""  "  "y"  "  "ࡻ"  "  ">Οݏ" ٜ"  " "ٜ"  "ޏ"  "  "˘"  "  ""  "  "̛ـ"  "  "0"  "  ""  "  "6"  "  "*"  "  ">ᚐ-" ٜ"  " "ٜ"  "＜"  "  ""  "  ">꓏" ٜ"  " "ٜ"  "ﲒ"  "  "Ӡ
"  "  "?" ٜ"  " "ٜ"  ""  "  "ϡ"  "  ">" ٜ"  " "ٜ"  "䬫"  "  "ñ"  "  ">ᕳ" ٜ"  " "ٜ"  "峓"  "  ""  "  "?ƙ" ٜ"  " "ٜ"  "
"  "  "Ǔڄ"  "  "?Δ" ٜ"  " "ٜ"  "ڒєࢅ"  "  "Ė|"  "  "ʗ"  "  "7"  "  "?ඣ" ٜ"  " "ٜ"  ""  "  "?Ȩň" ٜ"  " "ٜ"  "Ѣ	"  "  "a"  "  "ɛ"  "  ">r" ٜ"  " "ٜ"  ""  "  "V"  "  ">䎲" ٜ"  " "ٜ"  "ݽ"  "  ""  "  "?ݩ઻" ٜ"  " "ٜ"  "ྎ"  "  "੸ʲ"  "  ">̵" ٜ"  " "ٜ"  "Ե"  "  "ٵ"  "  ">" ٜ"  " "ٜ"  ""  "  ">" ٜ"  " "ٜ"  ""  "  ">" ٜ"  " "ٜ"  "["  "  "·"  "  ""  "  "I"  "  ">" ٜ"  " "ٜ"  ""  "  ""  "  "I"  "  ""  "  "䋈0"  "  "="  "  ">à
" ٜ"  " "ٜ"  "ई"  "  ""  "  ">塶%" ٜ"  " "ٜ"  "壶
"  "  "谶O"  "  "
"  "  "򎽶="  "  "꿶˘"  "  "¶"  "  ">Ƕ#" ٜ"  " "ٜ"  "ѣ˶"  "  "׆Զ"  "  "?ʗ" ٜ"  " "ٜ"  ""  "  ""  "  "ٹb"  "  "?ͼɳ" ٜ"  " "ٜ"  "ϼD"  "  "_"  "  ""  "  "?ʋ" ٜ"  " "ٜ"  "*"  "  "ൕ5"  "  "E"  "  "'"  "  "A"  "  "֎"  "  "H"  "  ""  "  "މ8"  "  "7"  "  "طW"  "  "ܔ1"  "  "Ʋ"  "  "౅"  "  "?ۚ" ٜ"  " "ٜ"  "Ӧu"  "  "	"  "  "?҇" ٜ"  " "ٜ"  ""  "  "ب"  "  "x"  "  ""  "  "ͅǂ"  "  ""  "  "ح"  "  "̬Q"  "  "ྊv"  "  "c"  "  ""  "  ""  "  "®C"  "  ""  "  "ड़"  "  "?" ٜ"  " "ٜ"  ""  "  "8"  "  "?І" ٜ"  " "ٜ"  "ĉ"  "  "?" ٜ"  " "ٜ"  "Їĕ"  "  "C"  "  "/"  "  "飫:"  "  "Ԓ"  "  "˓""  "  ""  "  "ω"  "  "?" ٜ"  " "ٜ"  ""  "  "7"  "  "?ȸ" ٜ"  " "ٜ"  "͸"  "  "޹"  "  "?" ٜ"  " "ٜ"  ""  "  "ඤ""  "  ">p" ٜ"  " "ٜ"  "˼c"  "  "Т"  "  ">|" ٜ"  " "ٜ"  "¡x"  "  "?ŧ" ٜ"  " "ٜ"  "Ϙ"  "  "	"  "  "?" ٜ"  " "ٜ"  "ðܟ"  "  "Ƣ5"  "  "?" ٜ"  " "ٜ"  "ʤӸ-"  "  "["  "  ""  "  "?܆" ٜ"  " "ٜ"  ""  "  ""  "  "?ɕ" ٜ"  " "ٜ"  ""  "  ""  "  "ֺ΄"  "  "ଂ㓸"  "  "`"  "  ""  "  "غ"  "  "3"  "  "ꚛe"  "  "тÓ"  "  -
tf_Compute̻"?ʨ" ٜ"  " "ٜ"  ""  "  ""  "  "ȟഡ"  "  ""  "  ">" ڈ𐲚"  " "ڈ𐲚" "" "  "?" ٜ"  " "ٜ"  "ݡŇ	"  "  "m"  "  "ے"  "  ">➽" ٜ"  " "ٜ"  "挿"  "  "Ċ"  "  "۬Ǌs"  "  "Ίྥ"  "  "Ԋ"  "  "׊O"  "  ">ɧ" ٜ"  " "ٜ"  ""  "  ""  "  ">" ٜ"  " "ٜ"  ""  "  "a"  "  ""  "  ""  "  "["  "  ">" ٜ"  " "ٜ"  "൫"  "  ""  "  "̫"  "  ">
" ٜ"  " "ٜ"  ""  "  "⅛"  "  "?ǐ" ٜ"  " "ٜ"  "ɐ_"  "  "V"  "  "ϐʎ"  "  "혏"  "  ">ƿӖ>" ٜ"  " "ٜ"  "Ԗ"  "  "ޖz"  "  "ߖO"  "  "0"  "  "$"  "  "a"  "  ""  "  "I"  "  ""  "  "셗"  "  "Ɏ"  "  ">" ٜ"  " "ٜ"  "ē"  "  "ʦǌ"  "  ""  "  "˛"  "  "Ǣa"  "  ">" ٜ"  " "ٜ"  ""  "  ""  "  "?ώ" ٜ"  " "ٜ"  "
"  "  "Ǩ"  "  "?ƌ" ٜ"  " "ٜ"  "Ѣ	"  "  ""  "  ">ʉ" ٜ"  " "ٜ"  ""  "  "	"  "  ">ر" ٜ"  " "ٜ"  "ڱٓ"  "  "ì"  "  "˘"  "  ""  "  "҉a"  "  ""  "  ">(" ٜ"  " "ٜ"  "֨"  "  "a"  "  "["  "  "0"  "  "$"  "  "a"  "  ""  "  "ۚC"  "  "҅"  "  "܏"  "  "?ŧ" ٜ"  " "ٜ"  "ਗ਼"  "  ""  "  "ӱ"  "  ""  "  "O"  "  "­"  "  "?ݘ" ٜ"  " "ٜ"  "ۂ屒"  "  "?ન" ٜ"  " "ٜ"  "͐"  "  "͈A"  "  "%"  "  "S"  "  ""  "  "˳"  "  ""  "  ""  "  "?ݳ" ٜ"  " "ٜ"  "%"  "  "ؚ4"  "  "X"  "  "̀ʉ"  "  "c"  "  "Ё"  "  "ا{"  "  ""  "  ""  "  "Ì"  "  "?̖" ٜ"  " "ٜ"  "ϖ~"  "  "ї	"  "  "?" ٜ"  " "ٜ"  "Üݕ"  "  "Бߝ"  "  "?ආ؜" ٜ"  " "ٜ"  "ɬ+"  "  "ٞe"  "  ""  "  "?ʟ
" ٜ"  " "ٜ"  "˟ࠊ;"  "  "׉2"  "  "Šԭ4"  "  "Ѷ"  "  "ɡ9"  "  ""  "  "ҕL"  "  ""  "  "Ǯ "  "  "Ù8"  "  "ۨӹy"  "  "׎שѴ9"  "  "┪"  "  ""  "  "?ଧĒ" ٜ"  " "ٜ"  "D"  "  "ӫ>"  "  "ŕ"  "  "?ٛѸ" ٜ"  " "ٜ"  "ǜ<"  "  "٬1"  "  "ɓ."  "  "ŭ"  "  "խ;"  "  "۾"  "  "ϯE"  "  ""  "  ""  "  "ݭ"  "  "?ԁ" ٜ"  " "ٜ"  ""  "  ""  "  ">ұz" ٜ"  " "ٜ"  "ઁt"  "  "?ߍ" ٜ"  " "ٜ"  "̼ӕ"  "  j3
tf_Compute̻"?ź" ٜ"  " "ٜ"  "؆"  "  ""  "  "ź"  "  ""  "  ">w" ڈ𐲚"  " "ڈ𐲚" "T" "  "9ܴ
" ڈ𐲚" "ڈ𐲚" "?
" ٜ"  " "ٜ"  "Õ"  "  "嗬"  "  "f"  "  ">ъ9" ٜ"  " "ٜ"  "ӊ"  "  "ڊ"  "  "݊C"  "  "ފ"  "  "C"  "  ""  "  ""  "  "$"  "  "ٿІ"  "  "ୃ"  "  "O"  "  "0"  "  ""  "  "͐"  "  "ʗ"  "  "6"  "  "π"  "  "脋"  "  "ЊU"  "  ">֟p" ٜ"  " "ٜ"  "࿬"  "  ""  "  "$"  "  ""  "  ""  "  "Ɩ$"  "  "򏗋"  "  "C"  "  "Ԏ"  "  ""  "  "ˋ"  "  "ݣ$"  "  "ˑ"  "  "s"  "  "՞C"  "  "ޘ$"  "  ""  "  ""  "  "͙"  "  ""  "  ""  "  ""  "  "a"  "  "> " ٜ"  " "ٜ"  ""  "  ""  "  ""  "  ""  "  "ǆ"  "  "쵈0"  "  ""  "  "Î"  "  "O"  "  ""  "  "֓"  "  ""  "  ""  "  ""  "  "ྦ"  "  "י"  "  "C"  "  ">1" ٜ"  " "ٜ"  "̫"  "  ""  "  "܂="  "  "Ì"  "  "Ɍ6"  "  "ʌࣷ"  "  "͌"  "  "ь$"  "  "Ҍ"  "  "֌"  "  "׌["  "  "ӽ،*"  "  "ٌ"  "  "ی"  "  "݌"  "  "ߌ"  "  ""  "  ""  "  "6"  "  ">էo" ٜ"  " "ٜ"  ""  "  ""  "  "$"  "  ""  "  "s"  "  ""  "  ""  "  "൵I"  "  ""  "  ""  "  ""  "  "Í$"  "  "č"  "  "Ǎ"  "  "ɍI"  "  "ަʍ$"  "  "ʍ"  "  "̍"  "  "΍"  "  "Ѝ"  "  "Ѝ"  "  "э"  "  "૖Ս0"  "  ">Ս"" ٜ"  " "ٜ"  "֍"  "  "వ؍"  "  "ڍ$"  "  "ڍ"  "  "հ"  "  "0"  "  ""  "  "g"  "  "O"  "  ""  "  ""  "  ""  "  ""  "  ""  "  "Ï"  "  ""  "  "="  "  ">C" ٜ"  " "ٜ"  ""  "  "˘"  "  "ĵ"  "  "ڵ""  "  ""  "  "ԣ"  "  "èๆ"  "  "Հ"  "  "ہm"  "  ""  "  "ѳs"  "  "򔶎O"  "  ""  "  ""  "  "C"  "  "*"  "  ">" ٜ"  " "ٜ"  ""  "  "$"  "  "ఌ"  "  ">Ŏ" ٜ"  " "ٜ"  "Ŏ*"  "  "ǎO"  "  "Ȏ"  "  ">Ύఌ" ٜ"  " "ٜ"  "ώ"  "  "ώ"  "  ">َ
" ٜ"  " "ٜ"  "َ̿"  "  "ݎ"  "  ">Ө" ٜ"  " "ٜ"  ""  "  ""  "  ">	" ٜ"  " "ٜ"  ""  "  "ಚ"  "  ">ҏ" ٜ"  " "ٜ"  "֏"  "  ">" ٜ"  " "ٜ"  "ϋ൫"  "  "󤫑m"  "  "֯"  "  ""  "  "O"  "  "ছ"  "  "ƼC"  "  ""  "  ">!" ٜ"  " "ٜ"  ""  "  "["  "  ""  "  ""  "  ""  "  ">ɔ" ٜ"  " "ٜ"  "˘"  "  ""  "  "Ě"  "  "唡Ԓ"  "  "Ч["  "  ">" ٜ"  " "ٜ"  "Ƨ"  "  "嫒"  "  "歒"  "  ""  "  "򼵒O"  "  ""  "  "O"  "  "Է6"  "  ">ݱ" ٜ"  " "ٜ"  ""  "  "оU"  "  ">" ٜ"  " "ٜ"  ""  "  "Ò"  "  "ॕǒ"  "  ">̒8" ٜ"  " "ٜ"  "͒m"  "  "Β["  "  "В["  "  "ђ"  "  "Ւ"  "  ""  "  ""  "  "["  "  "ఁz"  "  ">Ѕ	" ٜ"  " "ٜ"  "ǲU"  "  "ׇ"  "  "ǔ"  "  ""  "  "쭎0"  "  ">ڛ" ٜ"  " "ٜ"  "ޏ"  "  "Ů="  "  ""  "  "ېǌ"  "  "0"  "  "晓"  "  "*"  "  "0"  "  ">Й" ٜ"  " "ٜ"  "Ԟ"  "  "Հz"  "  ">褓" ٜ"  " "ٜ"  ""  "  ""  "  "ݽ"  "  "?ұ݄" ٜ"  " "ٜ"  "ʕ["  "  "g"  "  "["  "  "g"  "  ""  "  "֪s"  "  "ēW"  "  ""  "  "鶔"  "  ""  "  "Ĕ"  "  "Ɣ؞"  "  "๣ȔC"  "  "ʔ࠿S"  "  ""  "  ""  "  "Ғǌ"  "  "ܿ"  "  ">Õ" ٜ"  " "ٜ"  "ĕ["  "  "ŕ"  "  "Ǖ"  "  "˕"  "  "ϕa"  "  ">Е" ٜ"  " "ٜ"  "Őѕ"  "  "ฝՕC"  "  "֕"  "  "ٕ"  "  "ܕC"  "  "ݕ"  "  "ߕO"  "  "ß0"  "  ">" ٜ"  " "ٜ"  ""  "  "C"  "  ">
" ٜ"  " "ٜ"  "Ύ"  "  ""  "  ""  "  ">*" ٜ"  " "ٜ"  "ǯఌ"  "  "m"  "  ""  "  "ఌ"  "  "ߤ"  "  "I"  "  "Ԧ"  "  "*"  "  ""  "  ">G" ٜ"  " "ٜ"  "ȟ"  "  "="  "  ">" ٜ"  " "ٜ"  "ǌ"  "  "̍"  "  ">ۊ" ٜ"  " "ٜ"  "Ջ"  "  "ܐ"  "  ">ͣ" ٜ"  " "ٜ"  "ͤ
"  "  ""  "  ""  "  "?Ҩŗ" ٜ"  " "ٜ"  "Ɨz"  "  ""  "  ">Ș-" ٜ"  " "ٜ"  "ɘ"  "  "ಊӘȶ!"  "  "?ԑÙ" ٜ"  " "ٜ"  "ْəV"  "  "٢ފ"  "  ""  "  "ӂǴ9"  "  "?ޟ" ٜ"  " "ٜ"  "j"  "  "t"  "  ""  "  ""  "  ">ѹu" ٜ"  " "ٜ"  "ҹf"  "  "	"  "  "?" ٜ"  " "ٜ"  "Ź"  "  "	"  "  "?끖ט" ٜ"  " "ٜ"  "֔"  "  "?" ٜ"  " "ٜ"  "뵞%"  "  "e"  "  "൫"  "  "?ֵ" ٜ"  " "ٜ"  "*"  "  "3"  "  "B"  "  ""  "  "i"  "  "ɏ"  "  "X"  "  ""  "  "ի"  "  ""  "  ">྅v" ٜ"  " "ٜ"  "f"  "  "ۼ	"  "  "?" ٜ"  " "ٜ"  ""  "  "?
" ٜ"  " "ٜ"  "૒	"  "  ":"  "  "?" ٜ"  " "ٜ"  "A"  "  "ژS"  "  ""  "  "?" ٜ"  " "ٜ"  ""  "  "߄A"  "  "?یԠ" ٜ"  " "ٜ"  "ًߌ"  "  "ב	"  "  "?֖" ٜ"  " "ٜ"  "ݖ"  "  "%"  "  "?" ٜ"  " "ٜ"  "֒"  "  "䠜""  "  "?" ٜ"  " "ٜ"  "飨"  "  "?Ǹ" ٜ"  " "ٜ"  "˸ׄ"  "  "าӺ3"  "  "?ŋ" ٜ"  " "ٜ"  "ҍ҈"  "  "ଫJ"  "  ""  "  "?" ٜ"  " "ٜ"  "c"  "  "<"  "  "?" ٜ"  " "ٜ"  "ˎঌ"  "  "̹	"  "  "?ྣ" ٜ"  " "ٜ"  ""  "  "?ˣ" ٜ"  " "ٜ"  "ܝ"  "  "9"  "  "?ʥ" ٜ"  " "ٜ"  "ס"  "  "۵U"  "  "஝"  "  ""  "  4{
tf_Compute̻"?֟" ٜ"  " "ٜ"  ""  "  ""  "  ""  "  "΃"  "  "?" ٜ"  " "ٜ"  "؛3"  "  "D"  "  "ź["  "  "â"  "  ""  "  "ˉ%"  "  "?瞅" ٜ"  " "ٜ"  ""  "  "Њ""  "  "K"  "  "?Ԝ" ٜ"  " "ٜ"  ""  "  "ힹU"  "  "ĉ"  "  "?ᤫ" ٜ"  " "ٜ"  "֪"  "  "ͬ"  "  "6"  "  "ʿ"  "  "ߣf"  "  ""  "  "蠰"  "  "ܣƱ%"  "  "<"  "  "ԯD"  "  "ʤF"  "  "e"  "  "ڦ="  "  ""  "  "z"  "  "H"  "  ""  "  "?" ٜ"  " "ٜ"  "˽"  "  "̸Ϲ'"  "  ""  "  "?ę" ٜ"  " "ٜ"  "҈"  "  " "  "  ""  "  "?א
" ٜ"  " "ٜ"  "ȫ"  "  ""  "  "7"  "  ""  "  "ŉZ"  "  "$"  "  "{"  "  ""  "  "="  "  "Ǿ3"  "  "B"  "  "C"  "  "ٟM"  "  "կ"  "  "["  "  "A"  "  "݆ї"  "  "?Ĳ	" ٜ"  " "ٜ"  ""  "  "鲀x"  "  ""  "  ">" ٜ"  " "ٜ"  ""  "  ""  "  ">ˏ" ٜ"  " "ٜ"  "̏"  "  "ԏ"  "  ">ב=" ٜ"  " "ٜ"  "۹"  "  "é$"  "  ">Бp" ٜ"  " "ٜ"  "ԑ	"  "  "ߑ_"  "  ">ߕZ" ٜ"  " "ٜ"  "T"  "  "엓଱"  "  ">" ٜ"  " "ٜ"  "ǽ"  "  "â"  "  "?" ٜ"  " "ٜ"  "ɠ"  "  ""  "  "?ѕ" ٜ"  " "ٜ"  "ҕ"  "  ">:" ٜ"  " "ٜ"  ""  "  "+"  "  ">З" ٜ"  " "ٜ"  "ԗ"  "  "ڗ"  "  ">" ٜ"  " "ٜ"  ""  "  ""  "  ">p" ٜ"  " "ٜ"  ""  "  "^"  "  ">Ɨ" ٜ"  " "ٜ"  "靉"  "  ""  "  ">ʕ" ٜ"  " "ٜ"  "ಲa"  "  ">ɔ" ٜ"  " "ٜ"  "˘"  "  "ޜ"  "  "ޟ"  "  "?" ٜ"  " "ٜ"  "ਗ਼"  "  "㑭="  "  "Ȯz"  "  ""  "  "
"  "  "˚"  "  "ٽך["  "  "ਓٚȁ	"  "  "s"  "  "ҭO"  "  "0"  "  "$"  "  "O"  "  ""  "  "="  "  ""  "  "'"  "  ">ܬ'" ٜ"  " "ٜ"  "Ǝñ"  "  "๛Ǳ"  "  "ߋֱ"  "  "ر"  "  "ܱ"  "  "ਠ"  "  "?ԅ" ٜ"  " "ٜ"  "	"  "  ""  "  ""  "  ""  "  ""  "  ""  "  "ߴ̾	"  "  "ò "  "  "ࡷـ"  "  ""  "  ">" ٜ"  " "ٜ"  ""  "  ""  "  ">K" ٜ"  " "ٜ"  "є"  "  "۹"  "  ""  "  "ȳ"  "  "γ"  "  "ԳÓ"  "  ">Ȏܳγ" ٜ"  " "ٜ"  "ܳ"  "  "߳଱"  "  "["  "  "݌"  "  "a"  "  "0"  "  ">" ٜ"  " "ٜ"  "ـ"  "  "I"  "  ">." ٜ"  " "ٜ"  ""  "  ""  "  "ఌ"  "  "0"  "  "z"  "  "U"  "  "g"  "  "؂"  "  "̢آ"  "  "?ɵ" ٜ"  " "ٜ"  "˵"  "  "ٱ"  "  ">Ӵ" ٜ"  " "ٜ"  "	"  "  "ŭa"  "  ""  "  "剷"  "  ">Ǐh" ٜ"  " "ٜ"  "޵"  "  "]"  "  
tf_Compute̻"?" ٜ"  " "ٜ"  ">ת" ٜ"  " "ٜ"  "Ѭ"  "  ">环" ٜ"  " "ٜ"  "ƲU"  "  ">ע" ٜ"  " "ٜ"  "I"  "  ">" ٜ"  " "ٜ"  "Ǻ0"  "  ">µ" ٜ"  " "ٜ"  "0"  "  ">Լఌ" ٜ"  " "ٜ"  "6"  "  ">" ٜ"  " "ٜ"  "="  "  ">" ٜ"  " "ٜ"  ""  "  ">˘" ٜ"  " "ٜ"  "C"  "  ">ఌ" ٜ"  " "ٜ"  "C"  "  ">ఌ" ٜ"  " "ٜ"  "ಫ6"  "  ">؞" ٜ"  " "ٜ"  "="  "  ">" ٜ"  " "ٜ"  "0"  "  ">" ٜ"  " "ٜ"  "="  "  ">" ٜ"  " "ٜ"  "C"  "  ">" ٜ"  " "ٜ"  "C"  "  ">˘" ٜ"  " "ٜ"  "I"  "  ">ఌ" ٜ"  " "ٜ"  "6"  "  "=ളs" ٜ"  " "ٜ"  "$"  "  ">" ٜ"  " "ٜ"  "I"  "  ">˘" ٜ"  " "ٜ"  "C"  "  ">" ٜ"  " "ٜ"  "*"  "  ">" ٜ"  " "ٜ"  "6"  "  ">ఌ" ٜ"  " "ٜ"  "6"  "  ">" ٜ"  " "ٜ"  "ڐI"  "  ">" ٜ"  " "ٜ"  "O"  "  ">ఌ" ٜ"  " "ٜ"  "="  "  ">ఌ" ٜ"  " "ٜ"  "="  "  ">" ٜ"  " "ٜ"  "༞0"  "  "=z" ٜ"  " "ٜ"  "*"  "  ">ܘ" ٜ"  " "ٜ"  "C"  "  ">" ٜ"  " "ٜ"  "0"  "  ">" ٜ"  " "ٜ"  "0"  "  ">" ٜ"  " "ٜ"  "6"  "  ">؞" ٜ"  " "ٜ"  "="  "  ">˘" ٜ"  " "ٜ"  "I"  "  ">" ٜ"  " "ٜ"  "C"  "  ">؞" ٜ"  " "ٜ"  "O"  "  ">" ٜ"  " "ٜ"  "="  "  ">˘" ٜ"  " "ٜ"  "ਜ਼="  "  ">" ٜ"  " "ٜ"  "I"  "  ">" ٜ"  " "ٜ"  "U"  "  ">" ٜ"  " "ٜ"  "a"  "  ">" ٜ"  " "ٜ"  "0"  "  ">" ٜ"  " "ٜ"  "ૣ0"  "  "=s" ٜ"  " "ٜ"  "*"  "  ">བྷఌ" ٜ"  " "ٜ"  "Ԅ="  "  ">" ٜ"  " "ٜ"  "*"  "  ">" ٜ"  " "ٜ"  "0"  "  ">ఌ" ٜ"  " "ٜ"  "Ո6"  "  ">О" ٜ"  " "ٜ"  "Պ="  "  ">Ë" ٜ"  " "ٜ"  "຀6"  "  ">" ٜ"  " "ٜ"  "୫0"  "  ">ఌ" ٜ"  " "ٜ"  "Ў6"  "  "=z" ٜ"  " "ٜ"  "0"  "  ">А" ٜ"  " "ٜ"  "쟑U"  "  "=z" ٜ"  " "ٜ"  "ݒ0"  "  ">ē" ٜ"  " "ٜ"  "6"  "  ">ݔ" ٜ"  " "ٜ"  "ݗ6"  "  ">Ř" ٜ"  " "ٜ"  "鈙0"  "  ">" ٜ"  " "ٜ"  "="  "  "=z" ٜ"  " "ٜ"  "0"  "  ">ᡜ؞" ٜ"  " "ٜ"  "="  "  "=ޝs" ٜ"  " "ٜ"  "叞*"  "  "=m" ٜ"  " "ٜ"  "$"  "  ">" ٜ"  " "ٜ"  "Ԯ0"  "  ">" ٜ"  " "ٜ"  "ǡ="  "  ">؞" ٜ"  " "ٜ"  "I"  "  ">" ٜ"  " "ٜ"  "="  "  ">" ٜ"  " "ٜ"  "ԥ="  "  ">" ٜ"  " "ٜ"  "0"  "  ">" ٜ"  " "ٜ"  "ޝ0"  "  ">" ٜ"  " "ٜ"  "6"  "  ">ఌ" ٜ"  " "ٜ"  "۪C"  "  ">ȫఌ" ٜ"  " "ٜ"  "6"  "  ">" ٜ"  " "ٜ"  "ɯC"  "  ">ӽ" ٜ"  " "ٜ"  "0"  "  "=ܱz" ٜ"  " "ٜ"  "$"  "  "=z" ٜ"  " "ٜ"  "ॳ0"  "  ">" ٜ"  " "ٜ"  "C"  "  "=s" ٜ"  " "ٜ"  "*"  "  "=ʶz" ٜ"  " "ٜ"  "ꁷ0"  "  "=z" ٜ"  " "ٜ"  "6"  "  ">" ٜ"  " "ٜ"  "6"  "  ">" ٜ"  " "ٜ"  "ݺ6"  "  ">ǿ" ٜ"  " "ٜ"  "*"  "  ">޼ఌ" ٜ"  " "ٜ"  "0"  "  ">" ٜ"  " "ٜ"  "="  "  "=z" ٜ"  " "ٜ"  "*"  "  "=z" ٜ"  " "ٜ"  "0"  "  ">؞" ٜ"  " "ٜ"  "I"  "  "=z" ٜ"  " "ٜ"  "0"  "  ">ـ" ٜ"  " "ٜ"  "0"  "  ">" ٜ"  " "ٜ"  "0"  "  ">" ٜ"  " "ٜ"  "="  "  ">" ٜ"  " "ٜ"  "6"  "  ">" ٜ"  " "ٜ"  "*"  "  ">" ٜ"  " "ٜ"  "="  "  ">" ٜ"  " "ٜ"  "="  "  ">" ٜ"  " "ٜ"  "0"  "  ">ఌ" ٜ"  " "ٜ"  "6"  "  ">ن" ٜ"  " "ٜ"  "н0"  "  "=z" ٜ"  " "ٜ"  "*"  "  ">" ٜ"  " "ٜ"  "C"  "  ">ఌ" ٜ"  " "ٜ"  "="  "  "=࿾s" ٜ"  " "ٜ"  "*"  "  ">" ٜ"  " "ٜ"  "0"  "  ">˘" ٜ"  " "ٜ"  "ͦI"  "  ">ఌ" ٜ"  " "ٜ"  "C"  "  ">" ٜ"  " "ٜ"  "༧="  "  ""  "  ""  "  "؞"  "  "໘"  "  ">" ٜ"  " "ٜ"  "C"  "  ">" ٜ"  " "ٜ"  "Ӎ6"  "  ">" ٜ"  " "ٜ"  "I"  "  ">¬؞" ٜ"  " "ٜ"  "6"  "  "=z" ٜ"  " "ٜ"  "Ԡ0"  "  ">ఌ" ٜ"  " "ٜ"  "6"  "  ">؞" ٜ"  " "ٜ"  "I"  "  ">" ٜ"  " "ٜ"  "6"  "  ">" ٜ"  " "ٜ"  "Ƅ0"  "  ">槅" ٜ"  " "ٜ"  "0"  "  ">҆" ٜ"  " "ٜ"  "щ="  "  ">" ٜ"  " "ٜ"  "ථ6"  "  ">" ٜ"  " "ٜ"  "͉0"  "  ">֨" ٜ"  " "ٜ"  "*"  "  ">ǋ˘" ٜ"  " "ٜ"  "="  "  ">㐍" ٜ"  " "ٜ"  "U"  "  ">" ٜ"  " "ٜ"  "0"  "  ">" ٜ"  " "ٜ"  "6"  "  ">Γ˘" ٜ"  " "ٜ"  "0"  "  ">" ٜ"  " "ٜ"  "="  "  "=᪖z" ٜ"  " "ٜ"  "*"  "  "=×z" ٜ"  " "ٜ"  "0"  "  ">˽ఌ" ٜ"  " "ٜ"  "݀0"  "  ">˘" ٜ"  " "ٜ"  "귛6"  "  ">ྙ" ٜ"  " "ٜ"  "C"  "  "=z" ٜ"  " "ٜ"  "*"  "  "=هz" ٜ"  " "ٜ"  "ø6"  "  "=s" ٜ"  " "ٜ"  "נ*"  "  ">㲡" ٜ"  " "ٜ"  "0"  "  ">ݢ" ٜ"  " "ٜ"  "ښ"  "  ">" ٜ"  " "ٜ"  ""  "  ">" ٜ"  " "ٜ"  "ͬ"  "  ">" ٜ"  " "ٜ"  "ӯ݌"  "  ">" ٜ"  " "ٜ"  "6"  "  "=۹s" ٜ"  " "ٜ"  "࿒*"  "  ">ఌ" ٜ"  " "ٜ"  "*"  "  ">쒼" ٜ"  " "ٜ"  "6"  "  ">" ٜ"  " "ٜ"  "$"  "  ">" ٜ"  " "ٜ"  "0"  "  ">ξ" ٜ"  " "ٜ"  "="  "  "=z" ٜ"  " "ٜ"  "	0"  "  ">" ٜ"  " "ٜ"  "	"  "  ">" ٜ"  " "ٜ"  "	6"  "  "=z" ٜ"  " "ٜ"  "	Е0"  "  ">ُ؞" ٜ"  " "ٜ"  "	C"  "  ">" ٜ"  " "ٜ"  "	I"  "  ">" ٜ"  " "ٜ"  "	6"  "  "	ڢ"  "  "	m"  "  "	s"  "  ">" ٜ"  " "ٜ"  "	*"  "  ">ఌ" ٜ"  " "ٜ"  "	="  "  "=z" ٜ"  " "ٜ"  "	6"  "  "=s" ٜ"  " "ٜ"  "	0"  "  ">" ٜ"  " "ٜ"  "	0"  "  "=s" ٜ"  " "ٜ"  "	*"  "  ">" ٜ"  " "ٜ"  "	="  "  ">Й" ٜ"  " "ٜ"  "	I"  "  ">ൾ" ٜ"  " "ٜ"  "	="  "  "=z" ٜ"  " "ٜ"  "	0"  "  ">" ٜ"  " "ٜ"  "	U"  "  ">ఌ" ٜ"  " "ٜ"  "	6"  "  "=z" ٜ"  " "ٜ"  "	6"  "  ">" ٜ"  " "ٜ"  "	Ĺ0"  "  "=m" ٜ"  " "ٜ"  "	*"  "  ">ɧ" ٜ"  " "ٜ"  "	*"  "  ">" ٜ"  " "ٜ"  "	6"  "  "=z" ٜ"  " "ٜ"  "	*"  "  ">" ٜ"  " "ٜ"  "	Ů*"  "  "=m" ٜ"  " "ٜ"  "	*"  "  "=ௐs" ٜ"  " "ٜ"  "	*"  "  ">" ٜ"  " "ٜ"  "	="  "  "=z" ٜ"  " "ٜ"  "	0"  "  ">Ī"" ٜ"  " "ٜ"  "	؄"  "  "	ๆ"  "  "	"  "  "	z"  "  ">Μ" ٜ"  " "ٜ"  "	"  "  "	"  "  "	"  "  "	袻O"  "  ">" ٜ"  " "ٜ"  "	"  "  "	˘"  "  "	ܕ"  "  "	a"  "  ">Ǩٗ" ٜ"  " "ٜ"  "	"  "  "	"  "  "	"  "  "	I"  "  ">ȅ " ٜ"  " "ٜ"  "	"  "  "	˘"  "  "	"  "  "	Śఌ"  "  ">!" ٜ"  " "ٜ"  "	Ŝ"  "  "	˘"  "  "	"  "  "	U"  "  ">" ٜ"  " "ٜ"  "	ؾ"  "  "	؞"  "  "	ه"  "  "	I"  "  ">" ٜ"  " "ٜ"  "	"  "  "	"  "  "	"  "  "	U"  "  ">સ౅" ٜ"  " "ٜ"  "	"  "  "	ɘ"  "  "	Ӓ"  "  "	0"  "  ">ܜ'" ٜ"  " "ٜ"  "	"  "  "	"  "  "	"  "  "	ɍU"  "  ">-" ٜ"  " "ٜ"  "	"  "  "	"  "  "	"  "  "	I"  "  "	["  "  "	"  "  "	"  "  "	"  "  ">" ٜ"  " "ٜ"  "	"  "  "	"  "  "	*"  "  ">ɯ?" ٜ"  " "ٜ"  "	ـ"  "  "	৪ఌ"  "  "	ᰁ"  "  "	྽	"  "  "	6"  "  "	"  "  "	ܕ"  "  "	0"  "  "	"  "  "	ͼ"  "  "	ä="  "  "	U"  "  "	զ଱"  "  "	ʪݽ"  "  "	į"  "  "	C"  "  "	O"  "  "	戴"  "  "	I"  "  ">" ٜ"  " "ٜ"  "	պ"  "  "	ǽ"  "  "	0"  "  "	"  "  "	؞"  "  "	*"  "  "> " ٜ"  " "ٜ"  "	"  "  "	؞"  "  "	"  "  "	m"  "  ">" ٜ"  " "ٜ"  "	"  "  "	˘"  "  "	컇"  "  "	ɗ6"  "  "?" ٜ"  " "ٜ"  "	Ί͘"  "  "	೤"  "  "	"  "  "	˂"  "  ">" ڈ𐲚"  " "ڈ𐲚" "	" "  "?" ٜ"  " "ٜ"  "	"  "  "	мg"  "  "	ó"  "  ">ů" ٜ"  " "ٜ"  "	"  "  "	۫"  "  ">ߑઓ)" ٜ"  " "ٜ"  "	"  "  "
g"  "  "
ңI"  "  "
Η$"  "  "
"  "  "
U"  "  "
"  "  "
s"  "  "
͠"  "  "?͉" ٜ"  " "ٜ"  "
ٓ"  "  "
˻"  "  ">ѓ|" ٜ"  " "ٜ"  "
ғ"  "  "
ٓs"  "  "?ѻ" ٜ"  " "ٜ"  "
"  "  "
ĕ"  "  ">" ٜ"  " "ٜ"  "
Ԓ"  "  "
"  "  ">গ." ٜ"  " "ٜ"  "
׎"  "  "
̠"  "  "
Ǧñ"  "  "
"  "  "
賗"  "  "
"  "  "
"  "  "
ėI"  "  "?ɗ" ٜ"  " "ٜ"  "
ʗ"  "  "?" ٜ"  " "ٜ"  "
"  "  "
"  "  ">ǐ	" ٜ"  " "ٜ"  "
͑"  "  "
"  "  "?ۚΖ" ٜ"  " "ٜ"  "
ُ"  "  ">Ӄ" ٜ"  " "ٜ"  "
ľ"  "  ">ұ" ٜ"  " "ٜ"  "
ӱg"  "  "
Ա"  "  "
ڱ"  "  "
s"  "  "?ܜ" ٜ"  " "ٜ"  "
P"  "  "
K"  "  "
ĵ"  "  "
Ҳ"  "  ">ٹײt" ٜ"  " "ٜ"  "
ܓ۹ғq"  "  "?̄" ٜ"  " "ٜ"  "
»D"  "  "
՝%"  "  "
зԀJ"  "  "
иI"  "  "
н"  "  "
ҽ'"  "  "
"  "  "
঍"  "  "?" ٜ"  " "ٜ"  "
ִ"  "  "
$"  "  "?" ٜ"  " "ٜ"  "
׸̾"  "  "
ޞ8"  "  "?ཅ" ٜ"  " "ٜ"  "
"  "  "
+"  "  "
ǚ$"  "  "
e"  "  "
"  "  "
̖"  "  "
֯"  "  "
ե"  "  "?" ٜ"  " "ٜ"  "
ࣼ%"  "  "
ɰ4"  "  "
Ӊ*"  "  "
γ"  "  "
)"  "  "
"  "  "
R"  "  "
"  "  "
ҪN"  "  "
˯"  "  "
ԡ"  "  "
8"  "  "
"  "  "
	"  "  "?" ٜ"  " "ٜ"  "
օ"  "  "
"  "  "?ࠥ" ٜ"  " "ٜ"  "
ಙୃ"  "  "
ᯪ"  "  "
"  "  "
탑"  "  "
҃K"  "  "
Б"  "  "
ǞГ"  "  "
="  "  "
෇q"  "  "
ۛ["  "  "
k"  "  "
)"  "  "
+"  "  "
"  "  "
ݷ"  "  "?㡢ܲ" ٜ"  " "ٜ"  "
ǅ"  "  "
"  "  "?𾮦" ٜ"  " "ٜ"  "
"  "  "
"  "  ">׮w" ٜ"  " "ٜ"  "
ٮk"  "  "
ǯ"  "  "?ꣲ" ٜ"  " "ٜ"  "
"  "  "
ۣ믉"  "  "
˸"  "  "
ۺ"  "  "
w"  "  "
ᄽܔ"  "  "
"  "  "
 ༼C"  "  "
Ƀ໗"  "  "
\"  "  "
"  "  "
q"  "  "
0"  "  "
"  "  "
஄	"  "  "?ɞ" ٜ"  " "ٜ"  "
ɫ("  "  "
U"  "  "
ڣ"  "  "?ݏ" ٜ"  " "ٜ"  "
"  "  "
Ȉ?"  "  "?" ٜ"  " "ٜ"  "
⊦"  "  "
	"  "  "?О" ٜ"  " "ٜ"  "
"  "  "
"  "  UC
tf_Compute̻"?" ٜ"  " "ٜ"  "
"  "  "
ӫ]"  "  "
"  "  "
ֱ"  "  "?" ٜ"  " "ٜ"  "
	"  "  "
ōq"  "  "
"  "  ">>" ٜ"  " "ٜ"  "
"  "  ""  "  "ǂC"  "  ""  "  "O"  "  ""  "  "ێ"  "  "ݟ*"  "  ""  "  ""  "  "ޛa"  "  "6"  "  "䝉"  "  ""  "  ""  "  "$"  "  "楉"  "  ""  "  "ȫ="  "  ">Ԭn" ٜ"  " "ٜ"  "箉"  "  "ᰉ"  "  "ղ$"  "  "г"  "  "ķ"  "  "Ų$"  "  "×"  "  "؉"  "  "ډ"  "  "ޠ߉"  "  "๋"  "  "*"  "  "І"  "  ""  "  "="  "  "Ȋ*"  "  ""  "  "ԑ"  "  ""  "  "ᕊ"  "  "񑖊"  "  "Ֆ"  "  "蚊="  "  ">ۛѰ"" ٜ"  " "ٜ"  ""  "  ""  "  "֟$"  "  "ʠ"  "  ""  "  "爨0"  "  ""  "  "நg"  "  "ߴI"  "  "΢$"  "  "밊"  "  "ٲ"  "  "ഊ"  "  ""  "  ""  "  "ర"  "  "綠U"  "  ">ъ" ٜ"  " "ٜ"  "Ҋ"  "  "ي"  "  "܊C"  "  ">ࠇ" ٜ"  " "ٜ"  ""  "  ">ꮅ" ٜ"  " "ٜ"  "ե"  "  "͋"  "  "䞒Ħ"  "  ">ڭ޺9" ٜ"  " "ٜ"  "໎"  "  "Ѳ&"  "  "?" ٜ"  " "ٜ"  ""  "  "࢘s"  "  "a"  "  "ˌg"  "  "="  "  "뙂"  "  "໳C"  "  ""  "  "جๆ"  "  ""  "  "̜"  "  "֩s"  "  "ۗ"  "  "U"  "  "."  "  "["  "  "
"  "  "υ"  "  ""  "  ">ࠃ" ٜ"  " "ٜ"  "Ӝ൫"  "  ""  "  ""  "  "᫑ࣷ"  "  "̥["  "  ">叾:" ٜ"  " "ٜ"  "Ϣ݌"  "  "ȑU"  "  "ɑg"  "  "ʑ["  "  "̑z"  "  "ґ	"  "  "ݑC"  "  "ߑ	"  "  "*"  "  ""  "  "?ف" ٜ"  " "ٜ"  "ȸ"  "  "x"  "  ">ઞ	" ٜ"  " "ٜ"  "ๆ"  "  "з"  "  ">ԇ<" ٜ"  " "ٜ"  "݅	"  "  "Ɣ0"  "  ">" ٜ"  " "ٜ"  "ē"  "  "Ǔз"  "  ">͓" ٜ"  " "ٜ"  "͓"  "  "Г"  "  "?ԓ" ٜ"  " "ٜ"  "ȕՓs"  "  "ɔy"  "  "ɕз"  "  "셗/"  "  "?ӗ" ٜ"  " "ٜ"  "ԗ"  "  "s"  "  ">늛" ٜ"  " "ٜ"  ""  "  "Ӑ"  "  "?优Ҭ" ٜ"  " "ٜ"  ""  "  ""  "  "齱"  "  ">سƱ" ٜ"  " "ٜ"  "Ǳ"  "  "б"  "  "?ᐐ" ٜ"  " "ٜ"  ""  "  ""  "  ">" ٜ"  " "ٜ"  ""  "  ">૳	" ٜ"  " "ٜ"  ""  "  "̃"  "  "?" ٜ"  " "ٜ"  "ਗ਼"  "  ""  "  "แE"  "  ""  "  ""  "  ""  "  ""  "  ""  "  "a"  "  "ㆵ5"  "  "쾵z"  "  "Ƶ
"  "  "ӵ˘"  "  "ŉص"  "  "۵"  "  ">" ٜ"  " "ٜ"  "ࣷ"  "  ""  "  "a"  "  ""  "  ""  "  "̫"  "  ">ቶ_" ٜ"  " "ٜ"  ""  "  "g"  "  "ʏ؞"  "  "Г˘"  "  "⇔"  "  "Й"  "  "̠G"  "  ">Ĉ" ٜ"  " "ٜ"  "
"  "  ">䃷" ٜ"  " "ٜ"  "䄷	"  "  ">θs" ٜ"  " "ٜ"  "搷"  "  "蚷g"  "  "?۹Ņ" ٜ"  " "ٜ"  "ܹఴ"  "  "Æ8"  "  "Ʉ2"  "  "ќߘ%"  "  "Ƽ"  "  "?ƌ" ٜ"  " "ٜ"  ""  "  "m"  "  "?ܓΨ" ٜ"  " "ٜ"  "ݘ"  "  "Դ"  "  "?" ٜ"  " "ٜ"  "ߘ"  "  ""  "  "?ɺ" ٜ"  " "ٜ"  ""  "  "R"  "  ""  "  "?" ٜ"  " "ٜ"  "ถ^"  "  "3"  "  "?" ٜ"  " "ٜ"  ""  "  "Ŝ
"  "  "?ۍ" ٜ"  " "ٜ"  "ۗ'"  "  "થK"  "  ""  "  ">" ٜ"  " "ٜ"  ""  "  "߰ޟ"  "  ">Ѓ8" ٜ"  " "ٜ"  "໳ฬ-"  "  ""  "  "?ע" ٜ"  " "ٜ"  "ട"  "  ""  "  "?ୀ" ٜ"  " "ٜ"  ""  "  ""  "  "?" ٜ"  " "ٜ"  "ޅ"  "  "5"  "  "ގ"  "  ">`" ٜ"  " "ٜ"  "N"  "  "ۛ"  "  ">q" ٜ"  " "ٜ"  "Üm"  "  "?ʹԕ" ٜ"  " "ٜ"  "䐷L"  "  ""  "  "󣥞6"  "  "ݞ8"  "  ""  "  "ˠ"  "  "ɸ"  "  ""  "  "?묢֫" ٜ"  " "ٜ"  "毢׌"  "  ""  "  ">퐛j" ٜ"  " "ٜ"  "闠\"  "  ""  "  "?" ٜ"  " "ٜ"  ""  "  "ީ͠"  "  "?į" ٜ"  " "ٜ"  ""  "  ""  "  " "  "  "R"  "  "ఌ"  "  "ʒ"  "  "Ɩ"  "  "Ԡǟ"  "  "?ʳ" ٜ"  " "ٜ"  "ິ8"  "  "!"  "  "@"  "  ""  "  "Ѐ<"  "  "ʥ"  "  "M"  "  "ա"  "  "V"  "  "٤$"  "  "ڐ"  "  "I"  "  "˗"  "  ""  "  "?ఝૺ
" ٜ"  " "ٜ"  "ർ{"  "  "D"  "  ""  "  "عx"  "  ">"  "  "	"  "  "?ڿ" ٜ"  " "ٜ"  ""  "  "?" ٜ"  " "ٜ"  "్ԫ"  "  ""  "  ">%" ٜ"  " "ٜ"  ""  "  ""  "  9U
tf_Compute̻"?" ٜ"  " "ٜ"  "Ø"  "  ""  "  ""  "  "ɯ"  "  "?" ٜ"  " "ٜ"  ""  "  ""  "  "R"  "  ""  "  "?ଝ" ٜ"  " "ٜ"  "؛"  "  ""  "  ""  "  "3"  "  "꣉"  "  "˘"  "  "࡙("  "  ""  "  ""  "  "5"  "  ""  "  "?̈ǡ" ٜ"  " "ٜ"  "҈"  "  "⯨"  "  "Ɋ5"  "  "˃"  "  "J"  "  "ƍ"  "  "޿"  "  " "  "  "娛E"  "  "Y"  "  ">"  "  "ÇH"  "  "ˑ2"  "  "͝"  "  "O"  "  "苃U"  "  "ݒ|"  "  "?͊" ٜ"  " "ٜ"  "ٜ"  "  "ƕ="  "  ""  "  ""  "  "ڝn"  "  "̞ι"  "  "Ħ"  "  "ʤ"  "  "ػ>"  "  "໠ڔT"  "  "ԧ"  "  "<"  "  "F"  "  "8"  "  "ÇC"  "  "H"  "  "Ǫ"  "  "Ϫࣷ"  "  "Ӫ8"  "  "="  "  "?͵" ٜ"  " "ٜ"  "ϵ"  "  ""  "  "ķ'"  "  ""  "  "&"  "  ""  "  "?
" ٜ"  " "ٜ"  ""  "  "Ł,"  "  "5"  "  ""  "  "ˎR"  "  "%"  "  "܆"  "  ""  "  "ޜ<"  "  ""  "  "0"  "  "ܘH"  "  "I"  "  "ִ"  "  "U"  "  "/"  "  ""  "  "?" ٜ"  " "ٜ"  ""  "  "ٗ@"  "  ""  "  ""  "  "v"  "  ""  "  ""  "  ""  "  "D"  "  "ۚR"  "  "ڌ&"  "  "5"  "  "ŶD"  "  ";"  "  "྆C"  "  "L"  "  ""  "  "Ԓ"  "  "C"  "  "6"  "  "?" ٜ"  " "ٜ"  ""  "  "̑"  "  "筟/"  "  ""  "  "ཌ"  "  ""  "  ">$" ٜ"  " "ٜ"  ""  "  ""  "  "Ǉ̫"  "  "օࣷ"  "  "ۑs"  "  "ߒǽ"  "  "֗m"  "  "6"  "  ">Ŝ5" ٜ"  " "ٜ"  "ـ"  "  "ޢ["  "  "̏a"  "  "a"  "  "="  "  "޲"  "  ""  "  "	"  "  "ȏO"  "  "Ϗ"  "  ">ҏ" ٜ"  " "ٜ"  "ӏm"  "  "֏"  "  "؏"  "  "܏"  "  "ߏ="  "  ">" ٜ"  " "ٜ"  "Σ"  "  ">б" ٜ"  " "ٜ"  ""  "  ""  "  "긑"  "  ">Α" ٜ"  " "ٜ"  "Б"  "  "ԑ"  "  ">" ٜ"  " "ٜ"  ""  "  "؆"  "  ">Ď͠" ٜ"  " "ٜ"  "͈"  "  "䀒ٓ"  "  "?󖊒" ٜ"  " "ٜ"  "Ý֒"  "  "?" ٜ"  " "ٜ"  "ɢ֨"  "  ">Њ" ٜ"  " "ٜ"  "ȱ"  "  "෤
"  "  ">¦Õ
" ٜ"  " "ٜ"  "ĕ଱"  "  "̳ȕ"  "  "?Ε" ٜ"  " "ٜ"  "ϕ|"  "  "͖"  "  ">" ٜ"  " "ٜ"  "	"  "  "Ǹg"  "  "
"  "  ">" ٜ"  " "ٜ"  "㗗"  "  ">×ŅC" ٜ"  " "ٜ"  "ė"  "  "ȗU"  "  "ɗఌ"  "  "˗"  "  "̗"  "  "ӗ"  "  "Ш"  "  ""  "  "g"  "  "п"  "  ">؆" ٜ"  " "ٜ"  "s"  "  ""  "  ""  "  ""  "  "U"  "  ">Ȕ " ٜ"  " "ٜ"  "ϗ݌"  "  "U"  "  ""  "  "Ʃ"  "  "s"  "  ""  "  "ǯ="  "  "ഘI"  "  ">Øȁ	" ٜ"  " "ٜ"  "Ø"  "  "Ƙྥ"  "  "?јཱུ" ٜ"  " "ٜ"  "ĜҘ>"  "  "I"  "  "ջ"  "  "'"  "  "?Е" ٜ"  " "ٜ"  ""  "  "?ܵ" ٜ"  " "ٜ"  "޵Ɲ"  "  ">" ٜ"  " "ٜ"  "সԒ"  "  ""  "  ;tf_data_iterator_get_next̻"+" ٜ"  "  "$읂" x"  "C" 魷" x"8"	8"
 "  "䤊" "  ctf_data_iterator_resource̻"廥ߘ%" 	"+ڦ" єԢ" 魷"," ɨȍԋ" єԢ",݌" Ť" ɨȍԋ"+޲" ۗa" єԢ"+ܱ6" ԟ塄" ۗa"," ԟ塄" ۗa"Ɖ
" ڈ𐲚"9" ڈ𐲚" "ڈ𐲚" "mh^gradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/truediv/Sum:Sum"Sum"

wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/Tensordot/MatMul/MatMul:MatMul"MatMul"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_2/Sum:Sum"Sum"gbTmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_1/BiasAdd:BiasAdd"BiasAdd"U
P
8Adam/Adam/update_109/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"sn_gradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_11/ReluGrad:ReluGrad"ReluGrad"omodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"k;g;Zmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/BiasAdd:BiasAdd"BiasAdd"pkagradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/truediv:Mul"Mul"~ngradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_2/transpose:Transpose"	Transpose"		omodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"RMCgradient_tape/model/transformer/encoder/dropout_8/dropout/Mul_2:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_2/Sum:Sum"Sum"c^Tgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_15/dropout/Mul_2:Mul"Mul"~ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_1/transpose:Transpose"	Transpose"TO7Adam/Adam/update_27/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"p
k
`gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/Tile_1:Tile"Tile"WRHmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/sub:Sub"Sub"_	Z	Omodel/transformer/decoder/decoder_layer/layer_normalization_8/moments/mean:Mean"Mean"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/BiasAdd:BiasAdd"BiasAdd"}hmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"FA5model/transformer/encoder/encoder_layer_2/add_1:AddV2"AddV2"%%jmodel/transformer/decoder/decoder_layer/layer_normalization_10/moments/SquaredDifference:SquaredDifference"SquaredDifference"[VJmodel/transformer/decoder/decoder_layer/multi_head_attention_5/Equal:Equal"Equal"idTmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose:Transpose"	Transpose"ni_gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/truediv:Mul"Mul"UPFmodel/transformer/decoder/decoder_layer_3/dropout_20/dropout/Mul_1:Mul"Mul"`[Qgradient_tape/model/transformer/encoder/encoder_layer_1/dropout_3/dropout/Mul:Mul"Mul"idWmodel/transformer/decoder/decoder_layer_2/sequential_6/dense_56/Tensordot/MatMul:MatMul"MatMul"		pmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"HHygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/Tensordot/MatMul/MatMul_1:MatMul"MatMul"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Pmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/Softmax:Softmax"Softmax"83.EagerExecute: __inference_train_function_14421"wrhgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_2/Mul_1:Mul"Mul"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"

lgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/Tensordot/MatMul/MatMul_1:MatMul"MatMul"	|	gmodel/transformer/encoder/encoder_layer_2/sequential_2/dense_17/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"niUmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul:BatchMatMulV2"BatchMatMulV2"wrhgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_1/Mul_1:Mul"Mul"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/Tensordot/MatMul:MatMul"MatMul"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_2/Sum:Sum"Sum"ujqjhgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_1/Mul_1:Mul"Mul"mmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul/Sum_1:Sum"Sum"U
P
8Adam/Adam/update_136/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"{kgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/Tensordot/MatMul/MatMul:MatMul"MatMul"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_1/Mul:Mul"Mul"o
j
_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/Tile_1:Tile"Tile"+&Adam/gradients/AddN_16:AddN"AddN"vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/Tensordot/MatMul/MatMul:MatMul"MatMul"UP8Adam/Adam/update_110/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_112/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"c^Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_1:Mul"Mul"~ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_1/transpose:Transpose"	Transpose"imodel/transformer/decoder/decoder_layer/layer_normalization_9/moments/SquaredDifference:SquaredDifference"SquaredDifference"kfVmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_3:Transpose"	Transpose"rm`model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/Tensordot/MatMul:MatMul"MatMul"oj_gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/Tile_1:Tile"Tile"+
&
Adam/gradients/AddN_43:AddN"AddN"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul:Mul"Mul"[VLmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/truediv:Mul"Mul"convert_to_tensor"S	N	Dmodel/transformer/decoder/decoder_layer_1/dropout_13/dropout/Mul:Mul"Mul"NI6model/transformer/encoder/strided_slice_1:StridedSlice"StridedSlice"d_Smodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/add:AddV2"AddV2"rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_4/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"UP8Adam/Adam/update_108/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/truediv_1:Mul"Mul"UP8Adam/Adam/update_147/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"omodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgYmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/BiasAdd:BiasAdd"BiasAdd"e6a6Vmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/add_1:AddV2"AddV2"UPFmodel/transformer/decoder/decoder_layer_1/dropout_13/dropout/Mul_1:Mul"Mul"ojVmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul:BatchMatMulV2"BatchMatMulV2"		mmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"\WMgradient_tape/model/transformer/encoder/encoder_layer/dropout/dropout/Mul:Mul"Mul"lg]gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/mul_1:Mul"Mul"jmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_3/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"mh^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/Mul:Mul"Mul"oj`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/mul_1:Mul"Mul"lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"mgradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_11/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"|lgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose/transpose:Transpose"	Transpose"gbTmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_4/BiasAdd:BiasAdd"BiasAdd"rm`model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/Tensordot/MatMul:MatMul"MatMul"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul/Mul_1:Mul"Mul"		jmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_4/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"mmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_56:AddN"AddN"faWgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/mul:Mul"Mul"{ngradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_56/Tensordot/MatMul/MatMul_1:MatMul"MatMul"YTImodel/transformer/decoder/decoder_layer_2/sequential_6/dense_55/Relu:Relu"Relu"G~Gogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_2/transpose:Transpose"	Transpose"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"je[gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/Mul:Mul"Mul"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"`[Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul:Mul"Mul"ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"}	x	dmodel/transformer/decoder/decoder_layer/dropout_9/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"D?3model/transformer/decoder/decoder_layer_1/add:AddV2"AddV2"kmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/SquaredDifference:SquaredDifference"SquaredDifference"faUmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/add_1:AddV2"AddV2"~ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_2/transpose:Transpose"	Transpose"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"UPEmodel/transformer/encoder/encoder_layer_3/dropout_6/dropout/Cast:Cast"Cast"b
]
Sgradient_tape/model/transformer/encoder/encoder_layer_2/dropout_5/dropout/Mul_2:Mul"Mul"oj_gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/Tile:Tile"Tile"ca_aVgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/Sum:Sum"Sum"UP8Adam/Adam/update_159/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul/Mul:Mul"Mul"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/BiasAdd:BiasAdd"BiasAdd"wgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"FA5model/transformer/encoder/encoder_layer_1/add_1:AddV2"AddV2"|lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_3/transpose:Transpose"	Transpose"lmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/SquaredDifference:SquaredDifference"SquaredDifference"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_2/Sum:Sum"Sum"U
P
8Adam/Adam/update_125/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_54/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"idWmodel/transformer/encoder/encoder_layer_1/sequential_1/dense_11/Tensordot/MatMul:MatMul"MatMul"e
`
Vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/mul:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul/Mul_1:Mul"Mul"qmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"SOEmodel/transformer/encoder/encoder_layer_2/dropout_4/dropout/Cast:Cast"Cast"toegradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_2/Mul_1:Mul"Mul"+&Adam/gradients/AddN_40:AddN"AddN"b	]	Qmodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/add:AddV2"AddV2"UPEmodel/transformer/encoder/encoder_layer_1/dropout_3/dropout/Cast:Cast"Cast"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_2/Mul:Mul"Mul"TO7Adam/Adam/update_65/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"mh]gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/Tile:Tile"Tile"+
&
Adam/gradients/AddN_35:AddN"AddN"^	Y	Omodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/sub:Sub"Sub"a\Ogradient_tape/model/transformer/decoder/dense_26/Tensordot/MatMul/MatMul:MatMul"MatMul"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"snamodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/Tensordot/MatMul:MatMul"MatMul"c-_-Tmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/add_1:AddV2"AddV2"b]Smodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_2:Mul"Mul"lgYmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/BiasAdd:BiasAdd"BiasAdd"+&Adam/gradients/AddN_31:AddN"AddN"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_1:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_2/Sum:Sum"Sum"zfmodel/transformer/encoder/encoder_layer_3/dropout_6/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"		omodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"PPxgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/Tensordot/MatMul/MatMul_1:MatMul"MatMul"lg]gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/sub:Sub"Sub"kmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"kmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/SquaredDifference:SquaredDifference"SquaredDifference"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"mh^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/sub:Sub"Sub"qlagradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/Tile_1:Tile"Tile"ni\model/transformer/encoder/encoder_layer/multi_head_attention/dense_4/Tensordot/MatMul:MatMul"MatMul"

vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/Tensordot/MatMul/MatMul:MatMul"MatMul"mgradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_23/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"		Adam/Pow:Pow"Pow"TOEmodel/transformer/encoder/encoder_layer_3/dropout_6/dropout/Mul_1:Mul"Mul"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/Tensordot/MatMul/MatMul_1:MatMul"MatMul"rmbgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/Tile_1:Tile"Tile"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/sub/Neg:Neg"Neg"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"qrmrdgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul/Mul:Mul"Mul"|gmodel/transformer/decoder/decoder_layer_3/sequential_7/dense_65/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"E@2model/transformer/decoder/dense_26/BiasAdd:BiasAdd"BiasAdd"s
n
dgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul/Sum:Sum"Sum"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/sub/Sum:Sum"Sum"vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/Tensordot/MatMul/MatMul:MatMul"MatMul"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul/Sum_1:Sum"Sum"snamodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/Tensordot/MatMul:MatMul"MatMul"T
O
7Adam/Adam/update_11/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"wrhgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_1/Mul_1:Mul"Mul"TO7Adam/Adam/update_44/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_80/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_70/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Omodel/transformer/decoder/decoder_layer_2/sequential_6/dense_56/BiasAdd:BiasAdd"BiasAdd"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/truediv_1:Mul"Mul"b^Smodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/add_1:AddV2"AddV2"e`Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/add:AddV2"AddV2"kfVmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_3:Transpose"	Transpose"TO7Adam/Adam/update_83/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"n
i
_gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/mul_1:Mul"Mul"idWmodel/transformer/decoder/decoder_layer_3/sequential_7/dense_66/Tensordot/MatMul:MatMul"MatMul"ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_3/transpose:Transpose"	Transpose"/*%EagerLocalExecute: FlushSummaryWriter"k	f	Vmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_2:Transpose"	Transpose"TO7Adam/Adam/update_78/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"~ngradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_3/transpose:Transpose"	Transpose"[VLmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/truediv:Mul"Mul"|hgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"EagerKernelExecute"qlbgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/truediv/RealDiv:Mul"Mul"mgradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_45/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"qmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"snamodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/Tensordot/MatMul:MatMul"MatMul"7>3>*gradient_tape/mean_squared_error/mul_1:Mul"Mul"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_1:Mul"Mul"D?3model/transformer/decoder/decoder_layer_3/add:AddV2"AddV2"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/Tensordot/MatMul/MatMul_1:MatMul"MatMul"z	u	`model/transformer/encoder/encoder_layer/sequential/dense_6/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_60:AddN"AddN"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/Tensordot/MatMul/MatMul_1:MatMul"MatMul"_ZEmodel/transformer/encoder/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"a\Rgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_15/dropout/Mul:Mul"Mul"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/add_1:AddV2"AddV2"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/Tensordot/MatMul/MatMul_1:MatMul"MatMul"~yigradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"`[Qgradient_tape/model/transformer/encoder/encoder_layer_3/dropout_6/dropout/Mul:Mul"Mul"TO7Adam/Adam/update_48/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"\WMmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul/Mul_1:Mul"Mul"a\Rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/sub:Sub"Sub"`	[	Qmodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_2:Mul"Mul"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"kfXmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/BiasAdd:BiasAdd"BiasAdd"wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/Tensordot/MatMul/MatMul:MatMul"MatMul"UP8Adam/Adam/update_113/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"e`Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/add:AddV2"AddV2"SOOO8Adam/Adam/update_127/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"^YOmodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul/Sum_1:Sum"Sum""EagerExecute: LogicalAnd"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/Tensordot/MatMul:MatMul"MatMul"TO7Adam/Adam/update_88/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam":	5	IteratorGetNext:IteratorGetNext"IteratorGetNext"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_2:Mul"Mul"idTmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose:Transpose"	Transpose"+&Adam/gradients/AddN_25:AddN"AddN")$EagerCopyToDeviceAndAddCacheKey"wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"idTmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose:Transpose"	Transpose"q
l
agradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/Tile_1:Tile"Tile"vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/Tensordot/MatMul/MatMul:MatMul"MatMul")i%iAdam/gradients/AddN_23:AddN"AddN"mgradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_46/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/sub/Sum:Sum"Sum"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul/Mul_1:Mul"Mul"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/BiasAdd:BiasAdd"BiasAdd"ni_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul/Mul:Mul"Mul"snamodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/Tensordot/MatMul:MatMul"MatMul"+&Adam/gradients/AddN_33:AddN"AddN"kfVmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_1:Transpose"	Transpose"pk`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/Tile:Tile"Tile"m
h
^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/Mul:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul/Mul_1:Mul"Mul"a\Rgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_12/dropout/Mul:Mul"Mul"+
&
Adam/gradients/AddN_54:AddN"AddN"vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/Tensordot/MatMul/MatMul:MatMul"MatMul"mmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"SOFmodel/transformer/decoder/decoder_layer/multi_head_attention_5/sub:Sub"Sub"je[gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/sub:Sub"Sub"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul/Mul:Mul"Mul"j	e	Wmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/BiasAdd:BiasAdd"BiasAdd"ni\model/transformer/encoder/encoder_layer/multi_head_attention/dense_2/Tensordot/MatMul:MatMul"MatMul"|lgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"idWmodel/transformer/encoder/encoder_layer_1/sequential_1/dense_12/Tensordot/MatMul:MatMul"MatMul"b]Qmodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/add:AddV2"AddV2"T
O
7Adam/Adam/update_61/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"+&LogicalAnd:LogicalAnd"
LogicalAnd"Q	L	Bmodel/transformer/decoder/decoder_layer/dropout_11/dropout/Mul:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul/Sum_1:Sum"Sum"|gmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"kfVmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_3:Transpose"	Transpose"_5[5Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/sub:Sub"Sub"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/sub:Sub"Sub"`[Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul:Mul"Mul"jeUmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose:Transpose"	Transpose"+&Adam/gradients/AddN_53:AddN"AddN"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/Tensordot/MatMul:MatMul"MatMul"	z	emodel/transformer/decoder/decoder_layer/sequential_4/dense_35/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"kXgX^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/sub:Sub"Sub"~ngradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_2/transpose:Transpose"	Transpose"}xcmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"c^Tgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_17/dropout/Mul_2:Mul"Mul"~jgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"b]Qmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/Rsqrt:Rsqrt"Rsqrt"T
O
7Adam/Adam/update_29/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Omodel/transformer/encoder/encoder_layer_1/sequential_1/dense_12/BiasAdd:BiasAdd"BiasAdd"}	x	cmodel/transformer/decoder/decoder_layer/sequential_4/dense_36/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"zjgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_1/transpose:Transpose"	Transpose"TO7Adam/Adam/update_63/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"zzwgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"Mul:Mul"Mul"

wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"ni_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/truediv:Mul"Mul"{ngradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_17/Tensordot/MatMul/MatMul_1:MatMul"MatMul"c^Tgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_19/dropout/Mul_2:Mul"Mul"faUmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/Rsqrt:Rsqrt"Rsqrt"l
g
Ymodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/BiasAdd:BiasAdd"BiasAdd"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul/Mul:Mul"Mul"pkagradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/truediv:Mul"Mul"b]Omodel/transformer/encoder/encoder_layer_1/sequential_1/dense_11/BiasAdd:BiasAdd"BiasAdd"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"mhUmodel/transformer/encoder/encoder_layer_3/dropout_6/dropout/GreaterEqual:GreaterEqual"GreaterEqual"UP8Adam/Adam/update_101/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"% EagerLocalExecute: Identity"odkdbgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/truediv/RealDiv:Mul"Mul"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/BiasAdd:BiasAdd"BiasAdd"d_Smodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/add:AddV2"AddV2"

mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/Rsqrt:Rsqrt"Rsqrt"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/Tensordot/MatMul/MatMul_1:MatMul"MatMul"Q	L	Bmodel/transformer/decoder/decoder_layer/dropout_10/dropout/Mul:Mul"Mul"oj_gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/Tile:Tile"Tile"TO7Adam/Adam/update_42/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"D?3model/transformer/encoder/encoder_layer_3/add:AddV2"AddV2"'"GatherV2_2:GatherV2"GatherV2"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul/Sum_1:Sum"Sum"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_2/Mul:Mul"Mul"qlagradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/Tile_1:Tile"Tile"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"|gmodel/transformer/encoder/encoder_layer_2/sequential_2/dense_18/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"ok_model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/Tensordot/MatMul:MatMul"MatMul"b]Omodel/transformer/decoder/decoder_layer_1/sequential_5/dense_46/BiasAdd:BiasAdd"BiasAdd"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_2:Mul"Mul"TO7Adam/Adam/update_60/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"`	[	Qmodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_1:Mul"Mul"mhUmodel/transformer/encoder/encoder_layer_1/dropout_3/dropout/GreaterEqual:GreaterEqual"GreaterEqual"lmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_3/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/sub/Neg:Neg"Neg"	Sum_2:Sum"Sum"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_1/Mul:Mul"Mul"`[Qgradient_tape/model/transformer/encoder/encoder_layer/dropout_1/dropout/Mul_2:Mul"Mul"TO7Adam/Adam/update_51/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_38/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"snamodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/Tensordot/MatMul:MatMul"MatMul"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/Tensordot/MatMul/MatMul:MatMul"MatMul"]XEmodel/transformer/encoder/dropout_8/dropout/GreaterEqual:GreaterEqual"GreaterEqual"T	O	Dmodel/transformer/decoder/decoder_layer/dropout_11/dropout/Cast:Cast"Cast"kmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"e a Umodel/transformer/decoder/decoder_layer/sequential_4/dense_36/Tensordot/MatMul:MatMul"MatMul"snamodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/Tensordot/MatMul:MatMul"MatMul"mh^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/sub:Sub"Sub"TO7Adam/Adam/update_71/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"kfVmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_1:Transpose"	Transpose"SWOW8Adam/Adam/update_118/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"
|
lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_2/transpose:Transpose"	Transpose"zemodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Pmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/Softmax:Softmax"Softmax"sn_gradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_23/ReluGrad:ReluGrad"ReluGrad"$EagerExecute: WriteSummary"pk`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/Tile:Tile"Tile"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/truediv_1:Mul"Mul"		Adam/Pow_1:Pow"Pow"WRHmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/sub:Sub"Sub"lgYmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/BiasAdd:BiasAdd"BiasAdd"gbXgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/mul_1:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_1/Mul:Mul"Mul"UP8Adam/Adam/update_107/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UPFmodel/transformer/decoder/decoder_layer_2/dropout_15/dropout/Mul_1:Mul"Mul"TO7Adam/Adam/update_72/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"g
b
Xgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/mul_1:Mul"Mul"TO7Adam/Adam/update_33/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam")q%qAdam/gradients/AddN_24:AddN"AddN"|hgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/sub:Sub"Sub"LG:model/transformer/decoder/dense_26/Tensordot/MatMul:MatMul"MatMul"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul:Mul"Mul"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"D?3model/transformer/encoder/encoder_layer_2/add:AddV2"AddV2"faUmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/add_1:AddV2"AddV2"`[Qgradient_tape/model/transformer/encoder/encoder_layer_3/dropout_7/dropout/Mul:Mul"Mul"c^Pmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/Softmax:Softmax"Softmax"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_1/Mul:Mul"Mul"s
n
dgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_2/Mul:Mul"Mul"TO7Adam/Adam/update_47/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qlbgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/truediv/RealDiv:Mul"Mul"T
O
7Adam/Adam/update_16/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"rmcgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_1/Mul_1:Mul"Mul"|gmodel/transformer/decoder/decoder_layer_1/sequential_5/dense_46/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"]YOmodel/transformer/decoder/decoder_layer/layer_normalization_9/moments/mean:Mean"Mean"`[Qmodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_1:Mul"Mul"+&Adam/gradients/AddN_47:AddN"AddN"V	Q	Fmodel/transformer/decoder/decoder_layer_1/dropout_13/dropout/Cast:Cast"Cast"vqggradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_2/Mul_1:Mul"Mul"UP8Adam/Adam/update_144/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"faUmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/Rsqrt:Rsqrt"Rsqrt"[VLmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/truediv:Mul"Mul"o
j
_gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/Tile:Tile"Tile"1,WriteSummary:WriteSummary"WriteSummary"N	I	?model/transformer/encoder/encoder_layer/dropout/dropout/Mul:Mul"Mul"lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"pmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"d_Smodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/add:AddV2"AddV2"5=1=(gradient_tape/mean_squared_error/sub:Sub"Sub"e`Vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/mul:Mul"Mul"b]Smodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_2:Mul"Mul"UPFmodel/transformer/decoder/decoder_layer_3/dropout_18/dropout/Mul_1:Mul"Mul"vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/Tensordot/MatMul:MatMul"MatMul"{ngradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_24/Tensordot/MatMul/MatMul_1:MatMul"MatMul"	|	gmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"lg]gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/truediv:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul/Sum_1:Sum"Sum"nmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/Tensordot/MatMul/MatMul:MatMul"MatMul",'mean_squared_error/Mean:Mean"Mean"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul/Sum_1:Sum"Sum"kfVmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_2:Transpose"	Transpose"lmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/SquaredDifference:SquaredDifference"SquaredDifference"`[Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul:Mul"Mul"	|	gmodel/transformer/encoder/encoder_layer_1/sequential_1/dense_11/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"oj`gradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/truediv/RealDiv:Mul"Mul"mh^gradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/truediv/Sum:Sum"Sum"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/sub/Sum:Sum"Sum"aB]BQgradient_tape/model/transformer/decoder/dense_26/Tensordot/MatMul/MatMul_1:MatMul"MatMul"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"HC)AssignAddVariableOp_3:AssignAddVariableOp"AssignAddVariableOp"e
`
Vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/Sum:Sum"Sum"d_Smodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/Rsqrt:Rsqrt"Rsqrt"TO7Adam/Adam/update_39/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"rmcgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/truediv/RealDiv:Mul"Mul"kfVmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_2:Transpose"	Transpose"t
o
egradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_2/Mul:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul/Mul_1:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_2/Mul:Mul"Mul"e`Umodel/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/variance:Mean"Mean"b]Hmodel/transformer/decoder/dense_26/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/BiasAdd:BiasAdd"BiasAdd"c^Tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/mul:Mul"Mul"slolfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_2/Mul:Mul"Mul"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/Tensordot/MatMul:MatMul"MatMul"lgYmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/BiasAdd:BiasAdd"BiasAdd"U
P
8Adam/Adam/update_130/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/Tensordot/MatMul:MatMul"MatMul"xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/Tensordot/MatMul/MatMul_1:MatMul"MatMul"C	>	4model/transformer/decoder/dropout_21/dropout/Mul:Mul"Mul"TO7Adam/Adam/update_50/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"xgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/Tensordot/MatMul/MatMul_1:MatMul"MatMul"e`Vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/Sum:Sum"Sum"wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/Tensordot/MatMul/MatMul:MatMul"MatMul"xgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/Tensordot/MatMul/MatMul_1:MatMul"MatMul"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul/Sum:Sum"Sum"|gmodel/transformer/decoder/decoder_layer_3/sequential_7/dense_66/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"zemodel/transformer/encoder/encoder_layer_2/sequential_2/dense_17/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"gcTmodel/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_3:Transpose"	Transpose"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul:Mul"Mul"XSImodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/sub:Sub"Sub"xgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/Tensordot/MatMul/MatMul_1:MatMul"MatMul"l	g	Tmodel/transformer/decoder/decoder_layer/dropout_11/dropout/GreaterEqual:GreaterEqual"GreaterEqual"NI6model/transformer/encoder/strided_slice_3:StridedSlice"StridedSlice"|wbmodel/transformer/encoder/encoder_layer/sequential/dense_6/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul/Sum:Sum"Sum"HC)AssignAddVariableOp_4:AssignAddVariableOp"AssignAddVariableOp"vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"niUmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul:BatchMatMulV2"BatchMatMulV2"TO7Adam/Adam/update_40/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"c^Tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/Sum:Sum"Sum"lgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"TO7Adam/Adam/update_57/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"Q	L	Amodel/transformer/encoder/encoder_layer/dropout/dropout/Cast:Cast"Cast"zemodel/transformer/decoder/decoder_layer_1/sequential_5/dense_45/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"c(_(Tmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/Rsqrt:Rsqrt"Rsqrt"faUmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/Rsqrt:Rsqrt"Rsqrt"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"kfVmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_3:Transpose"	Transpose"__lgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"
{
kgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"zemodel/transformer/encoder/encoder_layer_3/sequential_3/dense_23/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"kmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/SquaredDifference:SquaredDifference"SquaredDifference"mgradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_56/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"WRHmodel/transformer/encoder/encoder_layer/multi_head_attention/truediv:Mul"Mul"TO7Adam/Adam/update_21/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"		kmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"upfgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_2/Mul_1:Mul"Mul"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"*%Adam/gradients/AddN_4:AddN"AddN"c^Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_1:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/sub/Sum:Sum"Sum"t
o
egradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_2/Sum:Sum"Sum"y{ylgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose/transpose:Transpose"	Transpose"zemodel/transformer/decoder/decoder_layer_3/sequential_7/dense_66/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_20:AddN"AddN"C>/mean_squared_error/weighted_loss/value:DivNoNan"DivNoNan"ojVmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul:BatchMatMulV2"BatchMatMulV2"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/Tensordot/MatMul/MatMul_1:MatMul"MatMul"b]Smodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_2:Mul"Mul"a\Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/mean:Mean"Mean"UP8Adam/Adam/update_157/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/SquaredDifference:SquaredDifference"SquaredDifference"+&Adam/gradients/AddN_11:AddN"AddN"

lgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"~jgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"+&Adam/gradients/AddN_27:AddN"AddN"m
h
Umodel/transformer/encoder/encoder_layer_2/dropout_5/dropout/GreaterEqual:GreaterEqual"GreaterEqual"wrhgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_2/Mul_1:Mul"Mul"vqggradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_1/Mul_1:Mul"Mul"LG:model/transformer/decoder/dense_25/Tensordot/MatMul:MatMul"MatMul"\XOmodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/sub:Sub"Sub"pkWmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"wgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"l	g	Ymodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/BiasAdd:BiasAdd"BiasAdd"xgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/Tensordot/MatMul/MatMul_1:MatMul"MatMul"mh]gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/Tile:Tile"Tile"e`Vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/mul:Mul"Mul"kfVmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_1:Transpose"	Transpose"D?3model/transformer/encoder/encoder_layer_1/add:AddV2"AddV2"f
a
Wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/sub:Sub"Sub"kfVmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_3:Transpose"	Transpose"S	N	Dmodel/transformer/decoder/decoder_layer_2/dropout_16/dropout/Mul:Mul"Mul"lg]gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/sub:Sub"Sub"qmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"ExecutorState::Process"TO7Adam/Adam/update_98/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UPEmodel/transformer/encoder/encoder_layer_3/dropout_7/dropout/Cast:Cast"Cast"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_1:Mul"Mul"B=3gradient_tape/model/transformer/decoder/mul/Mul:Mul"Mul"gbVmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/Rsqrt:Rsqrt"Rsqrt"vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/Tensordot/MatMul/MatMul:MatMul"MatMul"^	Y	Omodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul:Mul"Mul"SN6Adam/Adam/update_8/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"xgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/Tensordot/MatMul/MatMul_1:MatMul"MatMul"pmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"sn_gradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_45/ReluGrad:ReluGrad"ReluGrad"'"div_no_nan:DivNoNan"DivNoNan"xgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/Tensordot/MatMul/MatMul_1:MatMul"MatMul"pkWmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul_1:BatchMatMulV2"BatchMatMulV2"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/add_1:AddV2"AddV2"b]Smodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_2:Mul"Mul"c	^	Smodel/transformer/decoder/decoder_layer/layer_normalization_8/moments/variance:Mean"Mean"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_2:Mul"Mul"a']'Rmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/add:AddV2"AddV2"~ylgradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_12/Tensordot/MatMul/MatMul:MatMul"MatMul"TO7Adam/Adam/update_43/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"JJwgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"mgradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_65/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"p
k
agradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/sub/Neg:Neg"Neg"WRHmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/sub:Sub"Sub"~jgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_2/Mul:Mul"Mul"|lgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"e
`
Vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/Sum:Sum"Sum"s
n
dgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_2/Sum:Sum"Sum"~ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_3/transpose:Transpose"	Transpose"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/Tensordot/MatMul/MatMul_1:MatMul"MatMul"snamodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/Tensordot/MatMul:MatMul"MatMul"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/BiasAdd:BiasAdd"BiasAdd"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/Tensordot/MatMul:MatMul"MatMul"c^Pmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/Softmax:Softmax"Softmax"t{tlgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"UP8Adam/Adam/update_152/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"zfmodel/transformer/encoder/encoder_layer_3/dropout_7/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"p
k
`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/Tile:Tile"Tile"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/Tensordot/MatMul:MatMul"MatMul"upfgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_1/Mul_1:Mul"Mul"q	l	_model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/Tensordot/MatMul:MatMul"MatMul"+&Adam/gradients/AddN_58:AddN"AddN"|lgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose/transpose:Transpose"	Transpose"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/sub/Neg:Neg"Neg"~jgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"TO7Adam/Adam/update_49/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"+&Adam/gradients/AddN_17:AddN"AddN"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"{fmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"`\Qmodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/add:AddV2"AddV2"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/BiasAdd:BiasAdd"BiasAdd"}mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose/transpose:Transpose"	Transpose"TO7Adam/Adam/update_45/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"i	d	Qmodel/transformer/encoder/encoder_layer/dropout/dropout/GreaterEqual:GreaterEqual"GreaterEqual"TO7Adam/Adam/update_81/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"omodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul/Sum_1:Sum"Sum"mgradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_66/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"TO7Adam/Adam/update_13/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TOEmodel/transformer/encoder/encoder_layer_1/dropout_2/dropout/Mul_1:Mul"Mul"wgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/Tensordot/MatMul/MatMul_1:MatMul"MatMul"+&Adam/gradients/AddN_32:AddN"AddN"sndgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul/Sum_1:Sum"Sum"~ngradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/transpose_1/transpose:Transpose"	Transpose"		mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"omodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"i0e0Vmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_2:Transpose"	Transpose"kfVmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_2:Transpose"	Transpose"|gmodel/transformer/decoder/decoder_layer_1/sequential_5/dense_45/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"e`Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/add:AddV2"AddV2"sgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_4/Tensordot/MatMul/MatMul_1:MatMul"MatMul"v
q
ggradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_2/Mul_1:Mul"Mul"zemodel/transformer/encoder/encoder_layer_2/sequential_2/dense_18/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"faUmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/add_1:AddV2"AddV2"xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/Tensordot/MatMul/MatMul_1:MatMul"MatMul"B=1model/transformer/encoder/encoder_layer/add:AddV2"AddV2"TO7Adam/Adam/update_14/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"		kmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_148/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"_ZPgradient_tape/model/transformer/decoder/decoder_layer/dropout_11/dropout/Mul:Mul"Mul"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"faWgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/sub:Sub"Sub"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/Tensordot/MatMul:MatMul"MatMul"TO7Adam/Adam/update_52/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/BiasAdd:BiasAdd"BiasAdd"sAoAYgradient_tape/model/transformer/decoder/strided_slice_8/StridedSliceGrad:StridedSliceGrad"StridedSliceGrad"}hmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"HC)AssignAddVariableOp_2:AssignAddVariableOp"AssignAddVariableOp"mh^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/Mul:Mul"Mul"lg]gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/sub:Sub"Sub"kfVmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_1:Transpose"	Transpose"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_1/Mul:Mul"Mul"UP8Adam/Adam/update_138/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/add_1:AddV2"AddV2"+&Adam/gradients/AddN_12:AddN"AddN"p
k
agradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/truediv_1:Mul"Mul"zjgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/transpose/transpose:Transpose"	Transpose"a\Rgradient_tape/model/transformer/decoder/decoder_layer/dropout_11/dropout/Mul_2:Mul"Mul"s
n
_gradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_17/ReluGrad:ReluGrad"ReluGrad"wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"lg]gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/Mul:Mul"Mul"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"ecacXgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/mul_1:Mul"Mul"e`Umodel/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/variance:Mean"Mean"T	O	Dmodel/transformer/decoder/decoder_layer/dropout_10/dropout/Cast:Cast"Cast"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_1/Mul:Mul"Mul"|lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_2/transpose:Transpose"	Transpose"b]Omodel/transformer/encoder/encoder_layer_3/sequential_3/dense_24/BiasAdd:BiasAdd"BiasAdd"b]Smodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_2:Mul"Mul"U
P
8Adam/Adam/update_150/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"e`Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/add:AddV2"AddV2"S	N	Dmodel/transformer/decoder/decoder_layer_1/dropout_12/dropout/Mul:Mul"Mul"+&Adam/gradients/AddN_51:AddN"AddN"nmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"lhUmodel/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul_1:BatchMatMulV2"BatchMatMulV2"mh^gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/mul_1:Mul"Mul"4/#model/transformer/encoder/add:AddV2"AddV2"\WMmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/truediv:Mul"Mul"{kgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"qlXmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul_1:BatchMatMulV2"BatchMatMulV2"mgradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_18/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"~	y	emodel/transformer/decoder/decoder_layer/dropout_11/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"^YLgradient_tape/model/transformer/encoder/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"|gmodel/transformer/encoder/encoder_layer_3/sequential_3/dense_24/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_69/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"c^Tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/mul:Mul"Mul"b]Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/mean:Mean"Mean"TOEmodel/transformer/encoder/encoder_layer_3/dropout_7/dropout/Mul_1:Mul"Mul"q	l	_model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/Tensordot/MatMul:MatMul"MatMul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/sub/Neg:Neg"Neg"j/f/Ymodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/BiasAdd:BiasAdd"BiasAdd"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/truediv_1:Mul"Mul"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/Tensordot/MatMul/MatMul:MatMul"MatMul"rmbgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/Tile_1:Tile"Tile"qRmRdgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/sub/Sum:Sum"Sum"omodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"qlbgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/truediv/RealDiv:Mul"Mul"{
v
igradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_6/Tensordot/MatMul/MatMul_1:MatMul"MatMul"a\Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/mean:Mean"Mean"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"jeQmodel/transformer/encoder/encoder_layer/multi_head_attention/MatMul:BatchMatMulV2"BatchMatMulV2"r
m
cgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/sub/Neg:Neg"Neg"v
q
ggradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_2/Mul_1:Mul"Mul"oj`gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/truediv:Mul"Mul"YTImodel/transformer/encoder/encoder_layer_3/sequential_3/dense_23/Relu:Relu"Relu"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/sub/Sum:Sum"Sum"a\Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul:Mul"Mul"kfVmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_2:Transpose"	Transpose"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/SquaredDifference:SquaredDifference"SquaredDifference"||xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/Tensordot/MatMul/MatMul_1:MatMul"MatMul"UP8Adam/Adam/update_137/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"NI6model/transformer/encoder/strided_slice_4:StridedSlice"StridedSlice"

vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/Tensordot/MatMul/MatMul:MatMul"MatMul"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/Rsqrt:Rsqrt"Rsqrt"{ngradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_66/Tensordot/MatMul/MatMul_1:MatMul"MatMul"q	l	_model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/Tensordot/MatMul:MatMul"MatMul"TOEmodel/transformer/encoder/encoder_layer_2/dropout_4/dropout/Mul_1:Mul"Mul"UP8Adam/Adam/update_123/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"vqggradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_2/Mul_1:Mul"Mul"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Tgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_14/dropout/Mul_2:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/sub/Sum:Sum"Sum"UP8Adam/Adam/update_105/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"^ZMmodel/transformer/decoder/decoder_layer/sequential_4/dense_35/BiasAdd:BiasAdd"BiasAdd"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/BiasAdd:BiasAdd"BiasAdd"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/truediv_1:Mul"Mul"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"U	P	8Adam/Adam/update_169/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lg]gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/Mul:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_2/Mul:Mul"Mul"omodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"e`Vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/sub:Sub"Sub"|hgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"b]Smodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_1:Mul"Mul"xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/Tensordot/MatMul/MatMul_1:MatMul"MatMul"TO7Adam/Adam/update_90/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"faUmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/Rsqrt:Rsqrt"Rsqrt"pkWmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul_1:BatchMatMulV2"BatchMatMulV2"{ngradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_18/Tensordot/MatMul/MatMul_1:MatMul"MatMul"V	Q	Fmodel/transformer/decoder/decoder_layer_1/dropout_12/dropout/Cast:Cast"Cast"zemodel/transformer/encoder/encoder_layer_1/sequential_1/dense_12/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"k8g8Zmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/BiasAdd:BiasAdd"BiasAdd"mhUmodel/transformer/encoder/encoder_layer_3/dropout_7/dropout/GreaterEqual:GreaterEqual"GreaterEqual"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/BiasAdd:BiasAdd"BiasAdd"B=3gradient_tape/model/transformer/encoder/mul/Mul:Mul"Mul"l
g
]gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/sub:Sub"Sub"omodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"UPEmodel/transformer/encoder/encoder_layer_1/dropout_2/dropout/Cast:Cast"Cast"}kgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_36/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"`[Qmodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_2:Mul"Mul"mh^gradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/truediv/RealDiv:Mul"Mul"		imodel/transformer/decoder/decoder_layer/layer_normalization_8/moments/SquaredDifference:SquaredDifference"SquaredDifference"UP8Adam/Adam/update_134/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lgWmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_2:Transpose"	Transpose"+&Adam/gradients/AddN_19:AddN"AddN"wrhgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_1/Mul_1:Mul"Mul"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/Rsqrt:Rsqrt"Rsqrt"mgradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_17/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul:Mul"Mul"SIOI8Adam/Adam/update_160/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_167/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_2/Sum:Sum"Sum"+&Adam/gradients/AddN_38:AddN"AddN"mh^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/Mul:Mul"Mul"kfSmodel/transformer/encoder/encoder_layer/dropout_1/dropout/GreaterEqual:GreaterEqual"GreaterEqual"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/Tensordot/MatMul/MatMul:MatMul"MatMul"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul/Mul:Mul"Mul"pkWmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul_1:BatchMatMulV2"BatchMatMulV2"oj`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/mul_1:Mul"Mul"n
i
_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/sub/Sum:Sum"Sum"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul/Mul_1:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/sub/Sum:Sum"Sum"

wgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"gbPgradient_tape/model/transformer/decoder/dense_25/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"ngradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"S	N	Dmodel/transformer/decoder/decoder_layer_3/dropout_20/dropout/Mul:Mul"Mul"qkmkdgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/sub/Neg:Neg"Neg"snamodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/Tensordot/MatMul:MatMul"MatMul"F	A	6model/transformer/decoder/dropout_21/dropout/Cast:Cast"Cast"|wggradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul/Mul_1:Mul"Mul"TO7Adam/Adam/update_20/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"zfmodel/transformer/encoder/encoder_layer_1/dropout_2/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"+
&
Adam/gradients/AddN_18:AddN"AddN"b]Omodel/transformer/decoder/decoder_layer_2/sequential_6/dense_55/BiasAdd:BiasAdd"BiasAdd"i	d	Tmodel/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_2:Transpose"	Transpose"TO7Adam/Adam/update_30/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"omodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"a]Smodel/transformer/decoder/decoder_layer/layer_normalization_9/moments/variance:Mean"Mean"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/Tensordot/MatMul:MatMul"MatMul"d_Rmodel/transformer/encoder/encoder_layer/sequential/dense_5/Tensordot/MatMul:MatMul"MatMul"kgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"b]Sgradient_tape/model/transformer/encoder/encoder_layer_2/dropout_4/dropout/Mul_2:Mul"Mul"faVmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/variance:Mean"Mean"~jgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"{	v	bmodel/transformer/encoder/encoder_layer/dropout/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"ID7model/transformer/encoder/dense/Tensordot/MatMul:MatMul"MatMul"UP8Adam/Adam/update_121/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"jmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul/Mul:Mul"Mul"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/Tensordot/MatMul/MatMul:MatMul"MatMul"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/BiasAdd:BiasAdd"BiasAdd"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/sub/Sum:Sum"Sum"n	i	Vmodel/transformer/decoder/decoder_layer_1/dropout_13/dropout/GreaterEqual:GreaterEqual"GreaterEqual"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"r7n7bmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/Tensordot/MatMul:MatMul"MatMul"b]Sgradient_tape/model/transformer/encoder/encoder_layer_1/dropout_2/dropout/Mul_2:Mul"Mul"kf\gradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/truediv/Sum:Sum"Sum"qlbgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/truediv:Mul"Mul")Z%ZAdam/gradients/AddN_22:AddN"AddN"qmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_2/Mul:Mul"Mul"U
P
Emodel/transformer/encoder/encoder_layer_2/dropout_5/dropout/Cast:Cast"Cast"`[Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/sub:Sub"Sub"UP8Adam/Adam/update_133/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"PKAmodel/transformer/encoder/encoder_layer/dropout/dropout/Mul_1:Mul"Mul"T
O
7Adam/Adam/update_26/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"

mgradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_24/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"~jgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"ugradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/Tensordot/MatMul/MatMul:MatMul"MatMul"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul/Mul:Mul"Mul"lgWmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_3:Transpose"	Transpose"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul/Mul_1:Mul"Mul"gbVmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/add_1:AddV2"AddV2"~DzDngradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_65/Tensordot/MatMul/MatMul_1:MatMul"MatMul"UP8Adam/Adam/update_103/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"\WMmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/sub:Sub"Sub"g
b
Xgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/mul_1:Mul"Mul"jeUmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose:Transpose"	Transpose"ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_3/transpose:Transpose"	Transpose"b]Smodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_1:Mul"Mul"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/Tensordot/MatMul/MatMul_1:MatMul"MatMul"xgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/Tensordot/MatMul/MatMul_1:MatMul"MatMul"b]Hmodel/transformer/decoder/dense_25/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"|lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_3/transpose:Transpose"	Transpose"qlbgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul/Sum:Sum"Sum"|wjgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_35/Tensordot/MatMul/MatMul:MatMul"MatMul"d_Jmodel/transformer/decoder/dense_25/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"f}fjgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul:Mul"Mul"mh^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/Mul:Mul"Mul"e`Vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/mul_1:Mul"Mul"n	i	Vmodel/transformer/decoder/decoder_layer_1/dropout_12/dropout/GreaterEqual:GreaterEqual"GreaterEqual"TO7Adam/Adam/update_53/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"|lgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"qmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"wrhgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_1/Mul_1:Mul"Mul"rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_2/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"`[Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/sub:Sub"Sub"UP8Adam/Adam/update_120/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/Tensordot/MatMul/MatMul:MatMul"MatMul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/sub/Sum:Sum"Sum"faVmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/variance:Mean"Mean"oj_gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/Tile:Tile"Tile"j	e	Wmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/BiasAdd:BiasAdd"BiasAdd"|gmodel/transformer/encoder/encoder_layer_1/sequential_1/dense_12/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"=8)model/transformer/encoder/concat:ConcatV2"ConcatV2"+&Adam/gradients/AddN_29:AddN"AddN"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/SquaredDifference:SquaredDifference"SquaredDifference"RMCmodel/transformer/encoder/encoder_layer_1/dropout_3/dropout/Mul:Mul"Mul"n
i
_gradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/truediv/Sum:Sum"Sum"qmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"NI6model/transformer/encoder/strided_slice_2:StridedSlice"StridedSlice"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_2/Mul:Mul"Mul"idTmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose:Transpose"	Transpose"B=3model/transformer/encoder/dropout_8/dropout/Mul:Mul"Mul"d	_	Smodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/add_1:AddV2"AddV2"qlbgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/sub/Sum:Sum"Sum"UP8Adam/Adam/update_154/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"Q"M"Dmodel/transformer/decoder/decoder_layer/dropout_11/dropout/Mul_1:Mul"Mul"*%Adam/gradients/AddN_7:AddN"AddN"YTImodel/transformer/decoder/decoder_layer_3/sequential_7/dense_65/Relu:Relu"Relu"TO7Adam/Adam/update_85/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"idWmodel/transformer/decoder/decoder_layer_1/sequential_5/dense_46/Tensordot/MatMul:MatMul"MatMul"SQOQ8Adam/Adam/update_122/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"|wjgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_36/Tensordot/MatMul/MatMul:MatMul"MatMul"T
O
7Adam/Adam/update_82/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"gbXgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/mul_1:Mul"Mul"pk`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/Tile:Tile"Tile"mgradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_55/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"_ZLmodel/transformer/encoder/encoder_layer/multi_head_attention/Softmax:Softmax"Softmax"d_Pmodel/transformer/decoder/decoder_layer/multi_head_attention_5/SelectV2:SelectV2"SelectV2"TO7Adam/Adam/update_79/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/Tensordot/MatMul/MatMul:MatMul"MatMul"vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/Tensordot/MatMul/MatMul:MatMul"MatMul"k
f
Vmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_2:Transpose"	Transpose"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/Tensordot/MatMul/MatMul_1:MatMul"MatMul"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"WRHmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/sub:Sub"Sub"

lgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2""TFE_Py_ExecuteCancelable"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul/Sum_1:Sum"Sum"S	N	Dmodel/transformer/decoder/decoder_layer_3/dropout_18/dropout/Mul:Mul"Mul"qsmsdgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul/Sum:Sum"Sum"RMCmodel/transformer/encoder/encoder_layer_1/dropout_2/dropout/Mul:Mul"Mul"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/Tensordot/MatMul/MatMul:MatMul"MatMul"i	d	Tmodel/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_1:Transpose"	Transpose"kmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/SquaredDifference:SquaredDifference"SquaredDifference"~ylgradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_24/Tensordot/MatMul/MatMul:MatMul"MatMul"rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_1/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"94'model/transformer/encoder/Cumsum:Cumsum"Cumsum"

wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"faVmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/variance:Mean"Mean"Y	T	Jmodel/transformer/decoder/decoder_layer/multi_head_attention_4/truediv:Mul"Mul"ngradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"|wbmodel/transformer/encoder/encoder_layer/sequential/dense_5/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"eaUmodel/transformer/decoder/decoder_layer/sequential_4/dense_35/Tensordot/MatMul:MatMul"MatMul"UP8Adam/Adam/update_156/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"imodel/transformer/encoder/encoder_layer/layer_normalization_1/moments/SquaredDifference:SquaredDifference"SquaredDifference"rmbgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/Tile_1:Tile"Tile"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/sub/Sum:Sum"Sum"idWmodel/transformer/decoder/decoder_layer_3/sequential_7/dense_65/Tensordot/MatMul:MatMul"MatMul"c^Tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/sub:Sub"Sub"s	n	dgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/sub/Sum:Sum"Sum"~ylgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_35/Tensordot/MatMul/MatMul_1:MatMul"MatMul"lgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"je[gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/Mul:Mul"Mul"4/#model/transformer/decoder/add:AddV2"AddV2"+&Adam/gradients/AddN_14:AddN"AddN"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul/Sum_1:Sum"Sum"[VLmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/truediv:Mul"Mul"SN6Adam/Adam/update_3/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"s	n	amodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/Tensordot/MatMul:MatMul"MatMul"e`Vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/sub:Sub"Sub"s?o?Ygradient_tape/model/transformer/decoder/strided_slice_9/StridedSliceGrad:StridedSliceGrad"StridedSliceGrad"toegradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_1/Mul_1:Mul"Mul"toegradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_2/Mul_1:Mul"Mul"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/Tensordot/MatMul/MatMul:MatMul"MatMul"hcYgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/sub:Sub"Sub"|gmodel/transformer/encoder/encoder_layer_3/sequential_3/dense_23/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"|lgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"~
y
lgradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_17/Tensordot/MatMul/MatMul:MatMul"MatMul"mhUmodel/transformer/encoder/encoder_layer_1/dropout_2/dropout/GreaterEqual:GreaterEqual"GreaterEqual"|lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_1/transpose:Transpose"	Transpose"^YOmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_1:Mul"Mul"e`Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/add:AddV2"AddV2"
{
kgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/add_1:AddV2"AddV2"zfgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_2/Mul:Mul"Mul"e`Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/add:AddV2"AddV2"UP8Adam/Adam/update_158/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/mean:Mean"Mean"LLxgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/Tensordot/MatMul/MatMul_1:MatMul"MatMul"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_1/Mul:Mul"Mul"D?3model/transformer/encoder/encoder_layer/add_1:AddV2"AddV2"r
m
cgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_2/Sum:Sum"Sum"qlbgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/truediv:Mul"Mul"kgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"lgYmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/BiasAdd:BiasAdd"BiasAdd"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/Tensordot/MatMul/MatMul_1:MatMul"MatMul"rmbgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/Tile_1:Tile"Tile"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"|hgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"e`Vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/mul_1:Mul"Mul"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul/Mul_1:Mul"Mul"qmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"pnlnbgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/Tile_1:Tile"Tile"niUmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/MatMul:BatchMatMulV2"BatchMatMulV2"a\Rgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_17/dropout/Mul:Mul"Mul"TO7Adam/Adam/update_91/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"q	l	_model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/Tensordot/MatMul:MatMul"MatMul"ni_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul/Sum:Sum"Sum"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/Tensordot/MatMul/MatMul_1:MatMul"MatMul"		jmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_1/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul/Mul:Mul"Mul"qlagradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/Tile_1:Tile"Tile"RMCmodel/transformer/encoder/encoder_layer_3/dropout_7/dropout/Mul:Mul"Mul"UP8Adam/Adam/update_106/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_2/Sum:Sum"Sum"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/sub/Sum:Sum"Sum"idWmodel/transformer/decoder/decoder_layer_2/sequential_6/dense_55/Tensordot/MatMul:MatMul"MatMul"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/sub/Neg:Neg"Neg"l	g	Smodel/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul:BatchMatMulV2"BatchMatMulV2"omodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"gcTmodel/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_1:Transpose"	Transpose"b]Qmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/add_1:AddV2"AddV2"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul/Sum_1:Sum"Sum"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/add_1:AddV2"AddV2"gbTmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_2/BiasAdd:BiasAdd"BiasAdd"

xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/Tensordot/MatMul/MatMul_1:MatMul"MatMul"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"gbRmodel/transformer/encoder/encoder_layer/multi_head_attention/transpose_2:Transpose"	Transpose"wgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_7/Tensordot/MatMul/MatMul_1:MatMul"MatMul"e`Vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/mul:Mul"Mul"	{	gmodel/transformer/decoder/decoder_layer_1/dropout_13/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"UP8Adam/Adam/update_166/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/Tensordot/MatMul/MatMul_1:MatMul"MatMul"_*[*Rmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_1:Mul"Mul"e`Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/add:AddV2"AddV2"oj`gradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/truediv/RealDiv:Mul"Mul"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/Rsqrt:Rsqrt"Rsqrt"mYiY`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/mul_1:Mul"Mul"toegradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_2/Mul_1:Mul"Mul"p
k
agradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/truediv:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/sub/Neg:Neg"Neg"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_1/Mul:Mul"Mul"vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/Tensordot/MatMul/MatMul:MatMul"MatMul"gmodel/transformer/encoder/encoder_layer/layer_normalization/moments/SquaredDifference:SquaredDifference"SquaredDifference"`[Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/sub:Sub"Sub"TO7Adam/Adam/update_24/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"72-TensorHandle::GetResourceHandleInfo WaitReady"UP8Adam/Adam/update_145/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"t
o
egradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_2/Sum:Sum"Sum"ni_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/sub/Neg:Neg"Neg"UP8Adam/Adam/update_124/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/mean:Mean"Mean"r
m
cgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/truediv_1:Mul"Mul"UP8Adam/Adam/update_155/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"S	N	Dmodel/transformer/decoder/decoder_layer_1/dropout_14/dropout/Mul:Mul"Mul"R{N{7Adam/Adam/update_97/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"0+!model/transformer/encoder/Cos:Cos"Cos"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/Tensordot/MatMul/MatMul:MatMul"MatMul"i	d	Tmodel/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_3:Transpose"	Transpose"faUmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/add_1:AddV2"AddV2"UP8Adam/Adam/update_161/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"0+!model/transformer/decoder/Min:Min"Min"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"ni\model/transformer/encoder/encoder_layer/multi_head_attention/dense_3/Tensordot/MatMul:MatMul"MatMul"

lgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/BiasAdd:BiasAdd"BiasAdd"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/Tensordot/MatMul/MatMul:MatMul"MatMul"0+!model/transformer/decoder/mul:Mul"Mul"kege^gradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/truediv/Sum:Sum"Sum"UP8Adam/Adam/update_140/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"ql_model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/Tensordot/MatMul:MatMul"MatMul"qlbgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/truediv:Mul"Mul"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/SquaredDifference:SquaredDifference"SquaredDifference"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/sub/Sum:Sum"Sum"	{	gmodel/transformer/decoder/decoder_layer_1/dropout_12/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul/Mul:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/sub/Sum:Sum"Sum"TO7Adam/Adam/update_75/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_1/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_15:AddN"AddN"TO7Adam/Adam/update_76/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/mean:Mean"Mean"LG4model/transformer/decoder/strided_slice:StridedSlice"StridedSlice"l	g	Tmodel/transformer/decoder/decoder_layer/dropout_10/dropout/GreaterEqual:GreaterEqual"GreaterEqual"+&Adam/gradients/AddN_50:AddN"AddN"hdWmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/BiasAdd:BiasAdd"BiasAdd"TO7Adam/Adam/update_66/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"^YOgradient_tape/model/transformer/decoder/decoder_layer/dropout_9/dropout/Mul:Mul"Mul"=83EagerLocalExecute: __inference_train_function_14421"sgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_1/Tensordot/MatMul/MatMul_1:MatMul"MatMul"a\Gmodel/transformer/encoder/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_142/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"T
O
7Adam/Adam/update_41/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"2-#model/transformer/encoder/mul_2:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul/Mul_1:Mul"Mul"lgYmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/BiasAdd:BiasAdd"BiasAdd"b]Omodel/transformer/decoder/decoder_layer_1/sequential_5/dense_45/BiasAdd:BiasAdd"BiasAdd"f
a
Wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/mul:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_2/Sum:Sum"Sum"^!Z!Mmodel/transformer/decoder/decoder_layer/sequential_4/dense_36/BiasAdd:BiasAdd"BiasAdd"61%model/transformer/decoder/Equal:Equal"Equal"TO7Adam/Adam/update_84/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Omodel/transformer/decoder/decoder_layer_3/sequential_7/dense_65/BiasAdd:BiasAdd"BiasAdd"TO7Adam/Adam/update_32/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"% GatherV2:GatherV2"GatherV2"sToTfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_1/Mul:Mul"Mul"b]Sgradient_tape/model/transformer/encoder/encoder_layer_3/dropout_6/dropout/Mul_2:Mul"Mul"a\Rgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_19/dropout/Mul:Mul"Mul"`[Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/sub:Sub"Sub"
z
hgradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_5/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_2/Mul:Mul"Mul"rmbgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/Tile_1:Tile"Tile"qlbgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/truediv:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul/Sum_1:Sum"Sum"q
l
bgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/truediv_1:Mul"Mul"wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"omodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_34:AddN"AddN"lgWmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose_1:Transpose"	Transpose"je[gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/Mul:Mul"Mul"V	Q	Fmodel/transformer/decoder/decoder_layer_3/dropout_20/dropout/Cast:Cast"Cast"ovkvbgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/truediv:Mul"Mul"wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/Tensordot/MatMul/MatMul:MatMul"MatMul"SN6mean_squared_error/SquaredDifference:SquaredDifference"SquaredDifference"lg]gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/mul_1:Mul"Mul"g	b	Rmodel/transformer/decoder/decoder_layer/multi_head_attention_4/transpose:Transpose"	Transpose"a\Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/mean:Mean"Mean"'"ValidateInputTypeAndPlacement"S	N	Dmodel/transformer/decoder/decoder_layer_2/dropout_17/dropout/Mul:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul/Mul_1:Mul"Mul"gbXgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/mul_1:Mul"Mul"D?5model/transformer/encoder/dropout_8/dropout/Mul_1:Mul"Mul"TO7Adam/Adam/update_59/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"SN6Adam/Adam/update_7/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_115/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/moments/SquaredDifference:SquaredDifference"SquaredDifference"UP8Adam/Adam/update_104/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"B	=	1model/transformer/decoder/decoder_layer/add:AddV2"AddV2"zu`model/transformer/encoder/encoder_layer/sequential/dense_5/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"hdWmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/BiasAdd:BiasAdd"BiasAdd"lmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"_ZOmodel/transformer/encoder/encoder_layer/layer_normalization_1/moments/mean:Mean"Mean"je[gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/sub:Sub"Sub"b]Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/mean:Mean"Mean"+&Adam/gradients/AddN_39:AddN"AddN"
|
lgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"]XJmodel/transformer/encoder/encoder_layer/sequential/dense_6/BiasAdd:BiasAdd"BiasAdd"TO7Adam/Adam/update_10/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"+&Adam/gradients/AddN_42:AddN"AddN"'	"	GatherV2_1:GatherV2"GatherV2"mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/sub/Sum:Sum"Sum"j2f2Ymodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/BiasAdd:BiasAdd"BiasAdd"c^Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_1:Mul"Mul"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/sub/Neg:Neg"Neg"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/Tensordot/MatMul:MatMul"MatMul"hcYgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/Mul:Mul"Mul"mh]gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/Tile:Tile"Tile"r
m
cgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul/Mul:Mul"Mul"% Identity:Identity"Identity"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul/Sum:Sum"Sum"?:+model/transformer/decoder/concat_1:ConcatV2"ConcatV2"~ylgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_36/Tensordot/MatMul/MatMul_1:MatMul"MatMul"d_Smodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/add_1:AddV2"AddV2"oj`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/mul_1:Mul"Mul"zhgradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_6/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad" TFE_DeleteTensorHandle"UP8Adam/Adam/update_114/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"e
`
Vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/sub:Sub"Sub"zjgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/transpose_2/transpose:Transpose"	Transpose"UP8Adam/Adam/update_117/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a\Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/sub:Sub"Sub"FA5model/transformer/decoder/decoder_layer_1/add_1:AddV2"AddV2"UP8Adam/Adam/update_131/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"P	K	Amodel/transformer/decoder/decoder_layer/dropout_9/dropout/Mul:Mul"Mul"RCNC7Adam/Adam/update_68/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"^YOmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_2:Mul"Mul"+&Adam/gradients/AddN_37:AddN"AddN"*%Adam/gradients/AddN_3:AddN"AddN"~ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_1/transpose:Transpose"	Transpose"kfXmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/BiasAdd:BiasAdd"BiasAdd"mmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"TODmodel/transformer/encoder/encoder_layer/sequential/dense_5/Relu:Relu"Relu"

ugradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/Tensordot/MatMul/MatMul:MatMul"MatMul"pkWmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul_1:BatchMatMulV2"BatchMatMulV2"+&Adam/gradients/AddN_46:AddN"AddN"lmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_4/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"smomfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_2/Sum:Sum"Sum"{ngradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_45/Tensordot/MatMul/MatMul_1:MatMul"MatMul"|gmodel/transformer/decoder/decoder_layer_2/sequential_6/dense_55/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"pk`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/Tile:Tile"Tile"+&Adam/gradients/AddN_10:AddN"AddN"gbVmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/Rsqrt:Rsqrt"Rsqrt"je[gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/sub:Sub"Sub"E	@	6model/transformer/decoder/dropout_21/dropout/Mul_1:Mul"Mul"wgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"YTImodel/transformer/encoder/encoder_layer_1/sequential_1/dense_11/Relu:Relu"Relu"TO7Adam/Adam/update_64/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"V	Q	Fmodel/transformer/decoder/decoder_layer_2/dropout_17/dropout/Cast:Cast"Cast""TFE_Py_FastPathExecute_C"oj`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/mul_1:Mul"Mul"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_2/Mul:Mul"Mul"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/sub:Sub"Sub"kfVmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_1:Transpose"	Transpose"^	Y	Fmodel/transformer/decoder/dropout_21/dropout/GreaterEqual:GreaterEqual"GreaterEqual"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_2/Mul:Mul"Mul"ok_model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_34/Tensordot/MatMul:MatMul"MatMul"pkagradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/truediv:Mul"Mul"ytggradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_5/Tensordot/MatMul/MatMul:MatMul"MatMul"UP8Adam/Adam/update_168/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"PK1Adam/Adam/AssignAddVariableOp:AssignAddVariableOp"AssignAddVariableOp"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"~ylgradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_55/Tensordot/MatMul/MatMul:MatMul"MatMul"
~
ngradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_1/transpose:Transpose"	Transpose"gbTmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_3/BiasAdd:BiasAdd"BiasAdd"a\Qmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/mean:Mean"Mean"faVmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/variance:Mean"Mean"

ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/Tensordot/MatMul/MatMul_1:MatMul"MatMul"mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"])Y)Pmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul:Mul"Mul"e`Pmodel/transformer/encoder/encoder_layer/multi_head_attention/transpose:Transpose"	Transpose"faVmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/variance:Mean"Mean"~ylgradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_11/Tensordot/MatMul/MatMul:MatMul"MatMul"[VLmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/truediv:Mul"Mul"a\]\Tgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_13/dropout/Mul_2:Mul"Mul"vqggradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_1/Mul_1:Mul"Mul"hcYgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/mul_1:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul/Sum:Sum"Sum"s
n
amodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_43/Tensordot/MatMul:MatMul"MatMul"|lgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"SNDmodel/transformer/encoder/encoder_layer/multi_head_attention/sub:Sub"Sub"kmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/SquaredDifference:SquaredDifference"SquaredDifference"r
m
cgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul/Mul:Mul"Mul"~jgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"zemodel/transformer/decoder/decoder_layer_2/sequential_6/dense_56/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"`[Qgradient_tape/model/transformer/decoder/decoder_layer/dropout_9/dropout/Mul_2:Mul"Mul"wrhgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_1/Mul_1:Mul"Mul"_ZPgradient_tape/model/transformer/decoder/decoder_layer/dropout_10/dropout/Mul:Mul"Mul"V	Q	Fmodel/transformer/decoder/decoder_layer_3/dropout_18/dropout/Cast:Cast"Cast"~|~kgradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_35/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"UP8Adam/Adam/update_149/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"B=(div_no_nan/ReadVariableOp:ReadVariableOp"ReadVariableOp"ni_gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/mul_1:Mul"Mul"ytggradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_6/Tensordot/MatMul/MatMul:MatMul"MatMul"R	M	Cmodel/transformer/decoder/decoder_layer/dropout_9/dropout/Mul_1:Mul"Mul"`[Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/sub:Sub"Sub"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul/Mul_1:Mul"Mul"S	N	Dmodel/transformer/decoder/decoder_layer_3/dropout_19/dropout/Mul:Mul"Mul"~ylgradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_56/Tensordot/MatMul/MatMul:MatMul"MatMul"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_2/Sum:Sum"Sum"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"]XJmodel/transformer/encoder/encoder_layer/sequential/dense_5/BiasAdd:BiasAdd"BiasAdd"TOEmodel/transformer/encoder/encoder_layer_1/dropout_3/dropout/Mul_1:Mul"Mul"Iterator::Model"zjgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/transpose/transpose:Transpose"	Transpose"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/Tensordot/MatMul:MatMul"MatMul"ni^gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/Tile:Tile"Tile"E@2model/transformer/decoder/dense_25/BiasAdd:BiasAdd"BiasAdd"\XOmodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul:Mul"Mul"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"faUmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/add_1:AddV2"AddV2"a\Rgradient_tape/model/transformer/decoder/decoder_layer/dropout_10/dropout/Mul_2:Mul"Mul"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/sub:Sub"Sub"TO7Adam/Adam/update_56/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"T
O
7Adam/Adam/update_99/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"+&Adam/gradients/AddN_41:AddN"AddN"mmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"b]Smodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_1:Mul"Mul"a\Rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/Sum:Sum"Sum"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_1/Mul:Mul"Mul"~	y	emodel/transformer/decoder/decoder_layer/dropout_10/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"}mgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/transpose/transpose:Transpose"	Transpose"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"r:n:bmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/Tensordot/MatMul:MatMul"MatMul"lgWmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_3:Transpose"	Transpose"+&Adam/gradients/AddN_36:AddN"AddN"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/Tensordot/MatMul:MatMul"MatMul"~qgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_3/Tensordot/MatMul/MatMul:MatMul"MatMul"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/moments/truediv_1:Mul"Mul"+
&
Adam/gradients/AddN_44:AddN"AddN"*% EagerExecute: FlushSummaryWriter"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul/Sum_1:Sum"Sum"HC)AssignAddVariableOp_1:AssignAddVariableOp"AssignAddVariableOp"oj_gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/Tile_1:Tile"Tile"TO7Adam/Adam/update_62/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"[VLmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/truediv:Mul"Mul"e`Vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/sub:Sub"Sub"SN6Adam/Adam/update_9/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_153/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"^$Z$Pmodel/transformer/decoder/decoder_layer/layer_normalization_10/moments/mean:Mean"Mean"t
o
egradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_2/Mul:Mul"Mul"ParallelMapConsume"A<'Adam/Cast/ReadVariableOp:ReadVariableOp"ReadVariableOp"FA5model/transformer/decoder/decoder_layer_2/add_2:AddV2"AddV2"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_2:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_1/Mul:Mul"Mul"	z	emodel/transformer/encoder/encoder_layer_1/sequential_1/dense_11/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"SKOK8Adam/Adam/update_129/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RMCmodel/transformer/encoder/encoder_layer/dropout_1/dropout/Mul_1:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_2/Mul:Mul"Mul"UP8Adam/Adam/update_162/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_100/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul/Sum_1:Sum"Sum"zemodel/transformer/decoder/decoder_layer_1/sequential_5/dense_46/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"faUmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/Rsqrt:Rsqrt"Rsqrt"r
m
cgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul/Sum_1:Sum"Sum"faVmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/variance:Mean"Mean"ni_gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/mul_1:Mul"Mul"n	i	Vmodel/transformer/decoder/decoder_layer_2/dropout_17/dropout/GreaterEqual:GreaterEqual"GreaterEqual"nuju`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/Tile:Tile"Tile"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/Tensordot/MatMul/MatMul_1:MatMul"MatMul"mmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"~ylgradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_66/Tensordot/MatMul/MatMul:MatMul"MatMul"NI6model/transformer/decoder/strided_slice_9:StridedSlice"StridedSlice"d_Qmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/Softmax:Softmax"Softmax"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/Tensordot/MatMul/MatMul:MatMul"MatMul"j	e	Wmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_27/BiasAdd:BiasAdd"BiasAdd"vqggradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_1/Mul_1:Mul"Mul"d_Smodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/add:AddV2"AddV2"~ylgradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_23/Tensordot/MatMul/MatMul:MatMul"MatMul"V	Q	Fmodel/transformer/decoder/decoder_layer_3/dropout_19/dropout/Cast:Cast"Cast"C>%FlushSummaryWriter:FlushSummaryWriter"FlushSummaryWriter"vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/Tensordot/MatMul/MatMul:MatMul"MatMul"rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_3/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"c^Pmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/Softmax:Softmax"Softmax"UP8Adam/Adam/update_116/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"j	e	Wmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/BiasAdd:BiasAdd"BiasAdd"ni_gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/mul_1:Mul"Mul"b^Smodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/Rsqrt:Rsqrt"Rsqrt"~ngradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_3/transpose:Transpose"	Transpose"zjgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/transpose_3/transpose:Transpose"	Transpose"wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/Tensordot/MatMul/MatMul:MatMul"MatMul"0+!model/transformer/encoder/mul:Mul"Mul"qmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"wrhgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_2/Mul_1:Mul"Mul"

mgradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_12/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"d_Rmodel/transformer/encoder/encoder_layer/sequential/dense_6/Tensordot/MatMul:MatMul"MatMul"lgYmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/BiasAdd:BiasAdd"BiasAdd"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_1/Mul:Mul"Mul"w
r
hgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_2/Mul_1:Mul"Mul"qlbgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/truediv/RealDiv:Mul"Mul"q1m1amodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/Tensordot/MatMul:MatMul"MatMul"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_1/Mul:Mul"Mul"a\Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul/Sum_1:Sum"Sum"b]Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/mean:Mean"Mean"+&Adam/gradients/AddN_59:AddN"AddN"wgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/sub/Neg:Neg"Neg"a\Rgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_20/dropout/Mul:Mul"Mul"r
m
cgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/sub/Neg:Neg"Neg"UP8Adam/Adam/update_146/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"]XMmodel/transformer/encoder/encoder_layer/layer_normalization/moments/mean:Mean"Mean"kfVmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_1:Transpose"	Transpose"
{
ngradient_tape/model/transformer/encoder/encoder_layer_3/sequential_3/dense_23/Tensordot/MatMul/MatMul_1:MatMul"MatMul"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"omodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"'"EagerLocalExecute: LogicalAnd"+&Adam/gradients/AddN_57:AddN"AddN"UP8Adam/Adam/update_170/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"V	Q	Fmodel/transformer/decoder/decoder_layer_1/dropout_14/dropout/Cast:Cast"Cast"FFogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"~ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose_2/transpose:Transpose"	Transpose"gbPgradient_tape/model/transformer/decoder/dense_26/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/Tensordot/MatMul/MatMul:MatMul"MatMul"ni_gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/truediv_1:Mul"Mul"wrhgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_2/Mul_1:Mul"Mul"UP8Adam/Adam/update_151/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"S	N	Dmodel/transformer/decoder/decoder_layer_2/dropout_15/dropout/Mul:Mul"Mul"rmbgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/Tile_1:Tile"Tile"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul/Mul:Mul"Mul"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Smodel/transformer/encoder/encoder_layer/layer_normalization_1/moments/variance:Mean"Mean"b]Smodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_1:Mul"Mul"0+&InstantiatedCapturedFunction::RunAsync"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Pmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/Softmax:Softmax"Softmax"kf\gradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/truediv/Sum:Sum"Sum"zemodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"c`_`Vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/mul:Mul"Mul"}xcmodel/transformer/decoder/decoder_layer/sequential_4/dense_35/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"|lgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"\WMmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/truediv:Mul"Mul"vqggradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_1/Mul_1:Mul"Mul"e
`
Vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/sub:Sub"Sub"wgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"(#Adam/gradients/AddN:AddN"AddN"ojVmodel/transformer/encoder/dropout_8/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"lg]gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/Mul:Mul"Mul"p	k	Wmodel/transformer/decoder/dropout_21/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/truediv_1:Mul"Mul"zemodel/transformer/decoder/decoder_layer_3/sequential_7/dense_65/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"kgUmodel/transformer/encoder/encoder_layer_2/dropout_4/dropout/GreaterEqual:GreaterEqual"GreaterEqual"tf.constant"e`Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/add:AddV2"AddV2"

lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"niZgradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_5/ReluGrad:ReluGrad"ReluGrad"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/Rsqrt:Rsqrt"Rsqrt"QL4Adam/Adam/update/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"

ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_1/transpose:Transpose"	Transpose"sn_gradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_55/ReluGrad:ReluGrad"ReluGrad"D?*div_no_nan_1/ReadVariableOp:ReadVariableOp"ReadVariableOp"vgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"ngradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"qlbgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/sub/Neg:Neg"Neg"zjgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/transpose_1/transpose:Transpose"	Transpose"UP8Adam/Adam/update_143/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"oj`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/mul_1:Mul"Mul"],Y,Pmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/sub:Sub"Sub"

wgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_10/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"<7#Iterator::Model::ParallelMapV2::Zip"Iterator::Zip"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"RMCmodel/transformer/encoder/encoder_layer_3/dropout_6/dropout/Mul:Mul"Mul"UPFmodel/transformer/decoder/decoder_layer_1/dropout_14/dropout/Mul_1:Mul"Mul"~ylgradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_45/Tensordot/MatMul/MatMul:MatMul"MatMul"	|	gmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"SSOS8Adam/Adam/update_119/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Smodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_2:Mul"Mul"{ngradient_tape/model/transformer/decoder/decoder_layer_2/sequential_6/dense_55/Tensordot/MatMul/MatMul_1:MatMul"MatMul"gbRmodel/transformer/encoder/encoder_layer/multi_head_attention/transpose_3:Transpose"	Transpose"toegradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_1/Mul_1:Mul"Mul"~ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_3/transpose:Transpose"	Transpose"}hmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"idTmodel/transformer/decoder/decoder_layer/multi_head_attention_5/transpose_2:Transpose"	Transpose"
z
fmodel/transformer/encoder/encoder_layer_2/dropout_5/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/Tensordot/MatMul:MatMul"MatMul"vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_15/Tensordot/MatMul/MatMul:MatMul"MatMul"n	i	Vmodel/transformer/decoder/decoder_layer_3/dropout_19/dropout/GreaterEqual:GreaterEqual"GreaterEqual"R}N}7Adam/Adam/update_96/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"d_Jmodel/transformer/decoder/dense_26/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"rmbgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/Tile_1:Tile"Tile"D?*div_no_nan/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"lmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/SquaredDifference:SquaredDifference"SquaredDifference"~yigradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"mh]gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/Tile_1:Tile"Tile"j	e	Wmodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/BiasAdd:BiasAdd"BiasAdd"kfVmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_3:Transpose"	Transpose"lgYmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_20/BiasAdd:BiasAdd"BiasAdd"UP8Adam/Adam/update_141/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"V	Q	Fmodel/transformer/decoder/decoder_layer_2/dropout_15/dropout/Cast:Cast"Cast"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_2/Sum:Sum"Sum"lmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"A<Iterator::Model::ParallelMapV2"Iterator::ParallelMapV2"ogradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_2/transpose:Transpose"	Transpose"lgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"n	i	Umodel/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul_1:BatchMatMulV2"BatchMatMulV2"ugradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/Tensordot/MatMul/MatMul:MatMul"MatMul"UQGmodel/transformer/decoder/decoder_layer/sequential_4/dense_35/Relu:Relu"Relu"zemodel/transformer/decoder/decoder_layer_2/sequential_6/dense_55/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul/Mul_1:Mul"Mul"d_Mgradient_tape/model/transformer/encoder/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"|lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose/transpose:Transpose"	Transpose"vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/Tensordot/MatMul/MatMul_1:MatMul"MatMul"TO7Adam/Adam/update_77/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"zemodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"mh^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/sub:Sub"Sub"b]Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/mean:Mean"Mean"`[Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul:Mul"Mul"idWmodel/transformer/encoder/encoder_layer_3/sequential_3/dense_23/Tensordot/MatMul:MatMul"MatMul"pkWmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul_1:BatchMatMulV2"BatchMatMulV2"

vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/Tensordot/MatMul/MatMul:MatMul"MatMul"b]Sgradient_tape/model/transformer/encoder/encoder_layer_1/dropout_3/dropout/Mul_2:Mul"Mul"j9f9Wmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_2:Transpose"	Transpose"c^Tgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_12/dropout/Mul_2:Mul"Mul"qlXmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/MatMul_1:BatchMatMulV2"BatchMatMulV2"~ngradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_3/transpose:Transpose"	Transpose"a\Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/sub:Sub"Sub"~qgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_2/Tensordot/MatMul/MatMul:MatMul"MatMul"TO7Adam/Adam/update_22/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a\Rgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_18/dropout/Mul:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_2/Mul:Mul"Mul"e
`
Vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/mul:Mul"Mul"NI6model/transformer/decoder/strided_slice_8:StridedSlice"StridedSlice"t
o
egradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_1/Mul:Mul"Mul"^YOmodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/sub:Sub"Sub"b]Omodel/transformer/encoder/encoder_layer_3/sequential_3/dense_23/BiasAdd:BiasAdd"BiasAdd"p
k
agradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/truediv:Mul"Mul"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/BiasAdd:BiasAdd"BiasAdd"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp")$EagerLocalExecute: WriteSummary"~jgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"e`Vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/mul:Mul"Mul"S	N	Cmodel/transformer/decoder/decoder_layer/dropout_9/dropout/Cast:Cast"Cast"NNwgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"+&Adam/gradients/AddN_26:AddN"AddN"*%Adam/gradients/AddN_6:AddN"AddN"TO7Adam/Adam/update_46/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"sgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_2/Tensordot/MatMul/MatMul_1:MatMul"MatMul"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/Tensordot/MatMul/MatMul_1:MatMul"MatMul"UP8Adam/Adam/update_135/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"		jmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_2/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"qlbgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/truediv:Mul"Mul"vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/Tensordot/MatMul/MatMul:MatMul"MatMul"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"jeWmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/BiasAdd:BiasAdd"BiasAdd"`[Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/sub:Sub"Sub"+&Adam/gradients/AddN_49:AddN"AddN"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"lmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/SquaredDifference:SquaredDifference"SquaredDifference"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/sub:Sub"Sub"	{	gmodel/transformer/decoder/decoder_layer_2/dropout_17/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"hhvgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/Tensordot/MatMul/MatMul:MatMul"MatMul"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Tgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_20/dropout/Mul_2:Mul"Mul"b]Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/mean:Mean"Mean"kf[gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/Tile:Tile"Tile"r
m
cgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_2/Mul:Mul"Mul"xgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/Tensordot/MatMul/MatMul_1:MatMul"MatMul"n	i	Vmodel/transformer/decoder/decoder_layer_3/dropout_20/dropout/GreaterEqual:GreaterEqual"GreaterEqual"oj`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/mul_1:Mul"Mul"wgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_22/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_2/Sum:Sum"Sum"q	l	_model/transformer/decoder/decoder_layer/multi_head_attention_4/dense_28/Tensordot/MatMul:MatMul"MatMul"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"W
S
Jmodel/transformer/decoder/decoder_layer/multi_head_attention_5/truediv:Mul"Mul" EagerExecute: Identity"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/BiasAdd:BiasAdd"BiasAdd"r
m
cgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul/Sum:Sum"Sum"~qgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_4/Tensordot/MatMul/MatMul:MatMul"MatMul"idTmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose:Transpose"	Transpose"B=/model/transformer/encoder/dense/BiasAdd:BiasAdd"BiasAdd"

wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/truediv_1:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_1/Mul:Mul"Mul"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul/Sum_1:Sum"Sum"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul/Mul_1:Mul"Mul"+&Adam/gradients/AddN_28:AddN"AddN"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_2/Sum:Sum"Sum"oj`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/mul_1:Mul"Mul"faWgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/Sum:Sum"Sum"a4]4Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_2:Mul"Mul"gbVmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/Rsqrt:Rsqrt"Rsqrt"toegradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_1/Mul:Mul"Mul"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"niUmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul:BatchMatMulV2"BatchMatMulV2"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul_1:Mul"Mul"		omodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_37/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"_[[[Rgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_13/dropout/Mul:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul/Mul:Mul"Mul"~ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_2/transpose:Transpose"	Transpose"`[Omodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/add:AddV2"AddV2"TO7Adam/Adam/update_23/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"~ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_1/transpose:Transpose"	Transpose"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"mh^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/Mul:Mul"Mul"~
y
lgradient_tape/model/transformer/encoder/encoder_layer_2/sequential_2/dense_18/Tensordot/MatMul/MatMul:MatMul"MatMul"b]Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/mean:Mean"Mean"n	i	Vmodel/transformer/decoder/decoder_layer_2/dropout_15/dropout/GreaterEqual:GreaterEqual"GreaterEqual"SEOE8Adam/Adam/update_164/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_42/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"lmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"TOEmodel/transformer/encoder/encoder_layer_2/dropout_5/dropout/Mul_1:Mul"Mul")$div_no_nan_1:DivNoNan"DivNoNan"gbVmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/add_1:AddV2"AddV2"lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"~qgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_1/Tensordot/MatMul/MatMul:MatMul"MatMul"d_Smodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/add:AddV2"AddV2"idWmodel/transformer/encoder/encoder_layer_3/sequential_3/dense_24/Tensordot/MatMul:MatMul"MatMul"UP8Adam/Adam/update_132/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"V	Q	Fmodel/transformer/decoder/decoder_layer_2/dropout_16/dropout/Cast:Cast"Cast"pk`gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/Tile:Tile"Tile"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"FunctionRun"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/sub/Sum:Sum"Sum"xgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_38/Tensordot/MatMul/MatMul_1:MatMul"MatMul"SNDgradient_tape/model/transformer/decoder/dropout_21/dropout/Mul_2:Mul"Mul"g{glgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose/transpose:Transpose"	Transpose"mmodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"a\AIterator::Model::ParallelMapV2::Zip[1]::ForeverRepeat::FromTensor"Iterator::FromTensor"~ylgradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_46/Tensordot/MatMul/MatMul:MatMul"MatMul"{kgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"TO7Adam/Adam/update_74/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"|gmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Tgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_16/dropout/Mul_2:Mul"Mul"a\Rmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/sub:Sub"Sub"wrhgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_2/Mul_1:Mul"Mul"kmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/SquaredDifference:SquaredDifference"SquaredDifference"faVmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/variance:Mean"Mean"[VLmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/truediv:Mul"Mul"T
O
7Adam/Adam/update_25/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qlagradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/Tile_1:Tile"Tile"}yfmodel/transformer/encoder/encoder_layer_2/dropout_4/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/truediv/Sum:Sum"Sum"+&Adam/gradients/AddN_21:AddN"AddN"faVmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/variance:Mean"Mean"TO7Adam/Adam/update_73/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UPFmodel/transformer/decoder/decoder_layer_3/dropout_19/dropout/Mul_1:Mul"Mul"zfmodel/transformer/encoder/encoder_layer_1/dropout_3/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"UP8Adam/Adam/update_126/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"idWmodel/transformer/encoder/encoder_layer_2/sequential_2/dense_18/Tensordot/MatMul:MatMul"MatMul"+
&
Adam/gradients/AddN_48:AddN"AddN"FA'AssignAddVariableOp:AssignAddVariableOp"AssignAddVariableOp"l
g
]gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/Mul:Mul"Mul"niUmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul:BatchMatMulV2"BatchMatMulV2"e`Umodel/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/variance:Mean"Mean"h
c
Ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/mul_1:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/truediv_1:Mul"Mul"omodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_29/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"B#>#3model/transformer/decoder/decoder_layer/add_2:AddV2"AddV2"SN6Adam/Adam/update_1/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ni_gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/mul_1:Mul"Mul"		omodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"sVoVfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul/Sum_1:Sum"Sum"UP8Adam/Adam/update_172/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_51/Tensordot/MatMul/MatMul:MatMul"MatMul"TO7Adam/Adam/update_36/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"`[?Iterator::Model::ParallelMapV2::Zip[0]::FlatMap[0]::TensorSlice"Iterator::TensorSlice"lgSmodel/transformer/encoder/encoder_layer/multi_head_attention/MatMul_1:BatchMatMulV2"BatchMatMulV2"a\Rgradient_tape/model/transformer/decoder/decoder_layer_1/dropout_14/dropout/Mul:Mul"Mul" 		Adam/Cast_1:Cast"Cast"+&Adam/gradients/AddN_13:AddN"AddN"wgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"qlbgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/truediv:Mul"Mul"FA5model/transformer/encoder/encoder_layer_3/add_1:AddV2"AddV2"TO7Adam/Adam/update_28/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"gbVmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/add_1:AddV2"AddV2"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_2/Mul:Mul"Mul"idTmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose:Transpose"	Transpose"	{	gmodel/transformer/decoder/decoder_layer_3/dropout_19/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"upqphgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_2/Mul_1:Mul"Mul"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_47/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_2/Sum:Sum"Sum"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/truediv_1:Mul"Mul"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/sub:Sub"Sub"e`Umodel/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/variance:Mean"Mean"T
O
7Adam/Adam/update_12/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"vqggradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/mul_1/Mul_1:Mul"Mul"n	i	Vmodel/transformer/decoder/decoder_layer_3/dropout_18/dropout/GreaterEqual:GreaterEqual"GreaterEqual"wrhgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_1/Mul_1:Mul"Mul"lgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"UP8Adam/Adam/update_102/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a	\	Nmodel/transformer/decoder/decoder_layer/multi_head_attention_4/Softmax:Softmax"Softmax"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"B>3model/transformer/decoder/decoder_layer/add_1:AddV2"AddV2"rmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_58/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"pk`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/Tile:Tile"Tile"T
O
7Adam/Adam/update_58/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"SN6Adam/Adam/update_4/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"c^Tgradient_tape/model/transformer/decoder/decoder_layer_3/dropout_18/dropout/Mul_2:Mul"Mul"TO7Adam/Adam/update_86/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"q
l
bgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/moments/truediv:Mul"Mul"mh^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/moments/Mul:Mul"Mul"~jgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"c^Tgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/mul_1:Mul"Mul"TO7Adam/Adam/update_34/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/BiasAdd:BiasAdd"BiasAdd"e`Vgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/sub:Sub"Sub"wrhgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_1/Mul_1:Mul"Mul"*%Adam/gradients/AddN_5:AddN"AddN"j<f<Wmodel/transformer/decoder/decoder_layer_3/multi_head_attention_10/transpose_1:Transpose"	Transpose"YTImodel/transformer/decoder/decoder_layer_1/sequential_5/dense_45/Relu:Relu"Relu"lg]gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/Mul:Mul"Mul"C>)Adam/Cast_3/ReadVariableOp:ReadVariableOp"ReadVariableOp"D?3model/transformer/decoder/decoder_layer_2/add:AddV2"AddV2"idTmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose:Transpose"	Transpose"		qmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"je[gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/moments/mul_1:Mul"Mul"*%Adam/gradients/AddN_1:AddN"AddN"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_31/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"kfXmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/BiasAdd:BiasAdd"BiasAdd"{vigradient_tape/model/transformer/encoder/encoder_layer/sequential/dense_5/Tensordot/MatMul/MatMul_1:MatMul"MatMul"TO7Adam/Adam/update_94/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"zemodel/transformer/decoder/decoder_layer/sequential_4/dense_36/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"~ylgradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_65/Tensordot/MatMul/MatMul:MatMul"MatMul"r
m
cgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/truediv_1:Mul"Mul"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/sub:Sub"Sub"n	i	Vmodel/transformer/decoder/decoder_layer_2/dropout_16/dropout/GreaterEqual:GreaterEqual"GreaterEqual"SMOM8Adam/Adam/update_128/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"}hmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"}hmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"b]Smodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_1:Mul"Mul"wrhgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul_2/Mul_1:Mul"Mul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/mul/Sum:Sum"Sum"vqggradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_1/Mul_1:Mul"Mul"&!IteratorGetNextOp::DoCompute"lgYmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/BiasAdd:BiasAdd"BiasAdd"wgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/Tensordot/MatMul/MatMul_1:MatMul"MatMul"TO7Adam/Adam/update_89/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"		Adam/add:AddV2"AddV2"upfgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_1/Mul:Mul"Mul"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_40/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"vqggradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul_2/Mul_1:Mul"Mul"{ngradient_tape/model/transformer/decoder/decoder_layer_1/sequential_5/dense_46/Tensordot/MatMul/MatMul_1:MatMul"MatMul"kf\gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/sub:Sub"Sub"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul/Sum:Sum"Sum"qomodgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/truediv_1:Mul"Mul"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_50/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"wgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_14/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"xgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_19/Tensordot/MatMul/MatMul_1:MatMul"MatMul"ni_gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/mul_1:Mul"Mul"	{	gmodel/transformer/decoder/decoder_layer_3/dropout_20/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"FA5model/transformer/decoder/decoder_layer_1/add_2:AddV2"AddV2"mh^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/moments/sub:Sub"Sub"sgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/dense_3/Tensordot/MatMul/MatMul_1:MatMul"MatMul"snamodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_41/Tensordot/MatMul:MatMul"MatMul"FA5model/transformer/decoder/decoder_layer_2/add_1:AddV2"AddV2"
~
ngradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/transpose_1/transpose:Transpose"	Transpose"`[Qgradient_tape/model/transformer/encoder/encoder_layer_1/dropout_2/dropout/Mul:Mul"Mul"j	f	Smodel/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul:BatchMatMulV2"BatchMatMulV2"sndgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul/Mul_1:Mul"Mul"UP8Adam/Adam/update_111/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"tobmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/Tensordot/MatMul:MatMul"MatMul"vqggradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/mul_2/Mul_1:Mul"Mul"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_1:Mul"Mul"0+!model/transformer/encoder/Sin:Sin"Sin"wgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"faUmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/Rsqrt:Rsqrt"Rsqrt"
{
ngradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_11/Tensordot/MatMul/MatMul_1:MatMul"MatMul"FA,div_no_nan_1/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"r
m
cgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul/Sum:Sum"Sum"SN6Adam/Adam/update_6/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"

xgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/Tensordot/MatMul/MatMul_1:MatMul"MatMul"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/Tensordot/MatMul/MatMul_1:MatMul"MatMul"kmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"_+[+Rmodel/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_2:Mul"Mul"XS5Iterator::Model::ParallelMapV2::Zip[1]::ForeverRepeat"Iterator::ForeverRepeat"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/sub/Neg:Neg"Neg"		lmodel/transformer/encoder/encoder_layer/multi_head_attention/dense_2/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"^}^ngradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_3/transpose:Transpose"	Transpose"wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/Tensordot/MatMul/MatMul:MatMul"MatMul"wrhgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_2/Mul_1:Mul"Mul"~ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_2/transpose:Transpose"	Transpose"|lgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose/transpose:Transpose"	Transpose"a\Qmodel/transformer/encoder/encoder_layer/layer_normalization/moments/variance:Mean"Mean"	|	gmodel/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"qlbgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul/Mul:Mul"Mul"}hmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"sn_gradient_tape/model/transformer/decoder/decoder_layer_3/sequential_7/dense_65/ReluGrad:ReluGrad"ReluGrad"TO7Adam/Adam/update_17/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul/Sum:Sum"Sum"ql]gradient_tape/model/transformer/decoder/decoder_layer/sequential_4/dense_35/ReluGrad:ReluGrad"ReluGrad"FA5model/transformer/decoder/decoder_layer_3/add_1:AddV2"AddV2"UP8Adam/Adam/update_163/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lgYmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/BiasAdd:BiasAdd"BiasAdd"	{	gmodel/transformer/decoder/decoder_layer_2/dropout_15/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"x}xjgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"}hmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"b]Omodel/transformer/encoder/encoder_layer_2/sequential_2/dense_18/BiasAdd:BiasAdd"BiasAdd"mh^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/Mul:Mul"Mul"d_Qmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/Softmax:Softmax"Softmax"snamodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_21/Tensordot/MatMul:MatMul"MatMul"R
M
Cmodel/transformer/encoder/encoder_layer_2/dropout_5/dropout/Mul:Mul"Mul"vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_49/Tensordot/MatMul/MatMul:MatMul"MatMul"n	i	Vmodel/transformer/decoder/decoder_layer_1/dropout_14/dropout/GreaterEqual:GreaterEqual"GreaterEqual"b]Omodel/transformer/encoder/encoder_layer_2/sequential_2/dense_17/BiasAdd:BiasAdd"BiasAdd"rmcgradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/truediv_1:Mul"Mul"kf\gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/moments/Mul:Mul"Mul"TO7Adam/Adam/update_93/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"^ZQmodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_2:Mul"Mul"~imodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/sub/Neg:Neg"Neg"l
g
]gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/Mul:Mul"Mul"LG/Iterator::Model::ParallelMapV2::Zip[0]::FlatMap"Iterator::FlatMap"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul/Sum:Sum"Sum"s
n
dgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/mul_1/Mul:Mul"Mul"a\Rgradient_tape/model/transformer/decoder/decoder_layer_2/dropout_16/dropout/Mul:Mul"Mul"rmbgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/Tile_1:Tile"Tile"E@5model/transformer/encoder/dropout_8/dropout/Cast:Cast"Cast"~ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/transpose_3/transpose:Transpose"	Transpose"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_60/Tensordot/MatMul/MatMul_1:MatMul"MatMul"niUmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul:BatchMatMulV2"BatchMatMulV2"toegradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul_2/Mul:Mul"Mul"oj`gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/moments/mul_1:Mul"Mul"PLCmodel/transformer/encoder/encoder_layer_2/dropout_4/dropout/Mul:Mul"Mul"e`Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/add:AddV2"AddV2"+&Adam/gradients/AddN_55:AddN"AddN"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/sub/Neg:Neg"Neg"

vgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/Tensordot/MatMul/MatMul_1:MatMul"MatMul"c^Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_14/batchnorm/mul_2:Mul"Mul"UPFmodel/transformer/decoder/decoder_layer_1/dropout_12/dropout/Mul_1:Mul"Mul"d	_	Smodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/Rsqrt:Rsqrt"Rsqrt"SN6Adam/Adam/update_2/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/sub/Neg:Neg"Neg"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul/Mul:Mul"Mul"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul_2/Sum:Sum"Sum"c^Pmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/Softmax:Softmax"Softmax"a\Rgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/mul:Mul"Mul"`[Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul:Mul"Mul"|gmodel/transformer/decoder/decoder_layer_2/sequential_6/dense_56/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"faUmodel/transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/add_1:AddV2"AddV2"b&^&Tmodel/transformer/decoder/decoder_layer/layer_normalization_10/moments/variance:Mean"Mean"q
l
bgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/truediv/RealDiv:Mul"Mul"FA5model/transformer/decoder/decoder_layer_3/add_2:AddV2"AddV2"<	7	"Adam/ReadVariableOp:ReadVariableOp"ReadVariableOp"sUoUfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul/Mul_1:Mul"Mul"toegradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_1/Mul_1:Mul"Mul"}hmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"pkWmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul_1:BatchMatMulV2"BatchMatMulV2"|lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/transpose/transpose:Transpose"	Transpose"*%Adam/gradients/AddN_8:AddN"AddN"b]Sgradient_tape/model/transformer/encoder/encoder_layer_3/dropout_7/dropout/Mul_2:Mul"Mul"ParallelMapProduce"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul/Sum:Sum"Sum"}xhgradient_tape/model/transformer/encoder/encoder_layer/multi_head_attention/transpose/transpose:Transpose"	Transpose"rmcgradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul_2/Sum:Sum"Sum"	~	imodel/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"e`Vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/Sum:Sum"Sum"}hmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"{ngradient_tape/model/transformer/encoder/encoder_layer_1/sequential_1/dense_12/Tensordot/MatMul/MatMul_1:MatMul"MatMul"TO7Adam/Adam/update_95/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Smodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/mul_1:Mul"Mul"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/Tensordot/MatMul:MatMul"MatMul"`[Qgradient_tape/model/transformer/encoder/encoder_layer_2/dropout_4/dropout/Mul:Mul"Mul"kwgw^gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_11/moments/Mul:Mul"Mul"zemodel/transformer/encoder/encoder_layer_3/sequential_3/dense_24/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"oj_gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/Tile:Tile"Tile"rmcgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization/batchnorm/mul_2/Mul_1:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/sub/Neg:Neg"Neg"	{	gmodel/transformer/decoder/decoder_layer_3/dropout_18/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"snamodel/transformer/decoder/decoder_layer_2/multi_head_attention_8/dense_48/Tensordot/MatMul:MatMul"MatMul"*%Adam/gradients/AddN_2:AddN"AddN"SNCmodel/transformer/encoder/encoder_layer/dropout_1/dropout/Cast:Cast"Cast"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/sub/Neg:Neg"Neg"kfVmodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/transpose_3:Transpose"	Transpose"c^Tmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul_2:Mul"Mul"r
m
cgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul/Mul_1:Mul"Mul"TO7Adam/Adam/update_19/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"QMDmodel/transformer/decoder/decoder_layer/dropout_10/dropout/Mul_1:Mul"Mul"d_Smodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/add:AddV2"AddV2"TO7Adam/Adam/update_67/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"|lgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_17/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"lg]gradient_tape/model/transformer/encoder/encoder_layer_2/layer_normalization_4/moments/sub:Sub"Sub"b]Omodel/transformer/decoder/decoder_layer_3/sequential_7/dense_66/BiasAdd:BiasAdd"BiasAdd"ugradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_32/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"~jgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"WRHmodel/transformer/encoder/encoder_layer_3/multi_head_attention_3/sub:Sub"Sub"faVmodel/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/variance:Mean"Mean"UP8Adam/Adam/update_165/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"`
[
Qgradient_tape/model/transformer/encoder/encoder_layer_2/dropout_5/dropout/Mul:Mul"Mul"PKAmodel/transformer/encoder/encoder_layer/dropout_1/dropout/Mul:Mul"Mul"s
n
dgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul/Mul:Mul"Mul"lgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"kmodel/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"i3e3Vmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/transpose_1:Transpose"	Transpose"TO7Adam/Adam/update_37/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lg]gradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/moments/sub:Sub"Sub"	|	gmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"^YOgradient_tape/model/transformer/encoder/encoder_layer/dropout/dropout/Mul_2:Mul"Mul"ni_gradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/truediv/Sum:Sum"Sum"mh^gradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/sub:Sub"Sub"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul/Mul_1:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul/Sum:Sum"Sum"rm`model/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_9/Tensordot/MatMul:MatMul"MatMul"	|	gmodel/transformer/encoder/encoder_layer_3/layer_normalization_7/batchnorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/sub:Sub"Sub"C>)Adam/Cast_2/ReadVariableOp:ReadVariableOp"ReadVariableOp"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/truediv_1:Mul"Mul"}xdmodel/transformer/encoder/encoder_layer/dropout_1/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"^YOgradient_tape/model/transformer/encoder/encoder_layer/dropout_1/dropout/Mul:Mul"Mul"+&Adam/gradients/AddN_30:AddN"AddN"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul_2:Mul"Mul"gbXgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_8/mul_1:Mul"Mul"a\Rmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/mul:Mul"Mul"	{	gmodel/transformer/decoder/decoder_layer_2/dropout_16/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"D@@@5gradient_tape/model/transformer/decoder/Slice_1:Slice"Slice"omodel/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"`[Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/batchnorm/mul:Mul"Mul"tgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/Tensordot/MatMul/MatMul:MatMul"MatMul"wgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_57/Tensordot/MatMul/MatMul:MatMul"MatMul"sndgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/batchnorm/mul/Mul:Mul"Mul"+
&
Adam/gradients/AddN_45:AddN"AddN"upfgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/mul/Sum_1:Sum"Sum"k	f	Smodel/transformer/decoder/decoder_layer/dropout_9/dropout/GreaterEqual:GreaterEqual"GreaterEqual"e`Umodel/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/variance:Mean"Mean"{kgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"|lgradient_tape/model/transformer/decoder/decoder_layer/multi_head_attention_4/transpose_1/transpose:Transpose"	Transpose"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul/Sum:Sum"Sum"cb_bVgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/sub:Sub"Sub"omodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_52/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul/Sum:Sum"Sum"r
m
cgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/truediv/RealDiv:Mul"Mul"vgradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_13/Tensordot/MatMul/MatMul:MatMul"MatMul"ngradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"TO7Adam/Adam/update_55/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"q
l
bgradient_tape/model/transformer/encoder/encoder_layer_1/multi_head_attention_1/truediv/RealDiv:Mul"Mul"qlbgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/truediv:Mul"Mul"lgradient_tape/model/transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/sub/Sum:Sum"Sum"vgradient_tape/model/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_53/Tensordot/MatMul/MatMul:MatMul"MatMul"UPFmodel/transformer/decoder/decoder_layer_2/dropout_16/dropout/Mul_1:Mul"Mul"+&Adam/gradients/AddN_52:AddN"AddN"_[Nmodel/transformer/decoder/decoder_layer/multi_head_attention_5/Softmax:Softmax"Softmax"upfgradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul/Mul_1:Mul"Mul"lg]gradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/moments/mul_1:Mul"Mul"~yigradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"o
j
_gradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/Tile:Tile"Tile"mhZmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_64/BiasAdd:BiasAdd"BiasAdd"c^Tmodel/transformer/decoder/decoder_layer_1/layer_normalization_11/batchnorm/mul_1:Mul"Mul"g	b	Rmodel/transformer/decoder/decoder_layer/multi_head_attention_5/transpose:Transpose"	Transpose"ExecutorDoneCallback"YTImodel/transformer/encoder/encoder_layer_2/sequential_2/dense_17/Relu:Relu"Relu"rmcgradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul_1/Mul:Mul"Mul"pk`gradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/moments/Tile:Tile"Tile"SN6Adam/Adam/update_5/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_171/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"omodel/transformer/decoder/decoder_layer/multi_head_attention_5/dense_33/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"a\Qmodel/transformer/encoder/encoder_layer_2/layer_normalization_5/moments/mean:Mean"Mean"q.m.amodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_39/Tensordot/MatMul:MatMul"MatMul"q
l
agradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/moments/Tile_1:Tile"Tile"c^Tmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul_2:Mul"Mul"		nmodel/transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_8/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"]]vgradient_tape/model/transformer/decoder/decoder_layer_1/multi_head_attention_7/dense_44/Tensordot/MatMul/MatMul:MatMul"MatMul"TO7Adam/Adam/update_92/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"~imodel/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul/ReadVariableOp:ReadVariableOp"ReadVariableOp"e`Umodel/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/variance:Mean"Mean"sndgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_14/moments/truediv_1:Mul"Mul"*%Adam/gradients/AddN_9:AddN"AddN"xgradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_63/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"rmcgradient_tape/model/transformer/encoder/encoder_layer_1/layer_normalization_3/batchnorm/mul/Mul:Mul"Mul"rmcgradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_7/moments/truediv_1:Mul"Mul"gbRmodel/transformer/encoder/encoder_layer/multi_head_attention/transpose_1:Transpose"	Transpose"3.#model/transformer/decoder/Cast:Cast"Cast"TO7Adam/Adam/update_18/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"		omodel/transformer/decoder/decoder_layer/multi_head_attention_4/dense_30/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"qmodel/transformer/decoder/decoder_layer_2/multi_head_attention_9/dense_54/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"pkagradient_tape/model/transformer/encoder/encoder_layer/layer_normalization_1/batchnorm/mul/Mul:Mul"Mul"mh^gradient_tape/model/transformer/decoder/decoder_layer_3/layer_normalization_18/moments/sub:Sub"Sub"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_61/Tensordot/MatMul/MatMul_1:MatMul"MatMul"gbVmodel/transformer/decoder/decoder_layer_2/layer_normalization_15/batchnorm/Rsqrt:Rsqrt"Rsqrt"TO7Adam/Adam/update_35/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RN7Adam/Adam/update_87/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pmodel/transformer/decoder/decoder_layer_3/multi_head_attention_11/dense_62/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_31/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ni_gradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/moments/truediv:Mul"Mul"lgYmodel/transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_16/BiasAdd:BiasAdd"BiasAdd"UP8Adam/Adam/update_139/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"	{	gmodel/transformer/decoder/decoder_layer_1/dropout_14/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"niUmodel/transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul:BatchMatMulV2"BatchMatMulV2"idWmodel/transformer/encoder/encoder_layer_2/sequential_2/dense_17/Tensordot/MatMul:MatMul"MatMul"ni\model/transformer/encoder/encoder_layer/multi_head_attention/dense_1/Tensordot/MatMul:MatMul"MatMul"sndgradient_tape/model/transformer/decoder/decoder_layer_1/layer_normalization_12/batchnorm/mul/Sum:Sum"Sum"ygradient_tape/model/transformer/decoder/decoder_layer_3/multi_head_attention_10/dense_59/Tensordot/MatMul/MatMul_1:MatMul"MatMul"UPFmodel/transformer/decoder/decoder_layer_2/dropout_17/dropout/Mul_1:Mul"Mul"T
O
7Adam/Adam/update_15/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a\Ogradient_tape/model/transformer/decoder/dense_25/Tensordot/MatMul/MatMul:MatMul"MatMul"^ZQmodel/transformer/decoder/decoder_layer/layer_normalization_9/batchnorm/mul_1:Mul"Mul"UP8Adam/Adam/update_173/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"train_function"wrhgradient_tape/model/transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/mul_1/Mul_1:Mul"Mul"~ngradient_tape/model/transformer/encoder/encoder_layer_2/multi_head_attention_2/transpose_2/transpose:Transpose"	Transpose"a\Rmodel/transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/mul:Mul"Mul"pkagradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/truediv:Mul"Mul"toegradient_tape/model/transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/mul_1/Mul:Mul"Mul"pkagradient_tape/model/transformer/decoder/decoder_layer/layer_normalization_8/batchnorm/mul/Sum:Sum"Sum"a\Qmodel/transformer/encoder/encoder_layer_3/layer_normalization_6/moments/mean:Mean"Mean"idWmodel/transformer/decoder/decoder_layer_1/sequential_5/dense_45/Tensordot/MatMul:MatMul"MatMul*	step_name*group_id*selected_group_ids*is_eager*
element_id*
_c*autotune*	parent_id*
id*_ct*iter_num*tf_function_call*
_p*tracing_count*notTraced-nonXla*		deterministic*true*_pt*

parallelism"DESKTOP-90FSP9O